[
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "Source: https://news.mit.edu/2025/introducing-mit-generative-ai-impact-consortium-0203 Introducing the MIT Generative AI Impact Consortium | MIT News | Massachusetts Institute of Technology Skip to content \u2193 Massachusetts Institute of Technology MIT Top Menu\u2193 Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT More \u2193 Search MIT Search websites, locations, and people See More Results Suggestions or feedback? MIT News | Massachusetts Institute of Technology - On Campus and Around the world Subscribe to MIT News newsletter Browse Enter keywords to search for news articles: Submit Browse By Topics View All \u2192 Explore: Machine learning Sustainability Startups Black holes Classes and programs Departments View All \u2192 Explore: Aeronautics and Astronautics Brain and Cognitive Sciences Architecture Political Science Mechanical Engineering Centers, Labs, & Programs View All \u2192 Explore: Abdul Latif Jameel Poverty Action Lab (J-PAL) Picower Institute for Learning and Memory Media Lab Lincoln Laboratory Schools School of Architecture + Planning School of Engineering School of Humanities, Arts, and Social Sciences Sloan School of Management School of Science MIT Schwarzman College of Computing View all news coverage of MIT in the media \u2192 Listen to audio content from MIT News \u2192 Subscribe to MIT newsletter \u2192 Close Breadcrumb MIT News Introducing the MIT Generative AI Impact Consortium Introducing the MIT Generative AI Impact Consortium The consortium will bring researchers and industry together to focus on impact. Liam McDonnell | Office of Innovation and Strategy Publication Date: February 3, 2025 Press Inquiries Press Contact: Liam McDonnell Email: liammcd@mit.edu Phone: 781-267-8204 MIT Office of Innovation Close Caption: The MIT Generative AI Impact",
    "chunk_id": "downloaded_1763553846_0"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "industry together to focus on impact. Liam McDonnell | Office of Innovation and Strategy Publication Date: February 3, 2025 Press Inquiries Press Contact: Liam McDonnell Email: liammcd@mit.edu Phone: 781-267-8204 MIT Office of Innovation Close Caption: The MIT Generative AI Impact Consortium aims to harness the transformative power of artificial intelligence for societal good, tackling challenges before they shape the future in unintended ways. Credits: Image: Emily Dahl Previous image Next image From crafting complex code to revolutionizing the hiring process, generative artificial intelligence is reshaping industries faster than ever before \u2014 pushing the boundaries of creativity, productivity, and collaboration across countless domains.Enter the MIT Generative AI Impact Consortium, a collaboration between industry leaders and MIT\u2019s top minds. As MIT President Sally Kornbluth highlighted last year, the Institute is poised to address the societal impacts of generative AI through bold collaborations. Building on this momentum and established through MIT\u2019s Generative AI Week and impact papers, the consortium aims to harness AI\u2019s transformative power for societal good, tackling challenges before they shape the future in unintended ways.\u201cGenerative AI and large language models [LLMs] are reshaping everything, with applications stretching across diverse sectors,\u201d says Anantha Chandrakasan, dean of the School of Engineering and MIT\u2019s chief innovation and strategy officer, who leads the consortium. \u201cAs we push forward with newer and more efficient models, MIT is committed to guiding their development and impact on the world.\u201dChandrakasan adds that the consortium\u2019s vision is rooted in MIT\u2019s core mission. \u201cI am thrilled and honored to help advance one of President Kornbluth\u2019s strategic",
    "chunk_id": "downloaded_1763553846_1"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "and more efficient models, MIT is committed to guiding their development and impact on the world.\u201dChandrakasan adds that the consortium\u2019s vision is rooted in MIT\u2019s core mission. \u201cI am thrilled and honored to help advance one of President Kornbluth\u2019s strategic priorities around artificial intelligence,\u201d he says. \u201cThis initiative is uniquely MIT \u2014 it thrives on breaking down barriers, bringing together disciplines, and partnering with industry to create real, lasting impact. The collaborations ahead are something we\u2019re truly excited about.\u201dDeveloping the blueprint for generative AI\u2019s next leapThe consortium is guided by three pivotal questions, framed by Daniel Huttenlocher, dean of the MIT Schwarzman College of Computing and co-chair of the GenAI Dean\u2019s oversight group, that go beyond AI\u2019s technical capabilities and into its potential to transform industries and lives:How can AI-human collaboration create outcomes that neither could achieve alone?What is the dynamic between AI systems and human behavior, and how do we maximize the benefits while steering clear of risks?How can interdisciplinary research guide the development of better, safer AI technologies that improve human life?Generative AI continues to advance at lightning speed, but its future depends on building a solid foundation. \u201cEverybody recognizes that large language models will transform entire industries, but there's no strong foundation yet around design principles,\u201d says Tim Kraska, associate professor of electrical engineering and computer science in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and co-faculty director of the consortium.\u201cNow is a perfect time to look at the fundamentals \u2014 the building blocks that will make generative AI more effective",
    "chunk_id": "downloaded_1763553846_2"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "engineering and computer science in the MIT Computer Science and Artificial Intelligence Laboratory (CSAIL) and co-faculty director of the consortium.\u201cNow is a perfect time to look at the fundamentals \u2014 the building blocks that will make generative AI more effective and safer to use,\u201d adds Kraska.\"What excites me is that this consortium isn\u2019t just academic research for the distant future \u2014 we\u2019re working on problems where our timelines align with industry needs, driving meaningful progress in real time,\" says Vivek F. Farias, the Patrick J. McGovern (1959) Professor at the MIT Sloan School of Management, and co-faculty director of the consortium.A \u201cperfect match\u201d of academia and industryAt the heart of the Generative AI Impact Consortium are six founding members: Analog Devices, The Coca-Cola Co., OpenAI, Tata Group, SK Telecom, and TWG Global. Together, they will work hand-in-hand with MIT researchers to accelerate breakthroughs and address industry-shaping problems.The consortium taps into MIT\u2019s expertise, working across schools and disciplines \u2014 led by MIT\u2019s Office of Innovation and Strategy, in collaboration with the MIT Schwarzman College of Computing and all five of MIT\u2019s schools.\u201cThis initiative is the ideal bridge between academia and industry,\u201d says Chandrakasan. \u201cWith companies spanning diverse sectors, the consortium brings together real-world challenges, data, and expertise. MIT researchers will dive into these problems to develop cutting-edge models and applications into these different domains.\u201dIndustry partners: Collaborating on AI\u2019s evolutionAt the core of the consortium\u2019s mission is collaboration \u2014 bringing MIT researchers and industry partners together to unlock generative AI\u2019s potential while ensuring its benefits are felt across",
    "chunk_id": "downloaded_1763553846_3"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "models and applications into these different domains.\u201dIndustry partners: Collaborating on AI\u2019s evolutionAt the core of the consortium\u2019s mission is collaboration \u2014 bringing MIT researchers and industry partners together to unlock generative AI\u2019s potential while ensuring its benefits are felt across society.Among the founding members is OpenAI, the creator of the generative AI chatbot ChatGPT.\u201cThis type of collaboration between academics, practitioners, and labs is key to ensuring that generative AI evolves in ways that meaningfully benefit society,\u201d says Anna Makanju, vice president of global impact at OpenAI, adding that OpenAI \u201cis eager to work alongside MIT\u2019s Generative AI Consortium to bridge the gap between cutting-edge AI research and the real-world expertise of diverse industries.\u201dThe Coca-Cola Co. recognizes an opportunity to leverage AI innovation on a global scale. \u201cWe see a tremendous opportunity to innovate at the speed of AI and, leveraging The Coca-Cola Company's global footprint, make these cutting-edge solutions accessible to everyone,\u201d says Pratik Thakar, global vice president and head of generative AI. \u201cBoth MIT and The Coca-Cola Company are deeply committed to innovation, while also placing equal emphasis on the legally and ethically responsible development and use of technology.\u201dFor TWG Global, the consortium offers the ideal environment to share knowledge and drive advancements. \u201cThe strength of the consortium is its unique combination of industry leaders and academia, which fosters the exchange of valuable lessons, technological advancements, and access to pioneering research,\u201d says Drew Cukor, head of data and artificial intelligence transformation. Cukor adds that TWG Global \u201cis keen to share its insights and actively engage",
    "chunk_id": "downloaded_1763553846_4"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "and academia, which fosters the exchange of valuable lessons, technological advancements, and access to pioneering research,\u201d says Drew Cukor, head of data and artificial intelligence transformation. Cukor adds that TWG Global \u201cis keen to share its insights and actively engage with leading executives and academics to gain a broader perspective of how others are configuring and adopting AI, which is why we believe in the work of the consortium.\u201dThe Tata Group views the collaboration as a platform to address some of AI\u2019s most pressing challenges. \u201cThe consortium enables Tata to collaborate, share knowledge, and collectively shape the future of generative AI, particularly in addressing urgent challenges such as ethical considerations, data privacy, and algorithmic biases,\u201d says Aparna Ganesh, vice president of Tata Sons Ltd.Similarly, SK Telecom sees its involvement as a launchpad for growth and innovation. Suk-geun (SG) Chung, SK Telecom executive vice president and chief AI global officer, explains, \u201cJoining the consortium presents a significant opportunity for SK Telecom to enhance its AI competitiveness in core business areas, including AI agents, AI semiconductors, data centers (AIDC), and physical AI,\u201d says Chung. \u201cBy collaborating with MIT and leveraging the SK AI R&D Center as a technology control tower, we aim to forecast next-generation generative AI technology trends, propose innovative business models, and drive commercialization through academic-industrial collaboration.\u201dAlan Lee, chief technology officer of Analog Devices (ADI), highlights how the consortium bridges key knowledge gaps for both his company and the industry at large. \u201cADI can\u2019t hire a world-leading expert in every single corner case, but the consortium",
    "chunk_id": "downloaded_1763553846_5"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "collaboration.\u201dAlan Lee, chief technology officer of Analog Devices (ADI), highlights how the consortium bridges key knowledge gaps for both his company and the industry at large. \u201cADI can\u2019t hire a world-leading expert in every single corner case, but the consortium will enable us to access top MIT researchers and get them involved in addressing problems we care about, as we also work together with others in the industry towards common goals,\u201d he says.The consortium will host interactive workshops and discussions to identify and prioritize challenges. \u201cIt\u2019s going to be a two-way conversation, with the faculty coming together with industry partners, but also industry partners talking with each other,\u201d says Georgia Perakis, the John C Head III Dean (Interim) of the MIT Sloan School of Management and professor of operations management, operations research and statistics, who serves alongside Huttenlocher as co-chair of the GenAI Dean\u2019s oversight group.Preparing for the AI-enabled workforce of the futureWith AI poised to disrupt industries and create new opportunities, one of the consortium\u2019s core goals is to guide that change in a way that benefits both businesses and society.\u201cWhen the first commercial digital computers were introduced [the UNIVAC was delivered to the U.S. Census Bureau in 1951], people were worried about losing their jobs,\u201d says Kraska. \u201cAnd yes, jobs like large-scale, manual data entry clerks and human \u2018computers,\u2019 people tasked with doing manual calculations, largely disappeared over time. But the people impacted by those first computers were trained to do other jobs.\u201dThe consortium aims to play a key role in preparing the workforce",
    "chunk_id": "downloaded_1763553846_6"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "entry clerks and human \u2018computers,\u2019 people tasked with doing manual calculations, largely disappeared over time. But the people impacted by those first computers were trained to do other jobs.\u201dThe consortium aims to play a key role in preparing the workforce of tomorrow by educating global business leaders and employees on generative AI evolving uses and applications. With the pace of innovation accelerating, leaders face a flood of information and uncertainty.\u201cWhen it comes to educating leaders about generative AI, it\u2019s about helping them navigate the complexity of the space right now, because there\u2019s so much hype and hundreds of papers published daily,\u201d says Kraska. \u201cThe hard part is understanding which developments could actually have a chance of changing the field and which are just tiny improvements. There's a kind of FOMO [fear of missing out] for leaders that we can help reduce.\u201dDefining success: Shared goals for generative AI impactSuccess within the initiative is defined by shared progress, open innovation, and mutual growth. \u201cConsortium participants recognize, I think, that when I share my ideas with you, and you share your ideas with me, we\u2019re both fundamentally better off,\u201d explains Farias. \u201cProgress on generative AI is not zero-sum, so it makes sense for this to be an open-source initiative.\u201dWhile participants may approach success from different angles, they share a common goal of advancing generative AI for broad societal benefit. \u201cThere will be many success metrics,\u201d says Perakis. \u201cWe\u2019ll educate students, who will be networking with companies. Companies will come together and learn from each other. Business leaders will come",
    "chunk_id": "downloaded_1763553846_7"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "common goal of advancing generative AI for broad societal benefit. \u201cThere will be many success metrics,\u201d says Perakis. \u201cWe\u2019ll educate students, who will be networking with companies. Companies will come together and learn from each other. Business leaders will come to MIT and have discussions that will help all of us, not just the leaders themselves.\u201dFor Analog Devices\u2019 Alan Lee, success is measured in tangible improvements that drive efficiency and product innovation: \u201cFor us at ADI, it\u2019s a better, faster quality of experience for our customers, and that could mean better products. It could mean faster design cycles, faster verification cycles, and faster tuning of equipment that we already have or that we\u2019re going to develop for the future. But beyond that, we want to help the world be a better, more efficient place.\u201dGanesh highlights success through the lens of real-world application. \u201cSuccess will also be defined by accelerating AI adoption within Tata companies, generating actionable knowledge that can be applied in real-world scenarios, and delivering significant advantages to our customers and stakeholders,\u201d she says.Generative AI is no longer confined to isolated research labs \u2014 it\u2019s driving innovation across industries and disciplines. At MIT, the technology has become a campus-wide priority, connecting researchers, students, and industry leaders to solve complex challenges and uncover new opportunities. \u201cIt's truly an MIT initiative,\u201d says Farias, \u201cone that\u2019s much larger than any individual or department on campus.\u201d Share this news article on: X Facebook LinkedIn Reddit Print Related Links MIT Generative AI Impact Consortium Related Topics Artificial intelligence Industry Collaboration",
    "chunk_id": "downloaded_1763553846_8"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "truly an MIT initiative,\u201d says Farias, \u201cone that\u2019s much larger than any individual or department on campus.\u201d Share this news article on: X Facebook LinkedIn Reddit Print Related Links MIT Generative AI Impact Consortium Related Topics Artificial intelligence Industry Collaboration Research Funding Computer science and technology Technology and society Open access Human-computer interaction Ethics Labor and jobs Privacy Open source Technology and policy Innovation and Entrepreneurship (I&E) Semiconductors Computer Science and Artificial Intelligence Laboratory (CSAIL) Electrical engineering and computer science (EECS) School of Architecture and Planning School of Engineering School of Science School of Humanities Arts and Social Sciences MIT Sloan School of Management MIT Schwarzman College of Computing Related Articles Explained: Generative AI\u2019s environmental impact What do we know about the economics of AI? President Sally Kornbluth and OpenAI CEO Sam Altman discuss the future of AI Stratospheric safety standards: How aviation could steer regulation of AI in health MIT Generative AI Week fosters dialogue across disciplines Previous item Next item More MIT News A new take on carbon capture Mantel, founded by MIT alumni, developed a system that captures CO2 from factories and power plants while delivering steam to customers. Read full story \u2192 New AI agent learns to use CAD to create 3D objects from sketches The virtual VideoCAD tool could boost designers\u2019 productivity and help train engineers learning computer-aided design. Read full story \u2192 An improved way to detach cells from culture surfaces The approach could transform large-scale biomanufacturing by enabling automated and contamination-conscious workflows for cell therapies, tissue engineering, and regenerative",
    "chunk_id": "downloaded_1763553846_9"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "productivity and help train engineers learning computer-aided design. Read full story \u2192 An improved way to detach cells from culture surfaces The approach could transform large-scale biomanufacturing by enabling automated and contamination-conscious workflows for cell therapies, tissue engineering, and regenerative medicine. Read full story \u2192 The science of consciousness Through the MIT Consciousness Club, professors Matthias Michel and Earl Miller are exploring how neurological activity gives rise to human experience. Read full story \u2192 MIT Energy Initiative conference spotlights research priorities amidst a changing energy landscape Industry leaders agree collaboration is key to advancing critical technologies. Read full story \u2192 Introducing the MIT-GE Vernova Climate and Energy Alliance Five-year collaboration between MIT and GE Vernova aims to accelerate the energy transition and scale new innovations. Read full story \u2192 More news on MIT News homepage \u2192 More about MIT News at Massachusetts Institute of Technology This website is managed by the MIT News Office, part of the Institute Office of Communications. News by Schools/College: School of Architecture and Planning School of Engineering School of Humanities, Arts, and Social Sciences MIT Sloan School of Management School of Science MIT Schwarzman College of Computing Resources: About the MIT News Office MIT News Press Center Terms of Use Press Inquiries Filming Guidelines RSS Feeds Tools: Subscribe to MIT Daily/Weekly Subscribe to press releases Submit campus news Guidelines for campus news contributors Guidelines on generative AI Massachusetts Institute of Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building",
    "chunk_id": "downloaded_1763553846_10"
  },
  {
    "doc": "downloaded_1763553846.txt",
    "chunk": "Subscribe to press releases Submit campus news Guidelines for campus news contributors Guidelines on generative AI Massachusetts Institute of Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building a better world. Massachusetts Institute of Technology77 Massachusetts Avenue, Cambridge, MA, USA Recommended Links: Visit Map (opens in new window) Events (opens in new window) People (opens in new window) Careers (opens in new window) Contact Privacy Accessibility Social Media Hub MIT on X MIT on Facebook MIT on YouTube MIT on Instagram",
    "chunk_id": "downloaded_1763553846_11"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "Source: https://news.mit.edu/2025/explained-generative-ai-environmental-impact-0117 Explained: Generative AI\u2019s environmental impact | MIT News | Massachusetts Institute of Technology Skip to content \u2193 Massachusetts Institute of Technology MIT Top Menu\u2193 Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT More \u2193 Search MIT Search websites, locations, and people See More Results Suggestions or feedback? MIT News | Massachusetts Institute of Technology - On Campus and Around the world Subscribe to MIT News newsletter Browse Enter keywords to search for news articles: Submit Browse By Topics View All \u2192 Explore: Machine learning Sustainability Startups Black holes Classes and programs Departments View All \u2192 Explore: Aeronautics and Astronautics Brain and Cognitive Sciences Architecture Political Science Mechanical Engineering Centers, Labs, & Programs View All \u2192 Explore: Abdul Latif Jameel Poverty Action Lab (J-PAL) Picower Institute for Learning and Memory Media Lab Lincoln Laboratory Schools School of Architecture + Planning School of Engineering School of Humanities, Arts, and Social Sciences Sloan School of Management School of Science MIT Schwarzman College of Computing View all news coverage of MIT in the media \u2192 Listen to audio content from MIT News \u2192 Subscribe to MIT newsletter \u2192 Close Breadcrumb MIT News Explained: Generative AI\u2019s environmental impact Explained: Generative AI\u2019s environmental impact Rapid development and deployment of powerful generative AI models comes with environmental consequences, including increased electricity demand and water consumption. Adam Zewe | MIT News Publication Date: January 17, 2025 Press Inquiries Press Contact: Melanie Grados Email: mgrados@mit.edu Phone: 617-253-1682 MIT News Office Media Download \u2193 Download Image Caption: MIT News explores",
    "chunk_id": "downloaded_1763553849_0"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "consequences, including increased electricity demand and water consumption. Adam Zewe | MIT News Publication Date: January 17, 2025 Press Inquiries Press Contact: Melanie Grados Email: mgrados@mit.edu Phone: 617-253-1682 MIT News Office Media Download \u2193 Download Image Caption: MIT News explores the environmental and sustainability implications of generative AI technologies and applications. Credits: Image: iStock; edited by MIT News *Terms of Use: Images for download on the MIT News office website are made available to non-commercial entities, press and the general public under a Creative Commons Attribution Non-Commercial No Derivatives license. You may not alter the images provided, other than to crop them to size. A credit line must be used when reproducing images; if one is not provided below, credit the images to \"MIT.\" Close Caption: MIT News explores the environmental and sustainability implications of generative AI technologies and applications. Credits: Image: iStock; edited by MIT News Previous image Next image In a two-part series, MIT News explores the environmental implications of generative AI. In this article, we look at why this technology is so resource-intensive. A second piece will investigate what experts are doing to reduce genAI\u2019s carbon footprint and other impacts.The excitement surrounding potential benefits of generative AI, from improving worker productivity to advancing scientific research, is hard to ignore. While the explosive growth of this new technology has enabled rapid deployment of powerful models in many industries, the environmental consequences of this generative AI \u201cgold rush\u201d remain difficult to pin down, let alone mitigate.The computational power required to train generative AI models that",
    "chunk_id": "downloaded_1763553849_1"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "of this new technology has enabled rapid deployment of powerful models in many industries, the environmental consequences of this generative AI \u201cgold rush\u201d remain difficult to pin down, let alone mitigate.The computational power required to train generative AI models that often have billions of parameters, such as OpenAI\u2019s GPT-4, can demand a staggering amount of electricity, which leads to increased carbon dioxide emissions and pressures on the electric grid.Furthermore, deploying these models in real-world applications, enabling millions to use generative AI in their daily lives, and then fine-tuning the models to improve their performance draws large amounts of energy long after a model has been developed.Beyond electricity demands, a great deal of water is needed to cool the hardware used for training, deploying, and fine-tuning generative AI models, which can strain municipal water supplies and disrupt local ecosystems. The increasing number of generative AI applications has also spurred demand for high-performance computing hardware, adding indirect environmental impacts from its manufacture and transport.\u201cWhen we think about the environmental impact of generative AI, it is not just the electricity you consume when you plug the computer in. There are much broader consequences that go out to a system level and persist based on actions that we take,\u201d says Elsa A. Olivetti, professor in the Department of Materials Science and Engineering and the lead of the Decarbonization Mission of MIT\u2019s new Climate Project.Olivetti is senior author of a 2024 paper, \u201cThe Climate and Sustainability Implications of Generative AI,\u201d co-authored by MIT colleagues in response to an Institute-wide call for",
    "chunk_id": "downloaded_1763553849_2"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "and Engineering and the lead of the Decarbonization Mission of MIT\u2019s new Climate Project.Olivetti is senior author of a 2024 paper, \u201cThe Climate and Sustainability Implications of Generative AI,\u201d co-authored by MIT colleagues in response to an Institute-wide call for papers that explore the transformative potential of generative AI, in both positive and negative directions for society.Demanding data centersThe electricity demands of data centers are one major factor contributing to the environmental impacts of generative AI, since data centers are used to train and run the deep learning models behind popular tools like ChatGPT and DALL-E.A data center is a temperature-controlled building that houses computing infrastructure, such as servers, data storage drives, and network equipment. For instance, Amazon has more than 100 data centers worldwide, each of which has about 50,000 servers that the company uses to support cloud computing services.While data centers have been around since the 1940s (the first was built at the University of Pennsylvania in 1945 to support the first general-purpose digital computer, the ENIAC), the rise of generative AI has dramatically increased the pace of data center construction.\u201cWhat is different about generative AI is the power density it requires. Fundamentally, it is just computing, but a generative AI training cluster might consume seven or eight times more energy than a typical computing workload,\u201d says Noman Bashir, lead author of the impact paper, who is a Computing and Climate Impact Fellow at MIT Climate and Sustainability Consortium (MCSC) and a postdoc in the Computer Science and Artificial Intelligence Laboratory (CSAIL).Scientists have estimated",
    "chunk_id": "downloaded_1763553849_3"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "computing workload,\u201d says Noman Bashir, lead author of the impact paper, who is a Computing and Climate Impact Fellow at MIT Climate and Sustainability Consortium (MCSC) and a postdoc in the Computer Science and Artificial Intelligence Laboratory (CSAIL).Scientists have estimated that the power requirements of data centers in North America increased from 2,688 megawatts at the end of 2022 to 5,341 megawatts at the end of 2023, partly driven by the demands of generative AI. Globally, the electricity consumption of data centers rose to 460 terawatt-hours in 2022. This would have made data centers the 11th largest electricity consumer in the world, between the nations of Saudi Arabia (371 terawatt-hours) and France (463 terawatt-hours), according to the Organization for Economic Co-operation and Development.By 2026, the electricity consumption of data centers is expected to approach 1,050 terawatt-hours (which would bump data centers up to fifth place on the global list, between Japan and Russia).While not all data center computation involves generative AI, the technology has been a major driver of increasing energy demands.\u201cThe demand for new data centers cannot be met in a sustainable way. The pace at which companies are building new data centers means the bulk of the electricity to power them must come from fossil fuel-based power plants,\u201d says Bashir.The power needed to train and deploy a model like OpenAI\u2019s GPT-3 is difficult to ascertain. In a 2021 research paper, scientists from Google and the University of California at Berkeley estimated the training process alone consumed 1,287 megawatt hours of electricity (enough to power",
    "chunk_id": "downloaded_1763553849_4"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "and deploy a model like OpenAI\u2019s GPT-3 is difficult to ascertain. In a 2021 research paper, scientists from Google and the University of California at Berkeley estimated the training process alone consumed 1,287 megawatt hours of electricity (enough to power about 120 average U.S. homes for a year), generating about 552 tons of carbon dioxide.While all machine-learning models must be trained, one issue unique to generative AI is the rapid fluctuations in energy use that occur over different phases of the training process, Bashir explains.Power grid operators must have a way to absorb those fluctuations to protect the grid, and they usually employ diesel-based generators for that task.Increasing impacts from inferenceOnce a generative AI model is trained, the energy demands don\u2019t disappear.Each time a model is used, perhaps by an individual asking ChatGPT to summarize an email, the computing hardware that performs those operations consumes energy. Researchers have estimated that a ChatGPT query consumes about five times more electricity than a simple web search.\u201cBut an everyday user doesn\u2019t think too much about that,\u201d says Bashir. \u201cThe ease-of-use of generative AI interfaces and the lack of information about the environmental impacts of my actions means that, as a user, I don\u2019t have much incentive to cut back on my use of generative AI.\u201dWith traditional AI, the energy usage is split fairly evenly between data processing, model training, and inference, which is the process of using a trained model to make predictions on new data. However, Bashir expects the electricity demands of generative AI inference to eventually dominate",
    "chunk_id": "downloaded_1763553849_5"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "usage is split fairly evenly between data processing, model training, and inference, which is the process of using a trained model to make predictions on new data. However, Bashir expects the electricity demands of generative AI inference to eventually dominate since these models are becoming ubiquitous in so many applications, and the electricity needed for inference will increase as future versions of the models become larger and more complex.Plus, generative AI models have an especially short shelf-life, driven by rising demand for new AI applications. Companies release new models every few weeks, so the energy used to train prior versions goes to waste, Bashir adds. New models often consume more energy for training, since they usually have more parameters than their predecessors.While electricity demands of data centers may be getting the most attention in research literature, the amount of water consumed by these facilities has environmental impacts, as well.Chilled water is used to cool a data center by absorbing heat from computing equipment. It has been estimated that, for each kilowatt hour of energy a data center consumes, it would need two liters of water for cooling, says Bashir.\u201cJust because this is called \u2018cloud computing\u2019 doesn\u2019t mean the hardware lives in the cloud. Data centers are present in our physical world, and because of their water usage they have direct and indirect implications for biodiversity,\u201d he says.The computing hardware inside data centers brings its own, less direct environmental impacts.While it is difficult to estimate how much power is needed to manufacture a GPU, a type of",
    "chunk_id": "downloaded_1763553849_6"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "usage they have direct and indirect implications for biodiversity,\u201d he says.The computing hardware inside data centers brings its own, less direct environmental impacts.While it is difficult to estimate how much power is needed to manufacture a GPU, a type of powerful processor that can handle intensive generative AI workloads, it would be more than what is needed to produce a simpler CPU because the fabrication process is more complex. A GPU\u2019s carbon footprint is compounded by the emissions related to material and product transport.There are also environmental implications of obtaining the raw materials used to fabricate GPUs, which can involve dirty mining procedures and the use of toxic chemicals for processing.Market research firm TechInsights estimates that the three major producers (NVIDIA, AMD, and Intel) shipped 3.85 million GPUs to data centers in 2023, up from about 2.67 million in 2022. That number is expected to have increased by an even greater percentage in 2024.The industry is on an unsustainable path, but there are ways to encourage responsible development of generative AI that supports environmental objectives, Bashir says.He, Olivetti, and their MIT colleagues argue that this will require a comprehensive consideration of all the environmental and societal costs of generative AI, as well as a detailed assessment of the value in its perceived benefits.\u201cWe need a more contextual way of systematically and comprehensively understanding the implications of new developments in this space. Due to the speed at which there have been improvements, we haven\u2019t had a chance to catch up with our abilities to measure and understand",
    "chunk_id": "downloaded_1763553849_7"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "contextual way of systematically and comprehensively understanding the implications of new developments in this space. Due to the speed at which there have been improvements, we haven\u2019t had a chance to catch up with our abilities to measure and understand the tradeoffs,\u201d Olivetti says. Share this news article on: X Facebook LinkedIn Reddit Print Press Mentions WiredNoman Bashir, a fellow with the MIT Climate and Sustainability Consortium and a postdoc at CSAIL, speaks with Wired reporter Molly Taft about AI and energy consumption. Bashir explains that how quickly a model answers a question has a big impact on its energy use. \u201cThe goal is to provide all of this inference the quickest way possible so that you don\u2019t leave their platform,\u201d Bashir says. \u201cIf ChatGPT suddenly starts giving you a response after five minutes, you will go to some other tool that is giving you an immediate response.\u201d Full story via Wired \u2192 Previous item Next item Related Links Noman BashirElsa OlivettiMIT Climate and Sustainability ConsortiumComputer Science and Artificial Intelligence LaboratoryDepartment of Electrical Engineering and Computer ScienceDepartment of Materials Science and EngineeringSchool of EngineeringMIT Schwarzman College of Computing Related Topics Sustainable computing Artificial intelligence Machine learning Algorithms Human-computer interaction Data Energy Environment Emissions Sustainability Cleaner industry Water Computer science and technology Climate Computer Science and Artificial Intelligence Laboratory (CSAIL) Electrical engineering and computer science (EECS) DMSE School of Engineering MIT Schwarzman College of Computing Related Articles Q&A: The climate impact of generative AI Liftoff: The Climate Project at MIT takes flight New solar projects will grow",
    "chunk_id": "downloaded_1763553849_8"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "Intelligence Laboratory (CSAIL) Electrical engineering and computer science (EECS) DMSE School of Engineering MIT Schwarzman College of Computing Related Articles Q&A: The climate impact of generative AI Liftoff: The Climate Project at MIT takes flight New solar projects will grow renewable energy generation for four major campus buildings 3 Questions: Can we secure a sustainable supply of nickel? Explained: Generative AI Previous item Next item More MIT News A new take on carbon capture Mantel, founded by MIT alumni, developed a system that captures CO2 from factories and power plants while delivering steam to customers. Read full story \u2192 New AI agent learns to use CAD to create 3D objects from sketches The virtual VideoCAD tool could boost designers\u2019 productivity and help train engineers learning computer-aided design. Read full story \u2192 An improved way to detach cells from culture surfaces The approach could transform large-scale biomanufacturing by enabling automated and contamination-conscious workflows for cell therapies, tissue engineering, and regenerative medicine. Read full story \u2192 The science of consciousness Through the MIT Consciousness Club, professors Matthias Michel and Earl Miller are exploring how neurological activity gives rise to human experience. Read full story \u2192 MIT Energy Initiative conference spotlights research priorities amidst a changing energy landscape Industry leaders agree collaboration is key to advancing critical technologies. Read full story \u2192 Introducing the MIT-GE Vernova Climate and Energy Alliance Five-year collaboration between MIT and GE Vernova aims to accelerate the energy transition and scale new innovations. Read full story \u2192 More news on MIT News homepage \u2192 More",
    "chunk_id": "downloaded_1763553849_9"
  },
  {
    "doc": "downloaded_1763553849.txt",
    "chunk": "full story \u2192 Introducing the MIT-GE Vernova Climate and Energy Alliance Five-year collaboration between MIT and GE Vernova aims to accelerate the energy transition and scale new innovations. Read full story \u2192 More news on MIT News homepage \u2192 More about MIT News at Massachusetts Institute of Technology This website is managed by the MIT News Office, part of the Institute Office of Communications. News by Schools/College: School of Architecture and Planning School of Engineering School of Humanities, Arts, and Social Sciences MIT Sloan School of Management School of Science MIT Schwarzman College of Computing Resources: About the MIT News Office MIT News Press Center Terms of Use Press Inquiries Filming Guidelines RSS Feeds Tools: Subscribe to MIT Daily/Weekly Subscribe to press releases Submit campus news Guidelines for campus news contributors Guidelines on generative AI Massachusetts Institute of Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building a better world. Massachusetts Institute of Technology77 Massachusetts Avenue, Cambridge, MA, USA Recommended Links: Visit Map (opens in new window) Events (opens in new window) People (opens in new window) Careers (opens in new window) Contact Privacy Accessibility Social Media Hub MIT on X MIT on Facebook MIT on YouTube MIT on Instagram",
    "chunk_id": "downloaded_1763553849_10"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "Source: https://news.mit.edu/2025/responding-to-generative-ai-climate-impact-0930 Responding to the climate impact of generative AI | MIT News | Massachusetts Institute of Technology Skip to content \u2193 Massachusetts Institute of Technology MIT Top Menu\u2193 Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT More \u2193 Search MIT Search websites, locations, and people See More Results Suggestions or feedback? MIT News | Massachusetts Institute of Technology - On Campus and Around the world Subscribe to MIT News newsletter Browse Enter keywords to search for news articles: Submit Browse By Topics View All \u2192 Explore: Machine learning Sustainability Startups Black holes Classes and programs Departments View All \u2192 Explore: Aeronautics and Astronautics Brain and Cognitive Sciences Architecture Political Science Mechanical Engineering Centers, Labs, & Programs View All \u2192 Explore: Abdul Latif Jameel Poverty Action Lab (J-PAL) Picower Institute for Learning and Memory Media Lab Lincoln Laboratory Schools School of Architecture + Planning School of Engineering School of Humanities, Arts, and Social Sciences Sloan School of Management School of Science MIT Schwarzman College of Computing View all news coverage of MIT in the media \u2192 Listen to audio content from MIT News \u2192 Subscribe to MIT newsletter \u2192 Close Breadcrumb MIT News Responding to the climate impact of generative AI Responding to the climate impact of generative AI Explosive growth of AI data centers is expected to increase greenhouse gas emissions. Researchers are now seeking solutions to reduce these environmental harms. Adam Zewe | MIT News Publication Date: September 30, 2025 Press Inquiries Press Contact: MIT Media Relations Email: expertrequests@mit.edu Phone:",
    "chunk_id": "downloaded_1763553852_0"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "AI data centers is expected to increase greenhouse gas emissions. Researchers are now seeking solutions to reduce these environmental harms. Adam Zewe | MIT News Publication Date: September 30, 2025 Press Inquiries Press Contact: MIT Media Relations Email: expertrequests@mit.edu Phone: 617-253-2700 Close Caption: \u201cWe are on a path where the effects of climate change won\u2019t be fully known until it is too late to do anything about it,\u201d says Jennifer Turliuk MBA \u201925, who is working to help policymakers, scientists, and enterprises consider the multifaceted costs and benefits of generative AI. \u201cThis is a once-in-a-lifetime opportunity to innovate and make AI systems less carbon-intense.\u201d Credits: Credit: iStock Previous image Next image Audio In part 2 of our two-part series on generative artificial intelligence\u2019s environmental impacts, MIT News explores some of the ways experts are working to reduce the technology\u2019s carbon footprint.The energy demands of generative AI are expected to continue increasing dramatically over the next decade.For instance, an April 2025 report from the International Energy Agency predicts that the global electricity demand from data centers, which house the computing infrastructure to train and deploy AI models, will more than double by 2030, to around 945 terawatt-hours. While not all operations performed in a data center are AI-related, this total amount is slightly more than the energy consumption of Japan.Moreover, an August 2025 analysis from Goldman Sachs Research forecasts that about 60 percent of the increasing electricity demands from data centers will be met by burning fossil fuels, increasing global carbon emissions by about 220 million tons.",
    "chunk_id": "downloaded_1763553852_1"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "consumption of Japan.Moreover, an August 2025 analysis from Goldman Sachs Research forecasts that about 60 percent of the increasing electricity demands from data centers will be met by burning fossil fuels, increasing global carbon emissions by about 220 million tons. In comparison, driving a gas-powered car for 5,000 miles produces about 1 ton of carbon dioxide.These statistics are staggering, but at the same time, scientists and engineers at MIT and around the world are studying innovations and interventions to mitigate AI\u2019s ballooning carbon footprint, from boosting the efficiency of algorithms to rethinking the design of data centers.Considering carbon emissionsTalk of reducing generative AI\u2019s carbon footprint is typically centered on \u201coperational carbon\u201d \u2014 the emissions used by the powerful processors, known as GPUs, inside a data center. It often ignores \u201cembodied carbon,\u201d which are emissions created by building the data center in the first place, says Vijay Gadepally, senior scientist at MIT Lincoln Laboratory, who leads research projects in the Lincoln Laboratory Supercomputing Center.Constructing and retrofitting a data center, built from tons of steel and concrete and filled with air conditioning units, computing hardware, and miles of cable, consumes a huge amount of carbon. In fact, the environmental impact of building data centers is one reason companies like Meta and Google are exploring more sustainable building materials. (Cost is another factor.)Plus, data centers are enormous buildings \u2014 the world\u2019s largest, the China Telecomm-Inner Mongolia Information Park, engulfs roughly 10 million square feet \u2014 with about 10 to 50 times the energy density of a normal office building,",
    "chunk_id": "downloaded_1763553852_2"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "(Cost is another factor.)Plus, data centers are enormous buildings \u2014 the world\u2019s largest, the China Telecomm-Inner Mongolia Information Park, engulfs roughly 10 million square feet \u2014 with about 10 to 50 times the energy density of a normal office building, Gadepally adds. \u201cThe operational side is only part of the story. Some things we are working on to reduce operational emissions may lend themselves to reducing embodied carbon, too, but we need to do more on that front in the future,\u201d he says.Reducing operational carbon emissionsWhen it comes to reducing operational carbon emissions of AI data centers, there are many parallels with home energy-saving measures. For one, we can simply turn down the lights.\u201cEven if you have the worst lightbulbs in your house from an efficiency standpoint, turning them off or dimming them will always use less energy than leaving them running at full blast,\u201d Gadepally says.In the same fashion, research from the Supercomputing Center has shown that \u201cturning down\u201d the GPUs in a data center so they consume about three-tenths the energy has minimal impacts on the performance of AI models, while also making the hardware easier to cool.Another strategy is to use less energy-intensive computing hardware.Demanding generative AI workloads, such as training new reasoning models like GPT-5, usually need many GPUs working simultaneously. The Goldman Sachs analysis estimates that a state-of-the-art system could soon have as many as 576 connected GPUs operating at once.But engineers can sometimes achieve similar results by reducing the precision of computing hardware, perhaps by switching to less powerful processors",
    "chunk_id": "downloaded_1763553852_3"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "Goldman Sachs analysis estimates that a state-of-the-art system could soon have as many as 576 connected GPUs operating at once.But engineers can sometimes achieve similar results by reducing the precision of computing hardware, perhaps by switching to less powerful processors that have been tuned to handle a specific AI workload.There are also measures that boost the efficiency of training power-hungry deep-learning models before they are deployed.Gadepally\u2019s group found that about half the electricity used for training an AI model is spent to get the last 2 or 3 percentage points in accuracy. Stopping the training process early can save a lot of that energy.\u201cThere might be cases where 70 percent accuracy is good enough for one particular application, like a recommender system for e-commerce,\u201d he says.Researchers can also take advantage of efficiency-boosting measures.For instance, a postdoc in the Supercomputing Center realized the group might run a thousand simulations during the training process to pick the two or three best AI models for their project.By building a tool that allowed them to avoid about 80 percent of those wasted computing cycles, they dramatically reduced the energy demands of training with no reduction in model accuracy, Gadepally says.Leveraging efficiency improvementsConstant innovation in computing hardware, such as denser arrays of transistors on semiconductor chips, is still enabling dramatic improvements in the energy efficiency of AI models.Even though energy efficiency improvements have been slowing for most chips since about 2005, the amount of computation that GPUs can do per joule of energy has been improving by 50 to 60 percent",
    "chunk_id": "downloaded_1763553852_4"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "in the energy efficiency of AI models.Even though energy efficiency improvements have been slowing for most chips since about 2005, the amount of computation that GPUs can do per joule of energy has been improving by 50 to 60 percent each year, says Neil Thompson, director of the FutureTech Research Project at MIT\u2019s Computer Science and Artificial Intelligence Laboratory and a principal investigator at MIT\u2019s Initiative on the Digital Economy.\u201cThe still-ongoing \u2018Moore\u2019s Law\u2019 trend of getting more and more transistors on chip still matters for a lot of these AI systems, since running operations in parallel is still very valuable for improving efficiency,\u201d says Thomspon.Even more significant, his group\u2019s research indicates that efficiency gains from new model architectures that can solve complex problems faster, consuming less energy to achieve the same or better results, is doubling every eight or nine months.Thompson coined the term \u201cnegaflop\u201d to describe this effect. The same way a \u201cnegawatt\u201d represents electricity saved due to energy-saving measures, a \u201cnegaflop\u201d is a computing operation that doesn\u2019t need to be performed due to algorithmic improvements.These could be things like \u201cpruning\u201d away unnecessary components of a neural network or employing compression techniques that enable users to do more with less computation.\u201cIf you need to use a really powerful model today to complete your task, in just a few years, you might be able to use a significantly smaller model to do the same thing, which would carry much less environmental burden. Making these models more efficient is the single-most important thing you can do to",
    "chunk_id": "downloaded_1763553852_5"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "just a few years, you might be able to use a significantly smaller model to do the same thing, which would carry much less environmental burden. Making these models more efficient is the single-most important thing you can do to reduce the environmental costs of AI,\u201d Thompson says.Maximizing energy savingsWhile reducing the overall energy use of AI algorithms and computing hardware will cut greenhouse gas emissions, not all energy is the same, Gadepally adds.\u201cThe amount of carbon emissions in 1 kilowatt hour varies quite significantly, even just during the day, as well as over the month and year,\u201d he says.Engineers can take advantage of these variations by leveraging the flexibility of AI workloads and data center operations to maximize emissions reductions. For instance, some generative AI workloads don\u2019t need to be performed in their entirety at the same time.Splitting computing operations so some are performed later, when more of the electricity fed into the grid is from renewable sources like solar and wind, can go a long way toward reducing a data center\u2019s carbon footprint, says Deepjyoti Deka, a research scientist in the MIT Energy Initiative.Deka and his team are also studying \u201csmarter\u201d data centers where the AI workloads of multiple companies using the same computing equipment are flexibly adjusted to improve energy efficiency.\u201cBy looking at the system as a whole, our hope is to minimize energy use as well as dependence on fossil fuels, while still maintaining reliability standards for AI companies and users,\u201d Deka says.He and others at MITEI are building a flexibility model",
    "chunk_id": "downloaded_1763553852_6"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "the system as a whole, our hope is to minimize energy use as well as dependence on fossil fuels, while still maintaining reliability standards for AI companies and users,\u201d Deka says.He and others at MITEI are building a flexibility model of a data center that considers the differing energy demands of training a deep-learning model versus deploying that model. Their hope is to uncover the best strategies for scheduling and streamlining computing operations to improve energy efficiency.The researchers are also exploring the use of long-duration energy storage units at data centers, which store excess energy for times when it is needed.With these systems in place, a data center could use stored energy that was generated by renewable sources during a high-demand period, or avoid the use of diesel backup generators if there are fluctuations in the grid.\u201cLong-duration energy storage could be a game-changer here because we can design operations that really change the emission mix of the system to rely more on renewable energy,\u201d Deka says.In addition, researchers at MIT and Princeton University are developing a software tool for investment planning in the power sector, called GenX, which could be used to help companies determine the ideal place to locate a data center to minimize environmental impacts and costs.Location can have a big impact on reducing a data center\u2019s carbon footprint. For instance, Meta operates a data center in Lulea, a city on the coast of northern Sweden where cooler temperatures reduce the amount of electricity needed to cool computing hardware.Thinking farther outside the box (way",
    "chunk_id": "downloaded_1763553852_7"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "a data center\u2019s carbon footprint. For instance, Meta operates a data center in Lulea, a city on the coast of northern Sweden where cooler temperatures reduce the amount of electricity needed to cool computing hardware.Thinking farther outside the box (way farther), some governments are even exploring the construction of data centers on the moon where they could potentially be operated with nearly all renewable energy.AI-based solutionsCurrently, the expansion of renewable energy generation here on Earth isn\u2019t keeping pace with the rapid growth of AI, which is one major roadblock to reducing its carbon footprint, says Jennifer Turliuk MBA \u201925, a short-term lecturer, former Sloan Fellow, and former practice leader of climate and energy AI at the Martin Trust Center for MIT Entrepreneurship.The local, state, and federal review processes required for a new renewable energy projects can take years.Researchers at MIT and elsewhere are exploring the use of AI to speed up the process of connecting new renewable energy systems to the power grid.For instance, a generative AI model could streamline interconnection studies that determine how a new project will impact the power grid, a step that often takes years to complete.And when it comes to accelerating the development and implementation of clean energy technologies, AI could play a major role.\u201cMachine learning is great for tackling complex situations, and the electrical grid is said to be one of the largest and most complex machines in the world,\u201d Turliuk adds.For instance, AI could help optimize the prediction of solar and wind energy generation or identify ideal locations for",
    "chunk_id": "downloaded_1763553852_8"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "situations, and the electrical grid is said to be one of the largest and most complex machines in the world,\u201d Turliuk adds.For instance, AI could help optimize the prediction of solar and wind energy generation or identify ideal locations for new facilities.It could also be used to perform predictive maintenance and fault detection for solar panels or other green energy infrastructure, or to monitor the capacity of transmission wires to maximize efficiency.By helping researchers gather and analyze huge amounts of data, AI could also inform targeted policy interventions aimed at getting the biggest \u201cbang for the buck\u201d from areas such as renewable energy, Turliuk says.To help policymakers, scientists, and enterprises consider the multifaceted costs and benefits of AI systems, she and her collaborators developed the Net Climate Impact Score.The score is a framework that can be used to help determine the net climate impact of AI projects, considering emissions and other environmental costs along with potential environmental benefits in the future.At the end of the day, the most effective solutions will likely result from collaborations among companies, regulators, and researchers, with academia leading the way, Turliuk adds.\u201cEvery day counts. We are on a path where the effects of climate change won\u2019t be fully known until it is too late to do anything about it. This is a once-in-a-lifetime opportunity to innovate and make AI systems less carbon-intense,\u201d she says. Share this news article on: X Facebook LinkedIn Reddit Print Related Links Deepjyoti DekaVijay GadepallyNeil ThompsonJennifer TurliukMIT Energy InitiativeLincoln LaboratoryComputer Science and Artificial Intelligence LaboratoryDepartment of Electrical",
    "chunk_id": "downloaded_1763553852_9"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "a once-in-a-lifetime opportunity to innovate and make AI systems less carbon-intense,\u201d she says. Share this news article on: X Facebook LinkedIn Reddit Print Related Links Deepjyoti DekaVijay GadepallyNeil ThompsonJennifer TurliukMIT Energy InitiativeLincoln LaboratoryComputer Science and Artificial Intelligence LaboratoryDepartment of Electrical Engineering and Computer ScienceSchool of EngineeringMIT Sloan School of ManagementMIT Schwarzman College of Computing Related Topics Sustainable computing Research Computer science and technology Artificial intelligence Machine learning Algorithms Energy Climate change Supercomputing Energy storage Emissions Infrastructure Electrical engineering and computer science (EECS) MIT Energy Initiative Lincoln Laboratory Computer Science and Artificial Intelligence Laboratory (CSAIL) School of Engineering MIT Sloan School of Management MIT Schwarzman College of Computing Related Articles Responding to the climate impact of generative AI Explained: Generative AI\u2019s environmental impact Confronting the AI/energy conundrum The multifaceted challenge of powering AI Q&A: The climate impact of generative AI Previous item Next item More MIT News A new take on carbon capture Mantel, founded by MIT alumni, developed a system that captures CO2 from factories and power plants while delivering steam to customers. Read full story \u2192 New AI agent learns to use CAD to create 3D objects from sketches The virtual VideoCAD tool could boost designers\u2019 productivity and help train engineers learning computer-aided design. Read full story \u2192 An improved way to detach cells from culture surfaces The approach could transform large-scale biomanufacturing by enabling automated and contamination-conscious workflows for cell therapies, tissue engineering, and regenerative medicine. Read full story \u2192 The science of consciousness Through the MIT Consciousness Club, professors Matthias Michel and Earl",
    "chunk_id": "downloaded_1763553852_10"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "culture surfaces The approach could transform large-scale biomanufacturing by enabling automated and contamination-conscious workflows for cell therapies, tissue engineering, and regenerative medicine. Read full story \u2192 The science of consciousness Through the MIT Consciousness Club, professors Matthias Michel and Earl Miller are exploring how neurological activity gives rise to human experience. Read full story \u2192 MIT Energy Initiative conference spotlights research priorities amidst a changing energy landscape Industry leaders agree collaboration is key to advancing critical technologies. Read full story \u2192 Introducing the MIT-GE Vernova Climate and Energy Alliance Five-year collaboration between MIT and GE Vernova aims to accelerate the energy transition and scale new innovations. Read full story \u2192 More news on MIT News homepage \u2192 More about MIT News at Massachusetts Institute of Technology This website is managed by the MIT News Office, part of the Institute Office of Communications. News by Schools/College: School of Architecture and Planning School of Engineering School of Humanities, Arts, and Social Sciences MIT Sloan School of Management School of Science MIT Schwarzman College of Computing Resources: About the MIT News Office MIT News Press Center Terms of Use Press Inquiries Filming Guidelines RSS Feeds Tools: Subscribe to MIT Daily/Weekly Subscribe to press releases Submit campus news Guidelines for campus news contributors Guidelines on generative AI Massachusetts Institute of Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building a better world. Massachusetts Institute of Technology77 Massachusetts Avenue, Cambridge, MA, USA Recommended Links: Visit Map (opens in new",
    "chunk_id": "downloaded_1763553852_11"
  },
  {
    "doc": "downloaded_1763553852.txt",
    "chunk": "Technology MIT Top Level Links: Education Research Innovation Admissions + Aid Campus Life News Alumni About MIT Join us in building a better world. Massachusetts Institute of Technology77 Massachusetts Avenue, Cambridge, MA, USA Recommended Links: Visit Map (opens in new window) Events (opens in new window) People (opens in new window) Careers (opens in new window) Contact Privacy Accessibility Social Media Hub MIT on X MIT on Facebook MIT on YouTube MIT on Instagram",
    "chunk_id": "downloaded_1763553852_12"
  },
  {
    "doc": "downloaded_1763553881.txt",
    "chunk": "Source: https://www.imf.org/en/blogs/articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity AI Will Transform the Global Economy. Let\u2019s Make Sure It Benefits Humanity.Chart of the WeekRegionsTopicsAuthorsArchiveIMF HomeCredit X-poser/Adobe StockCredit X-poser/Adobe StockEnglish\u0627\u0644\u0639\u0631\u0628\u064a\u0629\u4e2d\u6587espa\u00f1ol\u0440\u0443\u0441\u0441\u043a\u0438\u0439\u65e5\u672c\u8a9efran\u00e7aisArtificial intelligenceAI Will Transform the Global Economy. Let\u2019s Make Sure It Benefits Humanity.AI will affect almost 40 percent of jobs around the world, replacing some and complementing others. We need a careful balance of policies to tap its potentialKristalina GeorgievaJanuary 14, 2024 We are on the brink of a technological revolution that could jumpstart productivity, boost global growth and raise incomes around the world. Yet it could also replace jobs and deepen inequality. The rapid advance of artificial intelligence has captivated the world, causing both excitement and alarm, and raising important questions about its potential impact on the global economy. The net effect is difficult to foresee, as AI will ripple through economies in complex ways. What we can say with some confidence is that we will need to come up with a set of policies to safely leverage the vast potential of AI for the benefit of humanity. Reshaping the Nature of Work In a new analysis, IMF staff examine the potential impact of AI on the global labor market. Many studies have predicted the likelihood that jobs will be replaced by AI. Yet we know that in many cases AI is likely to complement human work. The IMF analysis captures both these forces. The findings are striking: almost 40 percent of global employment is exposed to AI. Historically, automation and information technology have tended to affect routine tasks, but one of the things",
    "chunk_id": "downloaded_1763553881_0"
  },
  {
    "doc": "downloaded_1763553881.txt",
    "chunk": "complement human work. The IMF analysis captures both these forces. The findings are striking: almost 40 percent of global employment is exposed to AI. Historically, automation and information technology have tended to affect routine tasks, but one of the things that sets AI apart is its ability to impact high-skilled jobs. As a result, advanced economies face greater risks from AI\u2014but also more opportunities to leverage its benefits\u2014compared with emerging market and developing economies. In advanced economies, about 60 percent of jobs may be impacted by AI. Roughly half the exposed jobs may benefit from AI integration, enhancing productivity. For the other half, AI applications may execute key tasks currently performed by humans, which could lower labor demand, leading to lower wages and reduced hiring. In the most extreme cases, some of these jobs may disappear. In emerging markets and low-income countries, by contrast, AI exposure is expected to be 40 percent and 26 percent, respectively. These findings suggest emerging market and developing economies face fewer immediate disruptions from AI. At the same time, many of these countries don\u2019t have the infrastructure or skilled workforces to harness the benefits of AI, raising the risk that over time the technology could worsen inequality among nations. AI could also affect income and wealth inequality within countries. We may see polarization within income brackets, with workers who can harness AI seeing an increase in their productivity and wages\u2014and those who cannot falling behind. Research shows that AI can help less experienced workers enhance their productivity more quickly. Younger workers",
    "chunk_id": "downloaded_1763553881_1"
  },
  {
    "doc": "downloaded_1763553881.txt",
    "chunk": "see polarization within income brackets, with workers who can harness AI seeing an increase in their productivity and wages\u2014and those who cannot falling behind. Research shows that AI can help less experienced workers enhance their productivity more quickly. Younger workers may find it easier to exploit opportunities, while older workers could struggle to adapt. The effect on labor income will largely depend on the extent to which AI will complement high-income workers. If AI significantly complements higher-income workers, it may lead to a disproportionate increase in their labor income. Moreover, gains in productivity from firms that adopt AI will likely boost capital returns, which may also favor high earners. Both of these phenomena could exacerbate inequality. In most scenarios, AI will likely worsen overall inequality, a troubling trend that policymakers must proactively address to prevent the technology from further stoking social tensions. It is crucial for countries to establish comprehensive social safety nets and offer retraining programs for vulnerable workers. In doing so, we can make the AI transition more inclusive, protecting livelihoods and curbing inequality. An Inclusive AI-Driven World AI is being integrated into businesses around the world at remarkable speed, underscoring the need for policymakers to act. To help countries craft the right policies, the IMF has developed an AI Preparedness Index that measures readiness in areas such as digital infrastructure, human-capital and labor-market policies, innovation and economic integration, and regulation and ethics. The human-capital and labor-market policies component, for example, evaluates elements such as years of schooling and job-market mobility, as well as",
    "chunk_id": "downloaded_1763553881_2"
  },
  {
    "doc": "downloaded_1763553881.txt",
    "chunk": "readiness in areas such as digital infrastructure, human-capital and labor-market policies, innovation and economic integration, and regulation and ethics. The human-capital and labor-market policies component, for example, evaluates elements such as years of schooling and job-market mobility, as well as the proportion of the population covered by social safety nets. The regulation and ethics component assesses the adaptability to digital business models of a country\u2019s legal framework and the presence of strong governance for effective enforcement. Using the index, IMF staff assessed the readiness of 125 countries. The findings reveal that wealthier economies, including advanced and some emerging market economies, tend to be better equipped for AI adoption than low-income countries, though there is considerable variation across countries. Singapore, the United States and Denmark posted the highest scores on the index, based on their strong results in all four categories tracked. Guided by the insights from the AI Preparedness Index, advanced economies should prioritize AI innovation and integration while developing robust regulatory frameworks. This approach will cultivate a safe and responsible AI environment, helping maintain public trust. For emerging market and developing economies, the priority should be laying a strong foundation through investments in digital infrastructure and a digitally competent workforce. The AI era is upon us, and it is still within our power to ensure it brings prosperity for all. \u2014For more on artificial intelligence and the economy, see the December issue of Finance & Development, the IMF\u2019s quarterly magazine. RecentArtificial intelligenceA\u6587AI Needs More Abundant Power Supplies to Keep Driving Economic GrowthMay 13, 2025The power-hungry",
    "chunk_id": "downloaded_1763553881_3"
  },
  {
    "doc": "downloaded_1763553881.txt",
    "chunk": "it brings prosperity for all. \u2014For more on artificial intelligence and the economy, see the December issue of Finance & Development, the IMF\u2019s quarterly magazine. RecentArtificial intelligenceA\u6587AI Needs More Abundant Power Supplies to Keep Driving Economic GrowthMay 13, 2025The power-hungry technology requires policies to help expand electricity supplies, incentivize alternative sources, and help contain price surgesArtificial intelligenceA\u6587How Artificial Intelligence Can Boost Productivity in Latin AmericaMarch 20, 2025Some countries risk missing out on the full economic benefits of AI, but more formal jobs and expanded digital access can helpArtificial intelligenceHow AI Can Help Both Tax Collectors and TaxpayersFebruary 25, 2025New generative AI tools can redefine the relationship between governments and citizens, but strong leadership and safeguards are fundamental.ABOUT THE BLOGIMFBlog is a forum for the views of the International Monetary Fund (IMF) staff and officials on pressing economic and policy issues of the day. The IMF, based in Washington D.C., is an organization of 191 countries, working to foster global monetary cooperation and financial stability around the world. The views expressed are those of the author(s) and do not necessarily represent the views of the IMF and its Executive Board. Read MoreARTIFICIAL INTELLIGENCEDIGITAL MONEYFINANCIAL SECTOR STABILITYGLOBAL ECONOMYFINANCIAL MARKETFISCAL AFFAIRSMONETARY POLICYPEOPLEIMF HOME PAGE\u00a9 2025 INTERNATIONAL MONETARY FUND. ALL RIGHTS RESERVED",
    "chunk_id": "downloaded_1763553881_4"
  },
  {
    "doc": "downloaded_1763553885.txt",
    "chunk": "Source: https://hai.stanford.edu/ai-index/2025-ai-index-report/economy StanfordUniversityStanford HomeMaps & DirectionsSearch StanfordEmergency InfoTerms of UsePrivacyCopyrightTrademarksNon-DiscriminationAccessibility\u00a9 Stanford University. Stanford, California 94305.Pause MediaEconomy | The 2025 AI Index Report | Stanford HAIStay Up To DateGet the latest news, advances in research, policy work, and education program updates from HAI in your inbox weekly.Sign Up For Latest NewsNavigateAboutEventsCareersSearchParticipateGet InvolvedSupport HAIContact UsSkip to contentAboutAboutAboutPeopleGet Involved with HAISupport HAIResearchResearchResearchFellowship ProgramsGrantsStudent Affinity GroupsCenters & LabsResearch PublicationsResearch PartnersEducationEducationEducationExecutive and Professional EducationGovernment and PolicymakersK-12Stanford StudentsPolicyPolicyPolicyPolicy PublicationsPolicymaker EducationStudent OpportunitiesAI IndexAI IndexAI IndexAI Index ReportGlobal Vibrancy ToolPeopleNewsEventsIndustryCenters & Labs04EconomyEconomy, MarketsDownload Full ChapterSee Chapter 5All ChaptersBack to Overview01Research and Development02Technical Performance03Responsible AI04Economy05Science and Medicine06Policy and Governance07Education08Public Opinion1. Global private AI investment hits record high with 26% growth. Corporate AI investment reached $252.3 billion in 2024, with private investment climbing 44.5% and mergers and acquisitions up 12.1% from the previous year. The sector has experienced dramatic expansion over the past decade, with total investment growing more than thirteenfold since 2014.2. Generative AI funding soars. Private investment in generative AI reached $33.9 billion in 2024, up 18.7% from 2023 and over 8.5 times higher than 2022 levels. The sector now represents more than 20% of all AI-related private investment.3. The U.S. widens its lead in global AI private investment. U.S. private AI investment hit $109.1 billion in 2024, nearly 12 times higher than China\u2019s $9.3 billion and 24 times the U.K.\u2019s $4.5 billion. The gap is even more pronounced in generative AI, where U.S. investment exceeded the combined total of that of China and the European Union plus U.K. by $25.4 billion, up from",
    "chunk_id": "downloaded_1763553885_0"
  },
  {
    "doc": "downloaded_1763553885.txt",
    "chunk": "$9.3 billion and 24 times the U.K.\u2019s $4.5 billion. The gap is even more pronounced in generative AI, where U.S. investment exceeded the combined total of that of China and the European Union plus U.K. by $25.4 billion, up from a $21.8 billion gap in 2023.4. Use of AI climbs to unprecedented levels. In 2024, the proportion of survey respondents reporting AI use by their organizations jumped to 78% from 55% in 2023. Similarly, the number of respondents who reported using generative AI in at least one business function more than doubled\u2014from 33% in 2023 to 71% last year. 5. AI is beginning to deliver financial impact across business functions, but most companies are early in their journeys. Most companies that report financial impacts from using AI within a business function estimate the benefits as being at low levels. 49% of respondents whose organizations use AI in service operations report cost savings, followed by supply chain management (43%) and software engineering (41%), but most of them report cost savings of less than 10%. With regard to revenue, 71% of respondents using AI in marketing and sales report revenue gains, 63% in supply chain management, and 57% in service operations, but the most common level of revenue increases is less than 5%.6. Use of AI shows dramatic shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations\u2019 use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use.",
    "chunk_id": "downloaded_1763553885_1"
  },
  {
    "doc": "downloaded_1763553885.txt",
    "chunk": "shifts by region, with Greater China gaining ground. While North America maintains its leadership in organizations\u2019 use of AI, Greater China demonstrated one of the most significant year-over-year growth rates, with a 27 percentage point increase in organizational AI use. Europe followed with a 23 percentage point increase, suggesting a rapidly evolving global AI landscape and intensifying international competition in AI implementation.7. China\u2019s dominance in industrial robotics continues despite slight moderation. In 2023, China installed 276,300 industrial robots, six times more than Japan and 7.3 times more than the United States. Since surpassing Japan in 2013, when it accounted for 20.8% of global installations, China\u2019s share has risen to 51.1%. While China continues to install more robots than the rest of the world combined, this margin narrowed slightly in 2023, marking a modest moderation in its dramatic expansion.8. Collaborative and interactive robot installations become more common. In 2017, collaborative robots represented a mere 2.8% of all new industrial robot installations, a figure that climbed to 10.5% by 2023. Similarly, 2023 saw a rise in service robot installations across all application categories, except for medical robotics. This trend indicates not just an overall increase in robot installations but also a growing emphasis on deploying robots for human-facing roles.9. AI is driving significant shifts in energy sources, attracting interest in nuclear energy. Microsoft announced a $1.6 billion deal to revive the Three Mile Island nuclear reactor to power AI, while Google and Amazon have also secured nuclear energy agreements to support AI operations.10. AI boosts productivity and bridges",
    "chunk_id": "downloaded_1763553885_2"
  },
  {
    "doc": "downloaded_1763553885.txt",
    "chunk": "interest in nuclear energy. Microsoft announced a $1.6 billion deal to revive the Three Mile Island nuclear reactor to power AI, while Google and Amazon have also secured nuclear energy agreements to support AI operations.10. AI boosts productivity and bridges skill gaps. Last year\u2019s AI Index was among the first reports to highlight research showing AI\u2019s positive impact on productivity. This year, additional studies reinforced those findings, confirming that AI boosts productivity and in most cases, helps narrow the gap between low- and high-skilled workers.",
    "chunk_id": "downloaded_1763553885_3"
  },
  {
    "doc": "downloaded_1763553891.txt",
    "chunk": "Source: https://www.imf.org/en/publications/wp/issues/2025/04/11/the-global-impact-of-ai-mind-the-gap-566129 The Global Impact of AI: Mind the Gap About IMF\u2019s Work RESOURCES TOPICS IMF at a Glance Surveillance Lending Capacity Development IMF Factsheets List How the IMF Supports the Global Economy IMF Members IMF Finances IMF Financial Statements IMF Senior Officials IMF in History Archives of the IMF Job Opportunities Artificial Intelligence Fintech Fiscal Policies Governance and Anti-Corruption All Topics Research Flagship Publications Other Publications World Economic Outlook Global Financial Stability Report Fiscal Monitor External Sector Report Staff Discussion Notes Working Papers IMF Research Perspectives Economic Review Global Housing Watch Commodity Prices Commodities Data Portal IMF Researchers Annual Research Conference Other IMF Events Countries IMF reports and publications by country Regional Offices A B C D E F G H I J K L M N O P Q R S T U V Y Z IMF Resident Representative Offices IMF Regional Reports IMF and Europe IMF Members' Quotas and Voting Power, and Board of Governors IMF Regional Office for Asia and the Pacific IMF Capacity Development Office in Thailand (CDOT) IMF Office in the Pacific Islands IMF Europe Office in Paris and Brussels IMF Regional Office for Central, Eastern and Southeastern Europe IMF Regional Office in Riyadh IMF Regional Office in Central America, Panama, and the Dominican Republic Eastern Caribbean Currency Union (ECCU) Capacity Development About Us What We Do How We Work IMF Training Digital Training Program Online Learning Our Partners Country Stories Technical Assistance Reports High-Level Summary Technical Assistance Reports Strategy and Policies News All News See Also For Journalists Country",
    "chunk_id": "downloaded_1763553891_0"
  },
  {
    "doc": "downloaded_1763553891.txt",
    "chunk": "Capacity Development About Us What We Do How We Work IMF Training Digital Training Program Online Learning Our Partners Country Stories Technical Assistance Reports High-Level Summary Technical Assistance Reports Strategy and Policies News All News See Also For Journalists Country Focus Chart of the Week Communiqu\u00e9s Mission Concluding Statements Press Releases Speeches Statements at Donor Meetings Transcripts Views & Commentaries IMFBlog Article IV Consultations Financial Sector Assessment Program (FSAP) Seminars, Conferences, & Other Events E-mail Notification Press Center The IMF Press Center is a password-protected site for working journalists. Login or Register Information of interest Videos About the IMF Conferences Press briefings Speeches Special Features Africa Americas Asia Europe Middle East and Central Asia Economic Outlook Annual and spring meetings Capacity Development Most Recent Most Popular Data IMF Data Portal World Economic Outlook Databases AI Preparedness Index Climate Change Indicators Dashboard IMF Finances International Financial Statistics Financial Access Survey G20 Data Gaps Initiative Currency Composition of Official Foreign Exchange Reserves World Revenue Longitudinal Data Publications RESOURCES FLAGSHIPS KEY SERIES IMF NOTES Publications Advanced Search IMF eLibrary IMF Bookstore Publications Newsletter Essential Reading Guides World Economic Outlook Global Financial Stability Report Fiscal Monitor External Sector Report Regional Economic Reports Country Reports Departmental Papers Policy Papers Staff Discussion Notes Selected Issues Papers All Staff Notes Series Analytical Notes Fintech Notes How-To Notes Staff Climate Notes IMF Working PapersVisit the IMF eLibraryOur eLibrary offers over 25,000 IMF publications in multiple formats.ExploreIMF Publications NewsletterLatest economic research and insights delivered to your inbox each month.SubscribeThe Global Impact of AI: Mind the",
    "chunk_id": "downloaded_1763553891_1"
  },
  {
    "doc": "downloaded_1763553891.txt",
    "chunk": "Fintech Notes How-To Notes Staff Climate Notes IMF Working PapersVisit the IMF eLibraryOur eLibrary offers over 25,000 IMF publications in multiple formats.ExploreIMF Publications NewsletterLatest economic research and insights delivered to your inbox each month.SubscribeThe Global Impact of AI: Mind the GapByEugenio M Cerutti, Antonio I Garcia Pascual, Yosuke Kido, Longji Li, Giovanni Melina, Marina Mendes Tavares, Philippe WingenderApril 11, 2025Download PDFMore Formats on IMF eLibraryOrder a Print CopyCreate CitationShareCreate CitationMore formats on IMF eLibraryOrder a Print CopyPreview CitationCopyFormat: ChicagoEugenio M Cerutti, Antonio I Garcia Pascual, Yosuke Kido, Longji Li, Giovanni Melina, Marina Mendes Tavares, and Philippe Wingender. \"The Global Impact of AI: Mind the Gap\", IMF Working Papers 2025, 076 (2025), accessed 11/19/2025, https://doi.org/10.5089/9798229008570.001Export Citation.risProCiteRefWorksReference Manager.bibBibTexZotero.enwEndNoteDisclaimer: IMF Working Papers describe research in progress by the author(s) and are published to elicit comments and to encourage debate. The views expressed in IMF Working Papers are those of the author(s) and do not necessarily represent the views of the IMF, its Executive Board, or IMF management.SummaryThis paper examines the uneven global impact of AI, highlighting how its effects will be a function of (i) countries\u2019 sectoral exposure to AI, (ii) their preparedness to integrate these technologies into their economies, and (iii) their access to essential data and technologies. We feed these three aspects into a multi-sector dynamic general equilibrium model of the global economy and show that AI will exacerbate cross-country income inequality, disproportionately benefiting advanced economies. Indeed, the estimated growth impact in advanced economies could be more than double that in low-income countries. While improvements in AI",
    "chunk_id": "downloaded_1763553891_2"
  },
  {
    "doc": "downloaded_1763553891.txt",
    "chunk": "equilibrium model of the global economy and show that AI will exacerbate cross-country income inequality, disproportionately benefiting advanced economies. Indeed, the estimated growth impact in advanced economies could be more than double that in low-income countries. While improvements in AI preparedness and access can mitigate these disparities, they are unlikely to fully offset them. Moreover, the AI-driven productivity gains could reduce the traditional role of exchange rate adjustments due to AI\u2019s large impact in the non-tradable sector\u2014a mechanism akin to an inverse Balassa-Samuelson effect.Subject: Emerging and frontier financial markets, Financial markets, Production, Productivity, Total factor productivityKeywords: Africa, AI gap, AI preparedness, Artificial Intelligence, Asia and Pacific, Caribbean, Emerging and frontier financial markets, Global, IMF working paper No. 25/76, Middle East, Multi-Region DSGE Model, preparedness scenario, Productivity, productivity gain, Total factor productivityPublication DetailsPages:33Volume:2025DOI:https://doi.org/10.5089/9798229008570.001Issue:076Series:Working Paper No. 2025/076Stock No:WPIEA2025076ISBN:9798229008570ISSN:1018-5941You May Also Be Interested In...Tourism in the Post-Pandemic World: Economic Challenges and Opportunities for Asia-Pacific and the Western Hemisphere: November 202511/3/2025Enhancing Tax Capacity: Revenue Gains from Strengthening Tax Administration10/24/2025The Evolving Growth Model of Lithuania: Republic of Lithuania10/13/2025Potential Growth and Migration: Republic of Lithuania10/13/2025Allocative Efficiency, Firm Dynamics, and Productivity in Latvia: Republic of Latvia10/7/2025 About Research Countries Capacity Development News Events Videos Data Publications Social Media Hub Annual Report Copyright and Usage Privacy Notice Contact Us Careers Glossary Scam Alert IMF Brand \u0639\u0631\u0628\u064a \u4e2d\u6587 Fran\u00e7ais \u65e5\u672c\u8a9e \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Espa\u00f1ol \u00a9 2025 International Monetary Fund. All rights reserved.",
    "chunk_id": "downloaded_1763553891_3"
  },
  {
    "doc": "downloaded_1763553891.txt",
    "chunk": "Brand \u0639\u0631\u0628\u064a \u4e2d\u6587 Fran\u00e7ais \u65e5\u672c\u8a9e \u0420\u0443\u0441\u0441\u043a\u0438\u0439 Espa\u00f1ol \u00a9 2025 International Monetary Fund. All rights reserved.",
    "chunk_id": "downloaded_1763553891_4"
  },
  {
    "doc": "downloaded_1763553938.txt",
    "chunk": "Source: https://www.imf.org/en/blogs/articles/2024/01/14/ai-will-transform-the-global-economy-lets-make-sure-it-benefits-humanity AI Will Transform the Global Economy. Let\u2019s Make Sure It Benefits Humanity.Chart of the WeekRegionsTopicsAuthorsArchiveIMF HomeCredit X-poser/Adobe StockCredit X-poser/Adobe StockEnglish\u0627\u0644\u0639\u0631\u0628\u064a\u0629\u4e2d\u6587espa\u00f1ol\u0440\u0443\u0441\u0441\u043a\u0438\u0439\u65e5\u672c\u8a9efran\u00e7aisArtificial intelligenceAI Will Transform the Global Economy. Let\u2019s Make Sure It Benefits Humanity.AI will affect almost 40 percent of jobs around the world, replacing some and complementing others. We need a careful balance of policies to tap its potentialKristalina GeorgievaJanuary 14, 2024 We are on the brink of a technological revolution that could jumpstart productivity, boost global growth and raise incomes around the world. Yet it could also replace jobs and deepen inequality. The rapid advance of artificial intelligence has captivated the world, causing both excitement and alarm, and raising important questions about its potential impact on the global economy. The net effect is difficult to foresee, as AI will ripple through economies in complex ways. What we can say with some confidence is that we will need to come up with a set of policies to safely leverage the vast potential of AI for the benefit of humanity. Reshaping the Nature of Work In a new analysis, IMF staff examine the potential impact of AI on the global labor market. Many studies have predicted the likelihood that jobs will be replaced by AI. Yet we know that in many cases AI is likely to complement human work. The IMF analysis captures both these forces. The findings are striking: almost 40 percent of global employment is exposed to AI. Historically, automation and information technology have tended to affect routine tasks, but one of the things",
    "chunk_id": "downloaded_1763553938_0"
  },
  {
    "doc": "downloaded_1763553938.txt",
    "chunk": "complement human work. The IMF analysis captures both these forces. The findings are striking: almost 40 percent of global employment is exposed to AI. Historically, automation and information technology have tended to affect routine tasks, but one of the things that sets AI apart is its ability to impact high-skilled jobs. As a result, advanced economies face greater risks from AI\u2014but also more opportunities to leverage its benefits\u2014compared with emerging market and developing economies. In advanced economies, about 60 percent of jobs may be impacted by AI. Roughly half the exposed jobs may benefit from AI integration, enhancing productivity. For the other half, AI applications may execute key tasks currently performed by humans, which could lower labor demand, leading to lower wages and reduced hiring. In the most extreme cases, some of these jobs may disappear. In emerging markets and low-income countries, by contrast, AI exposure is expected to be 40 percent and 26 percent, respectively. These findings suggest emerging market and developing economies face fewer immediate disruptions from AI. At the same time, many of these countries don\u2019t have the infrastructure or skilled workforces to harness the benefits of AI, raising the risk that over time the technology could worsen inequality among nations. AI could also affect income and wealth inequality within countries. We may see polarization within income brackets, with workers who can harness AI seeing an increase in their productivity and wages\u2014and those who cannot falling behind. Research shows that AI can help less experienced workers enhance their productivity more quickly. Younger workers",
    "chunk_id": "downloaded_1763553938_1"
  },
  {
    "doc": "downloaded_1763553938.txt",
    "chunk": "see polarization within income brackets, with workers who can harness AI seeing an increase in their productivity and wages\u2014and those who cannot falling behind. Research shows that AI can help less experienced workers enhance their productivity more quickly. Younger workers may find it easier to exploit opportunities, while older workers could struggle to adapt. The effect on labor income will largely depend on the extent to which AI will complement high-income workers. If AI significantly complements higher-income workers, it may lead to a disproportionate increase in their labor income. Moreover, gains in productivity from firms that adopt AI will likely boost capital returns, which may also favor high earners. Both of these phenomena could exacerbate inequality. In most scenarios, AI will likely worsen overall inequality, a troubling trend that policymakers must proactively address to prevent the technology from further stoking social tensions. It is crucial for countries to establish comprehensive social safety nets and offer retraining programs for vulnerable workers. In doing so, we can make the AI transition more inclusive, protecting livelihoods and curbing inequality. An Inclusive AI-Driven World AI is being integrated into businesses around the world at remarkable speed, underscoring the need for policymakers to act. To help countries craft the right policies, the IMF has developed an AI Preparedness Index that measures readiness in areas such as digital infrastructure, human-capital and labor-market policies, innovation and economic integration, and regulation and ethics. The human-capital and labor-market policies component, for example, evaluates elements such as years of schooling and job-market mobility, as well as",
    "chunk_id": "downloaded_1763553938_2"
  },
  {
    "doc": "downloaded_1763553938.txt",
    "chunk": "readiness in areas such as digital infrastructure, human-capital and labor-market policies, innovation and economic integration, and regulation and ethics. The human-capital and labor-market policies component, for example, evaluates elements such as years of schooling and job-market mobility, as well as the proportion of the population covered by social safety nets. The regulation and ethics component assesses the adaptability to digital business models of a country\u2019s legal framework and the presence of strong governance for effective enforcement. Using the index, IMF staff assessed the readiness of 125 countries. The findings reveal that wealthier economies, including advanced and some emerging market economies, tend to be better equipped for AI adoption than low-income countries, though there is considerable variation across countries. Singapore, the United States and Denmark posted the highest scores on the index, based on their strong results in all four categories tracked. Guided by the insights from the AI Preparedness Index, advanced economies should prioritize AI innovation and integration while developing robust regulatory frameworks. This approach will cultivate a safe and responsible AI environment, helping maintain public trust. For emerging market and developing economies, the priority should be laying a strong foundation through investments in digital infrastructure and a digitally competent workforce. The AI era is upon us, and it is still within our power to ensure it brings prosperity for all. \u2014For more on artificial intelligence and the economy, see the December issue of Finance & Development, the IMF\u2019s quarterly magazine. RecentArtificial intelligenceA\u6587AI Needs More Abundant Power Supplies to Keep Driving Economic GrowthMay 13, 2025The power-hungry",
    "chunk_id": "downloaded_1763553938_3"
  },
  {
    "doc": "downloaded_1763553938.txt",
    "chunk": "it brings prosperity for all. \u2014For more on artificial intelligence and the economy, see the December issue of Finance & Development, the IMF\u2019s quarterly magazine. RecentArtificial intelligenceA\u6587AI Needs More Abundant Power Supplies to Keep Driving Economic GrowthMay 13, 2025The power-hungry technology requires policies to help expand electricity supplies, incentivize alternative sources, and help contain price surgesArtificial intelligenceA\u6587How Artificial Intelligence Can Boost Productivity in Latin AmericaMarch 20, 2025Some countries risk missing out on the full economic benefits of AI, but more formal jobs and expanded digital access can helpArtificial intelligenceHow AI Can Help Both Tax Collectors and TaxpayersFebruary 25, 2025New generative AI tools can redefine the relationship between governments and citizens, but strong leadership and safeguards are fundamental.ABOUT THE BLOGIMFBlog is a forum for the views of the International Monetary Fund (IMF) staff and officials on pressing economic and policy issues of the day. The IMF, based in Washington D.C., is an organization of 191 countries, working to foster global monetary cooperation and financial stability around the world. The views expressed are those of the author(s) and do not necessarily represent the views of the IMF and its Executive Board. Read MoreARTIFICIAL INTELLIGENCEDIGITAL MONEYFINANCIAL SECTOR STABILITYGLOBAL ECONOMYFINANCIAL MARKETFISCAL AFFAIRSMONETARY POLICYPEOPLEIMF HOME PAGE\u00a9 2025 INTERNATIONAL MONETARY FUND. ALL RIGHTS RESERVED",
    "chunk_id": "downloaded_1763553938_4"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "Source: https://www.clrn.org/how-does-artificial-intelligence-affect-the-economy/ How Does Artificial Intelligence Affect the Economy? - California Learning Resource Network Skip to content Reviews Tech Resource About Us Contact Terms of Use Privacy Policy Affiliate Disclosure Main Menu About UsAffiliate DisclosureContactHomePrivacy PolicyTerms of Use How Does Artificial Intelligence Affect the Economy?By CLRN team / July 7, 2025 Artificial intelligence (AI) is rapidly transforming the global economy, impacting everything from labor markets and productivity to innovation and wealth distribution. Its influence stems from its potential to automate tasks, augment human capabilities, and generate novel insights from vast datasets. This article delves into the multifaceted ways AI is shaping the economic landscape, examining its potential benefits, challenges, and implications for future growth. Productivity Enhancement and Automation At its core, AI\u2019s economic impact is driven by its ability to enhance productivity and automate processes. Machine learning algorithms, particularly deep learning models, can analyze complex datasets to optimize operations, predict demand, and improve resource allocation. This leads to increased efficiency and reduced operational costs across various industries. Sector AI Application Impact on Productivity Example Manufacturing Predictive Maintenance Reduces downtime, optimizes equipment lifespan, improves throughput. Detecting anomalies in sensor data to predict machine failure in a manufacturing plant. Logistics Route Optimization & Automation Minimizes delivery times, reduces fuel consumption, automates warehousing operations. Using reinforcement learning to optimize delivery routes based on real-time traffic conditions. Healthcare AI-Assisted Diagnosis Improves diagnostic accuracy, accelerates treatment planning, reduces medical errors. Analyzing medical images (X-rays, CT scans) to detect diseases like cancer. Finance Fraud Detection Identifies fraudulent transactions in real-time, minimizes financial",
    "chunk_id": "downloaded_1763553939_0"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "delivery routes based on real-time traffic conditions. Healthcare AI-Assisted Diagnosis Improves diagnostic accuracy, accelerates treatment planning, reduces medical errors. Analyzing medical images (X-rays, CT scans) to detect diseases like cancer. Finance Fraud Detection Identifies fraudulent transactions in real-time, minimizes financial losses, enhances security. Utilizing anomaly detection algorithms to flag suspicious credit card activity. Customer Service Chatbots & Virtual Assistants Provides instant support, resolves customer inquiries efficiently, reduces operational costs. Deploying natural language processing (NLP) powered chatbots to handle common customer queries. The automation capabilities of AI, particularly in areas such as robotics and process automation (RPA), are significantly reshaping the labor market. While automation can lead to job displacement in certain sectors, it also creates new opportunities in areas such as AI development, data science, and AI-related infrastructure management. The net effect on employment remains a subject of ongoing debate and depends heavily on factors such as the pace of technological adoption and the development of appropriate workforce retraining programs. Innovation and New Product Development AI is a catalyst for innovation, enabling the development of new products, services, and business models. Its ability to analyze large datasets, identify patterns, and generate insights facilitates the creation of novel solutions to complex problems. Drug Discovery: AI accelerates the drug discovery process by analyzing vast amounts of biological and chemical data to identify potential drug candidates and predict their effectiveness. This significantly reduces the time and cost associated with traditional drug development methods. Personalized Medicine: AI enables personalized medicine by analyzing individual patient data, including genetic information, medical history,",
    "chunk_id": "downloaded_1763553939_1"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "chemical data to identify potential drug candidates and predict their effectiveness. This significantly reduces the time and cost associated with traditional drug development methods. Personalized Medicine: AI enables personalized medicine by analyzing individual patient data, including genetic information, medical history, and lifestyle factors, to tailor treatment plans to specific patient needs. Autonomous Vehicles: AI is the driving force behind the development of autonomous vehicles, which promise to revolutionize transportation by improving safety, reducing traffic congestion, and enhancing accessibility. Generative Design: In engineering and design, AI-powered generative design tools can automatically create and optimize designs based on specified constraints, leading to innovative and efficient solutions. For example, in aerospace, AI can optimize the design of aircraft components for maximum strength and minimal weight. Impact on Labor Markets and Income Inequality The impact of AI on labor markets is a complex and multifaceted issue. While AI can automate routine tasks and displace workers in certain occupations, it also creates new jobs and enhances the productivity of existing workers. Job Displacement: AI-driven automation poses a risk to jobs that involve repetitive, manual, or rule-based tasks. This includes jobs in manufacturing, transportation, and customer service. Job Creation: The development, deployment, and maintenance of AI systems create new jobs in areas such as AI engineering, data science, machine learning, and AI ethics. Additionally, AI can create new industries and business models that generate employment opportunities. Skill Gap: The adoption of AI requires a workforce with new skills, including data analysis, programming, and critical thinking. This can lead to a skill gap,",
    "chunk_id": "downloaded_1763553939_2"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "ethics. Additionally, AI can create new industries and business models that generate employment opportunities. Skill Gap: The adoption of AI requires a workforce with new skills, including data analysis, programming, and critical thinking. This can lead to a skill gap, where the demand for skilled workers exceeds the supply. Wage Polarization: AI can exacerbate income inequality by increasing the demand for highly skilled workers and reducing the demand for low-skilled workers. This can lead to a widening gap between the wages of high-skilled and low-skilled workers. To mitigate the negative impacts of AI on labor markets, it is crucial to invest in education and training programs that equip workers with the skills needed to thrive in the AI-driven economy. These programs should focus on developing skills such as data analysis, critical thinking, and problem-solving, as well as providing opportunities for workers to upskill and reskill throughout their careers. AI and Economic Growth AI has the potential to significantly boost economic growth by increasing productivity, fostering innovation, and creating new markets. However, realizing this potential requires addressing the challenges associated with AI adoption, such as the need for skilled workers, the risk of job displacement, and the ethical considerations surrounding AI deployment. Factor Impact on Economic Growth Description Increased Productivity Higher output per worker, reduced production costs. AI-powered automation streamlines processes, optimizes resource allocation, and improves decision-making, leading to increased productivity across various sectors. Innovation & New Markets Creation of new products, services, and business models. AI enables the development of novel solutions to complex problems, fostering",
    "chunk_id": "downloaded_1763553939_3"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "AI-powered automation streamlines processes, optimizes resource allocation, and improves decision-making, leading to increased productivity across various sectors. Innovation & New Markets Creation of new products, services, and business models. AI enables the development of novel solutions to complex problems, fostering innovation and creating new markets for AI-powered products and services. Examples include personalized medicine, autonomous vehicles, and AI-driven financial services. Enhanced Decision-Making Improved accuracy and efficiency in business operations. AI algorithms can analyze vast datasets to identify patterns and insights that humans may miss, leading to more informed and data-driven decision-making. This can improve business outcomes and reduce risks. Lower Operational Costs Reduced expenses through automation and optimized resource utilization. AI-powered automation reduces labor costs, optimizes energy consumption, and minimizes waste, leading to lower operational costs for businesses. For instance, predictive maintenance can prevent equipment failures and reduce downtime, resulting in significant cost savings. Improved Customer Experience Personalized services and faster response times. AI enables businesses to provide personalized services and faster response times to customers, enhancing customer satisfaction and loyalty. Chatbots, personalized recommendations, and targeted marketing campaigns are examples of AI applications that improve the customer experience. Ethical Considerations and Regulatory Frameworks The widespread adoption of AI raises important ethical considerations, including bias, fairness, transparency, and accountability. AI algorithms can perpetuate and amplify existing biases in data, leading to discriminatory outcomes. It is crucial to develop AI systems that are fair, transparent, and accountable, and to establish regulatory frameworks that govern the development and deployment of AI technologies. Bias Mitigation: AI systems should be designed",
    "chunk_id": "downloaded_1763553939_4"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "in data, leading to discriminatory outcomes. It is crucial to develop AI systems that are fair, transparent, and accountable, and to establish regulatory frameworks that govern the development and deployment of AI technologies. Bias Mitigation: AI systems should be designed to mitigate bias in data and algorithms. This can involve using techniques such as data augmentation, fairness-aware algorithms, and bias detection tools. Transparency and Explainability: AI systems should be transparent and explainable, allowing users to understand how decisions are made. This is particularly important in high-stakes applications such as healthcare and finance. Techniques like SHAP (SHapley Additive exPlanations) and LIME (Local Interpretable Model-agnostic Explanations) can be used for model interpretability. Accountability: Developers and deployers of AI systems should be held accountable for the outcomes of their systems. This requires establishing clear lines of responsibility and developing mechanisms for redress when AI systems cause harm. Data Privacy: AI systems often rely on large amounts of data, raising concerns about data privacy. It is crucial to protect individuals\u2019 privacy by implementing appropriate data security measures and adhering to data privacy regulations such as GDPR (General Data Protection Regulation) and CCPA (California Consumer Privacy Act). The Future of AI and the Economy The impact of AI on the economy is only set to increase in the coming years. As AI technology continues to advance and become more integrated into various aspects of life, its transformative effects on productivity, innovation, and labor markets will become even more profound. The proliferation of cloud computing, the increasing availability of data, and advances",
    "chunk_id": "downloaded_1763553939_5"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "AI technology continues to advance and become more integrated into various aspects of life, its transformative effects on productivity, innovation, and labor markets will become even more profound. The proliferation of cloud computing, the increasing availability of data, and advances in algorithm development are all contributing to the rapid growth of AI. Quantum Computing: Quantum computing has the potential to revolutionize AI by enabling the training of more complex and powerful models. This could lead to breakthroughs in areas such as drug discovery, materials science, and financial modeling. Edge AI: Edge AI, which involves deploying AI models on edge devices such as smartphones and sensors, enables real-time data processing and decision-making without relying on cloud connectivity. This is particularly useful in applications such as autonomous vehicles, industrial automation, and smart cities. Explainable AI (XAI): As AI becomes more prevalent, the need for explainable AI (XAI) will become even more critical. XAI techniques aim to make AI models more transparent and interpretable, allowing users to understand how decisions are made and to identify potential biases. AI Ethics: AI ethics will continue to be a central concern as AI becomes more widespread. Ensuring that AI systems are fair, transparent, and accountable will be essential for building public trust and preventing unintended consequences. Conclusion Artificial intelligence is a powerful force shaping the global economy. Its potential to enhance productivity, foster innovation, and create new markets is immense. However, realizing this potential requires addressing the challenges associated with AI adoption, such as the need for skilled workers, the risk of",
    "chunk_id": "downloaded_1763553939_6"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "force shaping the global economy. Its potential to enhance productivity, foster innovation, and create new markets is immense. However, realizing this potential requires addressing the challenges associated with AI adoption, such as the need for skilled workers, the risk of job displacement, and the ethical considerations surrounding AI deployment. By investing in education and training, developing appropriate regulatory frameworks, and prioritizing ethical considerations, we can harness the power of AI to create a more prosperous and equitable future for all. As AI continues to evolve, understanding its multifaceted impact on the economy will be crucial for policymakers, businesses, and individuals alike. The integration of AI requires strategic planning and a commitment to responsible innovation to maximize its benefits and mitigate its risks. Your friends have asked us these questions - Check out the answers! How to Delete Tabs on Google ChromeWhy are apps not compatible with my iPad?How to create a listserv in Outlook?How to sign in to Twitter?How Long Do Drafts Last on Instagram?What Does Friend Suggestion Mean on Facebook?How to Add Contacts to Your Child\u2019s Apple WatchHow to connect last fm to discord? Previous How far is the 3 point line in middle school? Next What city is the university of washington in? Leave a Comment Cancel ReplyYour email address will not be published. Required fields are marked *Type here.. Name* Email* Website Save my name, email, and website in this browser for the next time I comment. \u0394 SearchSearchRecent Posts6 Best Deals on Epson EcoTank Printers in 2025 6 Best Small Printers for",
    "chunk_id": "downloaded_1763553939_7"
  },
  {
    "doc": "downloaded_1763553939.txt",
    "chunk": "Required fields are marked *Type here.. Name* Email* Website Save my name, email, and website in this browser for the next time I comment. \u0394 SearchSearchRecent Posts6 Best Deals on Epson EcoTank Printers in 2025 6 Best Small Printers for Home Use in 2025 10 Best Photo Printers in 2025 6 Best Top Rated All in One Laser Color Printers in 2025 6 Best Desktop Inkjet Printers in 2025 Copyright \u00a9 2025 California Learning Resource Network | Made with love by CLRN Scroll to Top",
    "chunk_id": "downloaded_1763553939_8"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "Source: https://cepr.org/voxeu/columns/global-impact-ai-mind-gap The global impact of AI: Mind the gap | CEPR Skip to main content Mobile menu Search VoxEU Columns Trump and Tariffs Blogs&Reviews VoxTalks VideoVox VoxEU Debates About VoxEU Research Programme Areas Research Policy Networks (RPNs) Research Projects and Networks Research Policies Data Sets Publications Publication Series Books and Reports Discussion Papers Covid Economics Papers Policy Papers Economic Policy Journal Search All Publications Archive Events Calls for Papers Forthcoming Events Past Events Event Series Audio and video Search all multimedia content VoxTalks VideoVox Vox Webcasts Webinar Videos About CEPR People News Press Governance Support CEPR Partners Jobs at CEPR Summer Reading 2025 Themes Search Themes Themes Key Themes Artificial Intelligence Central Banking Climate Change Competition Policy Development & Growth Economic History Energy EU Economic Architecture Inflation Political Economy Poverty and income inequality Sustainable Finance Ukraine Initiative Women in Economics Other Themes Business Cycles Covid 19 Exchange Rates Finance & Fintech Health Economics International Finance International Trade Labour Markets Migration Monetary Policy Productivity and Innovation Taxation Focus On The Economic Consequences of the War Trump & Tariffs Main navigation VoxEU Columns Trump and Tariffs Blogs&Reviews VoxTalks VideoVox VoxEU Debates About VoxEU Research Publications Publication Series Books and Reports Discussion Papers About CEPR Discussion Papers Discussion Paper Subscriptions Covid Economics Papers Policy Papers Economic Policy Journal Search All Publications Archive CEPR Bulletin Events Audio and video Search all multimedia content VoxTalks VideoVox Vox Webcasts Webinar Videos About CEPR People President and Vice Presidents Distinguished Fellows Programme Directors RPN Leaders CEPR Staff Advisory Board News Press Governance",
    "chunk_id": "downloaded_1763553940_0"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "Search All Publications Archive CEPR Bulletin Events Audio and video Search all multimedia content VoxTalks VideoVox Vox Webcasts Webinar Videos About CEPR People President and Vice Presidents Distinguished Fellows Programme Directors RPN Leaders CEPR Staff Advisory Board News Press Governance Support CEPR Partners Jobs at CEPR Summer Reading 2025 Secondary Menu CEPR Offices User account menu Log in Secondary Menu CEPR Offices User account menu Log in Themes Key Themes Artificial Intelligence Central Banking Climate Change Competition Policy Development & Growth Economic History Energy EU Economic Architecture Inflation Political Economy Poverty and income inequality Sustainable Finance Ukraine Initiative Women in Economics Other Themes Business Cycles Covid 19 Exchange Rates Finance & Fintech Health Economics International Finance International Trade Labour Markets Migration Monetary Policy Productivity and Innovation Taxation Focus On The Economic Consequences of the War Trump & Tariffs Search the site Search / VoxEU / Columns In this section Columns Trump and Tariffs Blogs and Reviews VoxTalks VoxEU Videos VoxEU Debates About VoxEU VoxEU Column Development & Growth Productivity and Innovation The global impact of AI: Mind the gap Eugenio Cerutti Antonio Garcia Pascual Yosuke Kido Longji Li Giovanni Melina Marina M. Tavares Philippe Wingender / 31 May 2025 Artificial intelligence is widely seen as a transformative force for productivity and innovation. Yet, its macroeconomic implications remain uncertain, especially from a global perspective. This column shows how structural differences in AI exposure, preparedness, and access in advanced economies, emerging markets, and low-income countries shape the distribution of AI-induced productivity gains. While improvements in AI preparedness and",
    "chunk_id": "downloaded_1763553940_1"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "remain uncertain, especially from a global perspective. This column shows how structural differences in AI exposure, preparedness, and access in advanced economies, emerging markets, and low-income countries shape the distribution of AI-induced productivity gains. While improvements in AI preparedness and access can mitigate some disparities between countries, they are unlikely to fully offset them. AI-driven productivity gains could reduce the traditional role of exchange rate adjustments due to AI\u2019s large impact on the non-tradable sector. Authors Eugenio Cerutti Antonio Garcia Pascual Yosuke Kido Longji Li Giovanni Melina Marina M. Tavares Philippe Wingender Share Twitter Facebook LinkedIn The magnitude of growth in total factor productivity (TFP) driven by AI remains a highly debated topic, marked by significant uncertainty. Focusing on the US, Acemoglu (2025) cautions that productivity gains may fall short of expectations, particularly when AI encounters complex, context-specific tasks. Aghion and Bunel (2024), by contrast, present a more optimistic view, highlighting AI\u2019s potential to drive growth through automation and accelerated idea generation. Building on their insights and a rapidly growing literature, our new research (Cerutti et al. 2025) takes a global perspective. It links AI exposure, preparedness, and access to TFP growth driven by AI adoption. To gauge AI\u2019s impact on TFP in advanced economies, emerging markets and low-income countries, we combine microdata on the exposure of task- and sectoral-level jobs to AI with country-specific measures of AI preparedness and assumptions on AI access. Determinants of AI adoption The global adoption of AI technologies has revealed significant disparities among advanced economies, emerging markets, and low-income countries.",
    "chunk_id": "downloaded_1763553940_2"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "of task- and sectoral-level jobs to AI with country-specific measures of AI preparedness and assumptions on AI access. Determinants of AI adoption The global adoption of AI technologies has revealed significant disparities among advanced economies, emerging markets, and low-income countries. These differences arise from structural, economic, and institutional factors, including access to high-quality data and the presence of supportive regulatory frameworks. While some nations are positioned to invest substantially in AI-driven innovation, others find it challenging to implement even basic AI solutions. Consequently, the widening gaps in competitiveness, productivity, and human capital development may exacerbate existing inequalities and generate new ones. Three critical elements influence country-level outcomes. Exposure refers to the share of jobs and sectors susceptible to AI-driven transformation. Task-based analyses show that roughly 60% of jobs in advanced economies are highly exposed to AI, compared to 42% in emerging markets and just 26% in low-income countries (Pizzinelli 2023, Cazzaniga et al. 2024). Preparedness reflects a country\u2019s institutional and digital readiness. The IMF AI Preparedness Index (Cazzaniga et al. 2024) reveals that advanced economies generally benefit from strong infrastructure, skilled labour, and robust governance frameworks, while many low-income countries lack even the basic foundations to absorb AI technologies (Figure 1). Access captures the availability of key AI enablers: semiconductors, computer power, data infrastructure, and global partnerships. Here, too, disparities can be stark. While the US and China lead in frontier capabilities, emerging markets and low-income countries face growing constraints amid rising geopolitical tensions and export controls (Hawkins and Leonard 2025, European Commission 2025). Figure 1",
    "chunk_id": "downloaded_1763553940_3"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "partnerships. Here, too, disparities can be stark. While the US and China lead in frontier capabilities, emerging markets and low-income countries face growing constraints amid rising geopolitical tensions and export controls (Hawkins and Leonard 2025, European Commission 2025). Figure 1 AI preparedness index and employment share in high-exposure occupations Notes: The plot includes 125 countries: 32 advanced economies, 56 emerging markets, and 37 low-income countries. The red reference lines are derived from the median values of the AI preparedness index and high-exposure employment. Circles represent the average values for each respective country group. Crosses denote the average values for each corresponding country group: AEs = advanced economies; EMs = emerging markets; LICs = low-income countries. Country labels use International Organization for Standardization (ISO) country codes. Source: Cazzaniga et al. (2024). Modelling global AI impacts To quantify these dynamics, we employ the IMF\u2019s Global Integrated Monetary and Fiscal model, a dynamic general equilibrium framework with rich policy and behavioural channels (Freedman et al. 2010, Kumhof et al. 2010). We use an enhanced version of the model (GIMF-GVC), which features three sectors in each region \u2013 the non-tradables, tradables, and AI-intensive sectors \u2013 and incorporates global value chains. AI shocks enter the model as TFP gains, scaled by each region\u2019s level of exposure, preparedness, and access. This structure allows for forward-looking behaviour, endogenous investment, and meaningful cross-country spillovers, making it well suited to assess AI\u2019s global macroeconomic footprint. Our version of the model also incorporates the global economy comprehensively by including seven large regions, as well as the",
    "chunk_id": "downloaded_1763553940_4"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "allows for forward-looking behaviour, endogenous investment, and meaningful cross-country spillovers, making it well suited to assess AI\u2019s global macroeconomic footprint. Our version of the model also incorporates the global economy comprehensively by including seven large regions, as well as the rest of the world. Macroeconomic effects The results reveal a stark asymmetry in outcomes. In a high TFP growth scenario, which assumes no restrictions to AI-specific technologies in all regions, global productivity rises by 2.4% over ten years, lifting world GDP by nearly 4%. Under a low TFP growth scenario, which also assumes no restrictions to AI-specific technologies but envisages more conservative productivity gains, gains are limited to 0.8% and 1.3% over ten years, respectively. Yet behind these global averages lie significant divergences (Figure 2). The US \u2013 which ranks highest in both AI preparedness and exposure \u2013 experiences output gains of 5.4% in the high-productivity-growth scenario. Other advanced economies, including Europe and Japan, follow closely. By contrast, low-income countries see output gains of just 2.7%, and emerging markets range from 3.0%\u20133.5%, reflecting weaker structural readiness and lower AI exposure. Figure 2 Cross-country differences in GDP impacts in baseline scenarios Notes: Panel (a) shows the deviations of real GDP from the steady state for the high TFP growth baseline scenario after 10 years. Panel (b) shows the deviations of real GDP from the steady state for the low TFP growth baseline scenario after 10 years. The global averages are shown as horizontal lines. EMA = emerging market economies Asia, Central, Asia, Russia, etc.; EML = emerging",
    "chunk_id": "downloaded_1763553940_5"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "the deviations of real GDP from the steady state for the low TFP growth baseline scenario after 10 years. The global averages are shown as horizontal lines. EMA = emerging market economies Asia, Central, Asia, Russia, etc.; EML = emerging market economies Latin America, Middle East, Africa, etc.; EUS = EU and Switzerland; LIC = low-income countries; OAD = other advanced economies; ROW = rest of the world. See Cerutti et al. (2025) for a detailed composition of the countries in each group. Source: Cerutti et al. (2025). Inflation rises modestly in the short run as demand outpaces supply, but later declines as AI-driven productivity improves supply capacity. Central banks respond with modest tightening. Interestingly, real exchange rates in advanced economies depreciate, contrary to traditional expectations. This reflects large productivity gains in the non-tradable sectors, such as healthcare and education, creating an \u2018inverse Balassa-Samuelson effect\u2019 that enhances competitiveness in advanced economies (Figure 3). Figure 3 Changes in real effective exchange rates and non-tradable sector TFP (10-year horizon) Notes: The values are shown as deviations of high TFP growth scenario outcomes from the steady state after 10 years. See Annex I of our paper for the list of ISIC sectors included in the non-tradable sector. EMA = emerging market economies Asia, Central, Asia, Russia, etc.; EML = emerging market economies Latin America, Middle East, Africa, etc.; EUS = EU and Switzerland; LIC = low-income countries; OAD = other advanced economies; and ROW = rest of the world. See Cerutti et al. (2025) for a detailed composition of",
    "chunk_id": "downloaded_1763553940_6"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "emerging market economies Latin America, Middle East, Africa, etc.; EUS = EU and Switzerland; LIC = low-income countries; OAD = other advanced economies; and ROW = rest of the world. See Cerutti et al. (2025) for a detailed composition of the countries in each group. Source: Cerutti et al. (2025). Policy matters but cannot fully close the gap Can policy mitigate these disparities? Two alternative scenarios suggest that it can \u2013 but only to a degree. Importantly, policy can also aggravate these disparities. In a limited AI access scenario \u2013 where emerging markets (excluding China) and low-income countries face continued barriers to advanced AI technologies \u2013 output growth in these countries declines by about 1 percentage point relative to the baseline (Figure 4). This highlights how access to computer power, chips, and data remains a hard constraint on inclusive AI adoption. An enhanced AI preparedness scenario assumes that emerging markets and low-income countries improve institutions and digital infrastructure to match the best performers in their peer groups. This raises output, particularly in AI-intensive sectors, but cross-country inequality persists, even under this more optimistic reform path. Figure 4 Cross-country differences of GDP in the alternative scenarios Notes: Panel (a) shows the deviations of real GDP from the steady state for the limited AI access scenario after 10 years. Panel (b) shows the deviations of real GDP from the steady state for the enhanced AI preparedness scenario after 10 years. The global averages are shown as horizontal lines. EMA = emerging market economies Asia, Central, Asia, Russia, etc.;",
    "chunk_id": "downloaded_1763553940_7"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "years. Panel (b) shows the deviations of real GDP from the steady state for the enhanced AI preparedness scenario after 10 years. The global averages are shown as horizontal lines. EMA = emerging market economies Asia, Central, Asia, Russia, etc.; EML = emerging market economies Latin America, Middle East, Africa, etc.; EUS = EU and Switzerland; LIC = low-income countries; OAD = other advanced economies; and ROW = rest of the world. See Cerutti et al. (2025) for a detailed composition of the countries in each group.Source: Cerutti et al. (2025). Conclusions These findings suggest that AI readiness is both a growth imperative and a global equity issue. For advanced economies, the policy focus should be on AI governance, innovation ecosystems, and responsible AI deployment. For emerging markets and low-income countries, foundational investments in digital infrastructure, education, and data access are essential. Public investment is particularly important in high social return areas like healthcare, education, and public administration, where private markets may underinvest. There are grounds for optimism. Technological breakthroughs such as DeepSeek\u2019s efficient large language models show that frontier innovation is not necessarily resource-intensive. Open-source models, combined with targeted reforms, can lower barriers for the developing world. The success of Kenya\u2019s M-Pesa, which leapfrogged traditional banking infrastructure to create a thriving fintech ecosystem, illustrates the potential of well-targeted digital innovation in lower-income settings. Still, without sustained efforts to close gaps in readiness and access, AI could become a new fault line in global development, reinforcing \u2013 not reversing \u2013 cross-country inequality. Authors\u2019 note: The views",
    "chunk_id": "downloaded_1763553940_8"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "potential of well-targeted digital innovation in lower-income settings. Still, without sustained efforts to close gaps in readiness and access, AI could become a new fault line in global development, reinforcing \u2013 not reversing \u2013 cross-country inequality. Authors\u2019 note: The views expressed in this column are the authors\u2019 own and do not represent the views of the International Monetary Fund, its Executive Board, or IMF management. References Acemoglu, D (2025), \u201cThe simple macroeconomics of AI\u201d, Economic Policy 40(121): 13\u201358. Aghion, P, and S Bunel (2024), \u201cAI and growth: Where do we stand?\u201d, policy note. Hawkins, M, and J Leonard (2025), \u201cBiden to further limit Nvidia AI chip exports in final push\u201d, Bloomberg.com, 9 January. Cazzaniga, M, M F Jaumotte, L Li, M G Melina, A J Panton, C Pizzinelli, E Rockall, and M M Tavares (2024), \u201cGen-AI: Artificial intelligence and the future of work\u201d, IMF Staff Discussion Note SDN2024/001. Cerutti, E, A Garcia Pascual, Y Kido, L Li, G Melina, M M Tavares, and P Wingender (2025), \u201cThe global impact of AI: Mind the gap\u201d, IMF Working Paper No. 25/76. European Commission (2025), \u201cCommission calls on Member States to review outbound investments and assess risks to economic security\u201d, press release, 15 January. Freedman, C, M Kumhof, D Laxton, D Muir, and S Mursula (2010), \u201cGlobal effects of fiscal stimulus during the crisis\u201d, Journal of Monetary Economics 57(5): 506\u201326. Kumhof, M, D Muir, S Mursula, and D Laxton (2010), \u201cThe Global Integrated Monetary and Fiscal Model (GIMF) \u2013 theoretical structure\u201d, IMF Working Paper 10/34. Pizzinelli, C, A Panton,",
    "chunk_id": "downloaded_1763553940_9"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "fiscal stimulus during the crisis\u201d, Journal of Monetary Economics 57(5): 506\u201326. Kumhof, M, D Muir, S Mursula, and D Laxton (2010), \u201cThe Global Integrated Monetary and Fiscal Model (GIMF) \u2013 theoretical structure\u201d, IMF Working Paper 10/34. Pizzinelli, C, A Panton, M M Tavares, M Cazzaniga, and L Li (2023), \u201cLabor market exposure to AI: Cross-country differences and distributional implications\u201d, IMF Working Paper 2023/216. Authors Eugenio Cerutti Chief of the Macro-Financial Unit, SPR International Monetary Fund Antonio Garcia Pascual Deputy Division Chief International Monetary Fund Yosuke Kido Economist International Monetary Fund Longji Li Research Officer International Monetary Fund Giovanni Melina Deputy Division Chief, Structural and Climate Policy division International Monetary Fund Marina M. Tavares Senior Economist International Monetary Fund Philippe Wingender Senior Economist International Monetary Fund Themes Development & Growth Productivity and Innovation Keywords Artificial intelligence Productivity growth Share Twitter Facebook LinkedIn VoxEU Column Should AI stay or should AI go: The promises and perils of AI for productivity and growth Francesco Filippucci Peter Gal Cecilia Jona-Lasinio Alvaro Leandro giuseppe nicoletti 2 May 2024 ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Productivity and Innovation VoxEU Column The local effects of artificial intelligence labour investments: Evidence from the municipal bond market Lefteris Andreadis Emmanouil Chatzikonstantinou Elena Kalotychou Christodoulos Louca Christos Makridis 18 Apr 2025 ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Artificial Intelligence ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Labour Markets ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Productivity and Innovation VoxEU Column The impact of artificial intelligence on growth and employment Ethan Ilzetzki Suryaansh Jain 20 Jun 2023 ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Labour Markets ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png)",
    "chunk_id": "downloaded_1763553940_10"
  },
  {
    "doc": "downloaded_1763553940.txt",
    "chunk": "2022-01-04 at 17.01.16.png) Labour Markets ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Productivity and Innovation VoxEU Column The impact of artificial intelligence on growth and employment Ethan Ilzetzki Suryaansh Jain 20 Jun 2023 ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Labour Markets ![](../../../../../../../../../../var/folders/34/zq18d8kx7kbgby0j06p_j6t40000gn/T/TemporaryItems/NSIRD_screencaptureui_EM2XPo/Screenshot 2022-01-04 at 17.01.16.png) Productivity and Innovation Themes & Current Issues Artificial Intelligence Business Cycles Central Banking Climate Change Competition Policy COVID-19 Development & Growth Economic history Energy EU Economic Architecture Exchange Rates Finance and Fintech Financial Markets Financial Regulation and Banking Health Economics Inflation International Finance International trade Labour Markets Migration Monetary Policy Political Economy Poverty and Income Inequality Productivity and Innovation Taxation Ukraine Initiative Women in Economics Sign up to our newsletter follow us Copyright 2025 CEPR /designbysoapbox.com Contact Us Cookies Privacy Policy RSS Feeds",
    "chunk_id": "downloaded_1763553940_11"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "Source: https://www.linkedin.com/pulse/ai-workforce-transformation-academic-analysis-tipping-randy-cook-6ulec The AI Workforce Transformation: An Academic Analysis of Post-Pandemic Tipping Point Dynamics LinkedIn respects your privacy LinkedIn and 3rd parties use essential and non-essential cookies to provide, secure, analyze and improve our Services, and to show you relevant ads (including professional and job ads) on and off LinkedIn. Learn more in our Cookie Policy.Select Accept to consent or Reject to decline non-essential cookies for this use. You can update your choices at any time in your settings. Accept Reject Agree & Join LinkedIn By clicking Continue to join or sign in, you agree to LinkedIn\u2019s User Agreement, Privacy Policy, and Cookie Policy. Skip to main content LinkedIn Top Content People Learning Jobs Games Join now Sign in The AI Workforce Transformation: An Academic Analysis of Post-Pandemic Tipping Point Dynamics Report this article Randy C. Randy C. Digital Transformation Leader | Naval Special Warfare \u2192 Inter-Agency \u2192 C-Suite \u2192 Startup Founder | Helping Organizations Navigate the Future of Work | MBA Kelley \u201926 Published Jul 21, 2025 + Follow Abstract This paper examines the convergence of multiple technological and social factors that have created a Gladwellian tipping point in workforce transformation, specifically focusing on artificial intelligence adoption and its intersection with post-pandemic workplace evolution. Through analysis of empirical data spanning YouTube content proliferation, micro-learning adoption rates, agentic AI emergence, LinkedIn platform evolution, and remote work normalization, we demonstrate that small, seemingly isolated changes have reached critical mass to fundamentally reshape organizational ecosystems. The research applies Malcolm Gladwell's tipping point framework\u2014the Law of the Few, Stickiness",
    "chunk_id": "downloaded_1763554644_0"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "rates, agentic AI emergence, LinkedIn platform evolution, and remote work normalization, we demonstrate that small, seemingly isolated changes have reached critical mass to fundamentally reshape organizational ecosystems. The research applies Malcolm Gladwell's tipping point framework\u2014the Law of the Few, Stickiness Factor, and Power of Context\u2014to understand how AI workforce transformation has crossed the threshold from gradual adoption to exponential spread. Introduction Malcolm Gladwell 's seminal work \"The Tipping Point\" (2000) defined the critical moment as \"that magic moment when an idea, trend, or social behavior crosses a threshold, tips, and spreads like wildfire.\" Gladwell's framework, originally applied to social epidemics, has gained renewed relevance in understanding post-pandemic organizational transformation. As Gladwell himself noted in his 2024 work \"Revenge of the Tipping Point,\" the COVID-19 pandemic created unique conditions for multiple tipping points to emerge simultaneously (Gladwell, 2024). The intersection of artificial intelligence adoption with post-pandemic workplace transformation presents a compelling case study for tipping point theory. This paper argues that we are witnessing not merely technological adoption, but a fundamental restructuring of workforce ecosystems driven by the convergence of multiple small changes that have reached critical mass. Literature Review and Theoretical Framework Post-Pandemic Tipping Point Theory Recent scholarship has identified the COVID-19 pandemic as a catalyst for multiple simultaneous tipping points across various domains (Kucharski, 2024). The pandemic created what researchers term \"perfect storm conditions\" where traditional resistance to change was temporarily suspended, allowing new behaviors to take root rapidly (Psychology Today, 2020). This aligns with Gladwell's \"Power of Context\" principle, which emphasizes that environmental conditions",
    "chunk_id": "downloaded_1763554644_1"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "The pandemic created what researchers term \"perfect storm conditions\" where traditional resistance to change was temporarily suspended, allowing new behaviors to take root rapidly (Psychology Today, 2020). This aligns with Gladwell's \"Power of Context\" principle, which emphasizes that environmental conditions determine whether a tipping point occurs. The remote work transformation exemplifies this phenomenon. Pre-pandemic, remote work adoption remained relatively static at approximately 5% for a decade (Corporate Rebels, 2020). However, by 2024, over 40% of U.S. workers had shifted to hybrid or fully remote arrangements (Gallup, 2023), representing what researchers identify as a clear tipping point moment (Lumin PDF, 2024). Gladwell's Three Laws Applied to AI Workforce Transformation The Law of the Few: Mavens, Connectors, and Salesmen Gladwell identified three types of people who drive tipping points: Mavens (knowledge specialists), Connectors (network hubs), and Salesmen (persuaders). In the AI workforce transformation, these roles are being filled by unexpected champions. Contemporary research identifies a new category of \"Learning Executives\"\u2014C-suite leaders who have personally engaged with AI development tools (Harvard Business Review, 2024). When executives can speak authentically about configuring API keys or debugging code, their credibility with technical teams increases exponentially, creating a new breed of maven who bridges strategic vision with technical reality. The Stickiness Factor: Democratization of Technical Capability The \"stickiness factor\" in AI workforce transformation lies in the democratization of technical capability through natural language programming interfaces. Y Combinator reports that over 25% of its startups now rely on AI for 95% of their codebase, while Google reveals that approximately 25% of its new",
    "chunk_id": "downloaded_1763554644_2"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "transformation lies in the democratization of technical capability through natural language programming interfaces. Y Combinator reports that over 25% of its startups now rely on AI for 95% of their codebase, while Google reveals that approximately 25% of its new code is AI-generated (Forbes, 2025). This represents a fundamental shift from incremental efficiency gains to transformational capability expansion. The emergence of \"vibe coding\"\u2014programming through natural language instructions to AI\u2014exemplifies this stickiness. Coined by AI researcher Andrej Karpathy, this approach allows business leaders to articulate requirements without traditional coding knowledge (MIT Technology Review, 2025). The stickiness comes from immediate, tangible results that make the technology not just useful, but essential. The Power of Context: Perfect Storm Conditions Current contextual factors create optimal conditions for AI workforce transformation: 1. Economic Pressure: Organizations face unprecedented pressure to achieve exponential productivity gains rather than incremental improvements. 2. Talent Scarcity: The shortage of technical talent has reached crisis levels, with AI-assisted development offering a path to scale capability without proportionally scaling headcount. 3. Generational Shift: Digital natives entering the workforce expect AI integration and are frustrated by its absence rather than fearful of its presence. 4. Platform Evolution: LinkedIn's transformation from networking platform to content ecosystem has created new channels for thought leadership and knowledge dissemination. Empirical Evidence of Tipping Point Dynamics YouTube AI Content Proliferation Analysis of YouTube content trends reveals exponential growth in AI-related educational content. The platform has experienced a 400% increase in AI tutorial and thought leadership content between 2023 and 2024 (YouTube Trends, 2024). This proliferation",
    "chunk_id": "downloaded_1763554644_3"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "Dynamics YouTube AI Content Proliferation Analysis of YouTube content trends reveals exponential growth in AI-related educational content. The platform has experienced a 400% increase in AI tutorial and thought leadership content between 2023 and 2024 (YouTube Trends, 2024). This proliferation represents what researchers term \"knowledge democratization,\" where complex technical concepts become accessible to non-technical audiences through micro-learning formats. The rise of AI content creators has fundamentally altered the knowledge acquisition landscape. Traditional gatekeepers\u2014universities, corporate training programs, technical certifications\u2014are being bypassed by just-in-time learning delivered through short-form video content. This shift represents a classic tipping point dynamic where small changes in content accessibility create massive shifts in learning behavior. Micro-Learning vs. Traditional Education Empirical data demonstrates a clear tipping point in learning preferences. Micro-learning platforms report completion rates of 83% compared to traditional training's 20-30% completion rates (SC Training, 2019). This 4:1 advantage in engagement represents more than incremental improvement\u2014it signals a fundamental shift in how knowledge workers acquire new skills. The COVID-19 pandemic accelerated this transition by normalizing self-directed, technology-mediated learning. When traditional educational institutions were forced online, learners discovered that bite-sized, on-demand content often provided superior outcomes to traditional lecture formats. This discovery created a permanent shift in learning expectations and behaviors. Agentic AI Discussion Evolution Perhaps the most striking evidence of tipping point dynamics is the evolution of agentic AI discourse. Six months ago, discussions of autonomous AI agents were largely confined to academic circles and specialized conferences. Today, agentic AI has become a mainstream business topic, with Gartner predicting that 33% of enterprise",
    "chunk_id": "downloaded_1763554644_4"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "is the evolution of agentic AI discourse. Six months ago, discussions of autonomous AI agents were largely confined to academic circles and specialized conferences. Today, agentic AI has become a mainstream business topic, with Gartner predicting that 33% of enterprise software applications will include agentic AI by 2028, up from less than 1% in 2024 (Gartner, 2024). This represents a classic Gladwellian moment where a concept crosses from specialized knowledge to mainstream adoption. The speed of this transition\u2014from academic curiosity to enterprise priority in less than twelve months\u2014exemplifies the exponential spread characteristic of tipping point phenomena. LinkedIn Platform Evolution LinkedIn's transformation from professional networking platform to content ecosystem provides compelling evidence of contextual tipping point dynamics. The platform's algorithm updates in 2024 prioritized knowledge-sharing content and thought leadership, creating new pathways for professional influence (Hootsuite, 2025). Data from LinkedIn reveals a 300% increase in thought leadership content engagement between 2023 and 2024 (LinkedIn Business, 2024). This shift has democratized professional influence, allowing individual contributors to build audiences traditionally reserved for corporate executives or published authors. The platform's evolution has created new categories of professional influence that bypass traditional hierarchical structures. Remote Work Normalization The normalization of remote work represents perhaps the most visible tipping point of the post-pandemic era. Bureau of Labor Statistics data shows that remote work adoption increased from 7% pre-pandemic to over 40% by 2024 (BLS, 2024). This represents a 6:1 increase that fundamentally altered workplace expectations and organizational structures. The persistence of remote work arrangements despite corporate return-to-office mandates demonstrates the irreversible",
    "chunk_id": "downloaded_1763554644_5"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "remote work adoption increased from 7% pre-pandemic to over 40% by 2024 (BLS, 2024). This represents a 6:1 increase that fundamentally altered workplace expectations and organizational structures. The persistence of remote work arrangements despite corporate return-to-office mandates demonstrates the irreversible nature of this tipping point. When Amazon and other major corporations implemented five-day office requirements, they faced significant employee resistance and talent retention challenges (Colorado Today, 2024). This resistance indicates that remote work has crossed from accommodation to expectation\u2014a classic tipping point characteristic. Synthesis: The Convergence Effect The simultaneous occurrence of these individual tipping points creates what we term a \"convergence effect\"\u2014where multiple small changes reinforce each other to create systemic transformation. The AI workforce transformation is not driven by any single factor, but by the intersection of: - Democratized learning through YouTube and micro-learning platforms - Normalized remote work creating demand for digital collaboration tools - LinkedIn's evolution enabling new forms of professional influence - Agentic AI emergence providing autonomous capability - Economic pressure demanding exponential rather than incremental gains This convergence creates what complexity theorists call \"emergent behavior\"\u2014outcomes that are greater than the sum of their parts. Individual executives learning to code, remote workers adopting AI tools, and thought leaders sharing knowledge through social platforms combine to create organizational transformation that exceeds what any single factor could achieve. Implications for Organizational Leadership The convergence of these tipping points creates both opportunities and challenges for organizational leaders: Capability vs. Dependency: Organizations must build AI capability without creating dangerous dependencies. The answer lies in understanding, not",
    "chunk_id": "downloaded_1763554644_6"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "single factor could achieve. Implications for Organizational Leadership The convergence of these tipping points creates both opportunities and challenges for organizational leaders: Capability vs. Dependency: Organizations must build AI capability without creating dangerous dependencies. The answer lies in understanding, not just using technology. Leaders who engage directly with AI development tools gain credibility and insight that pure delegation cannot provide. Speed vs. Quality: Maintaining quality standards while development velocity increases exponentially requires new approaches to testing, security, and governance. Traditional quality assurance methods designed for human-generated code may be inadequate for AI-generated systems. Human vs. Machine: Preserving human judgment and creativity while leveraging machine efficiency requires complementarity rather than replacement. The most successful organizations will be those that enhance human capability rather than substitute it. Learning vs. Knowing: Building organizations that can learn faster than technology evolves demands a fundamental shift from knowledge-based to learning-based cultures. Static expertise becomes less valuable than adaptive learning capability. Conclusion The AI workforce transformation represents a classic Gladwellian tipping point where small, seemingly isolated changes have reached critical mass to create systemic transformation. The convergence of YouTube content proliferation, micro-learning adoption, agentic AI emergence, LinkedIn platform evolution, and remote work normalization has created perfect storm conditions for exponential change. Organizations and leaders who recognize this tipping point moment and position themselves accordingly will define the post-transformation landscape. Those who treat current changes as temporary disruptions rather than permanent shifts risk being swept along by forces they failed to understand or anticipate. The lesson from Dorothy Vaughan's adaptation to IBM computers",
    "chunk_id": "downloaded_1763554644_7"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "themselves accordingly will define the post-transformation landscape. Those who treat current changes as temporary disruptions rather than permanent shifts risk being swept along by forces they failed to understand or anticipate. The lesson from Dorothy Vaughan's adaptation to IBM computers at NASA remains relevant: when technology changes, leaders have two choices. Learn to wield it, or be replaced by those who do. The tipping point is here. The question is not whether AI will transform the workforce, but whether leaders will drive that transformation or be driven by it. References Bureau of Labor Statistics. (2024). Remote work productivity and trends. Retrieved from https://www.bls.gov/opub/btn/volume-13/remote-work-productivity.htm Corporate Rebels. (2020). The remote revolution: Are we reaching the tipping point? Retrieved from https://www.corporate-rebels.com/blog/the-remote-revolution Forbes. (2025). What is vibe coding? And why should you care? Retrieved from https://www.forbes.com/sites/nishatalagala/2025/03/30/what-is-vibe-coding-and-why-should-you-care/ Gallup. (2023). The future of the office has arrived: It's hybrid. Retrieved from https://www.gallup.com/workplace/511994/future-office-arrived-hybrid.aspx Gartner. (2024). Gartner names agentic AI top tech trend for 2025. Retrieved from https://thejournal.com/articles/2024/10/23/gartner-names-agentic-ai-top-tech-trend-for-2025.aspx Gladwell, M. (2000). The tipping point: How little things can make a big difference. Little, Brown and Company. Gladwell, M. (2024). Revenge of the tipping point: Overstories, superspreaders, and the rise of social engineering. Little, Brown and Company. Harvard Business Review. (2024). What is agentic AI, and how will it change work? Retrieved from https://hbr.org/2024/12/what-is-agentic-ai-and-how-will-it-change-work Hootsuite. (2025). How the LinkedIn algorithm works in 2025. Retrieved from https://blog.hootsuite.com/linkedin-algorithm/ Kucharski, A. (2024). The real revenge of the tipping point. Retrieved from https://kucharski.substack.com/p/the-real-revenge-of-the-tipping-point LinkedIn Business. (2024). LinkedIn creative trends: Looking back at 2024 through a data lens. Retrieved from",
    "chunk_id": "downloaded_1763554644_8"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "(2025). How the LinkedIn algorithm works in 2025. Retrieved from https://blog.hootsuite.com/linkedin-algorithm/ Kucharski, A. (2024). The real revenge of the tipping point. Retrieved from https://kucharski.substack.com/p/the-real-revenge-of-the-tipping-point LinkedIn Business. (2024). LinkedIn creative trends: Looking back at 2024 through a data lens. Retrieved from https://www.linkedin.com/business/marketing/blog/marketing-collective/linkedin-creative-trends-looking-back-at-2024-through-a-data-lens Lumin PDF. (2024). Why right now is remote work's tipping point. Retrieved from https://www.luminpdf.com/blog/why-right-now-is-remote-works-tipping-point/ MIT Technology Review. (2025). What is vibe coding, exactly? Retrieved from https://www.technologyreview.com/2025/04/16/1115135/what-is-vibe-coding-exactly/ Psychology Today. (2020). At the tipping point: Behavior change lessons from the pandemic. Retrieved from https://www.psychologytoday.com/us/blog/the-conservation-psychologist/202006/at-the-tipping-point-behavior-change-lessons-from-the SC Training. (2019). Microlearning vs traditional learning. Retrieved from https://training.safetyculture.com/blog/transitioning-from-traditional-classroom-training-to-microlearning/ University of Colorado Today. (2024). The 5-day office mandate: A tipping point for employee well-being? Retrieved from https://www.colorado.edu/today/2024/10/23/5-day-office-mandate-tipping-point-employee-well-being YouTube Trends. (2024). YouTube trends in 2024: Shorts, AI, reactions. Retrieved from https://prodvigate.com/blog/YouTube-Trends-in-2024-Shorts-AI-Reactions/ Like Comment Copy LinkedIn Facebook X Share 30 9 Comments Spencer Belsky Product @ Meta || founder @leanaireport.com || Ex Professional Skier 3mo Report this comment This is dope insight on AI and workforce transformation! Like Reply 1 Reaction Alex Barsi Lopes Associate Chair for Operations and Decision Technologies Graduate Programs - Clinical Professor - Grant Thornton Scholar at Indiana University - Kelley School of Business 3mo Report this comment Randy Cook, you are ahead of the curve: https://www.mckinsey.com/capabilities/people-and-organizational-performance/our-insights/we-are-all-techies-now-digital-skill-building-for-the-future Like Reply 1 Reaction 2 Reactions Viren Tailor, MBA Vice President, Preferred Banking Financial Center Manager at Bank of America. 3mo Report this comment That is absolutely wonderful, Randy. Congratulations, and I am very proud of you. Please continue your excellent work, and it will take you far. Like Reply 1 Reaction 2",
    "chunk_id": "downloaded_1763554644_9"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "Financial Center Manager at Bank of America. 3mo Report this comment That is absolutely wonderful, Randy. Congratulations, and I am very proud of you. Please continue your excellent work, and it will take you far. Like Reply 1 Reaction 2 Reactions Rita Sola Cook 3mo Report this comment Nicely done and thank you for helping me adopt AI to find a more efficient way at to digest large amounts of content down to key points. Proud of you! Like Reply 1 Reaction 2 Reactions \ud83e\udded Jenny McAlmond VP North America and Europe | Partner to businesses building Philippine offshore dedicated staffing and offices. 3mo Report this comment Congratulations, and this post comes at a perfect time in conversations I am having with a mentor in being prepared for what's to come. There's a lot to review in your article, but thank you for writing it; it will be helpful. Like Reply 1 Reaction See more comments To view or add a comment, sign in More articles by Randy C. The AI Governance Gap: Why We Can't Afford a 20-Year Regulatory Lag Aug 1, 2025 The AI Governance Gap: Why We Can't Afford a 20-Year Regulatory Lag After two decades of helping organizations navigate technological disruption across government and private sectors\u2026 17 The Decentralized Future: What Businesses Need to Know for 2025 and Beyond Feb 12, 2025 The Decentralized Future: What Businesses Need to Know for 2025 and Beyond The world is rapidly moving toward decentralization\u2014driven by blockchain, decentralized finance (DeFi), and\u2026 24 Navigating My MBA Journey:",
    "chunk_id": "downloaded_1763554644_10"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "Need to Know for 2025 and Beyond Feb 12, 2025 The Decentralized Future: What Businesses Need to Know for 2025 and Beyond The world is rapidly moving toward decentralization\u2014driven by blockchain, decentralized finance (DeFi), and\u2026 24 Navigating My MBA Journey: Insights and Impacts from the First Semester Apr 30, 2024 Navigating My MBA Journey: Insights and Impacts from the First Semester As a seasoned professional deeply involved in both running my own company and directing others, the decision to pursue\u2026 50 7 Comments Workforce resilience \u2013 a kinetic approach to organizational health Sep 8, 2022 Workforce resilience \u2013 a kinetic approach to organizational health With recent challenges across the world and rapidly evolving workforce dynamics business leaders must understand\u2026 34 2 Comments Coronavirus: A Global Insurgency Apr 4, 2020 Coronavirus: A Global Insurgency The country is witnessing our healthcare professionals transform into a battle tested force engaged in a global counter\u2026 35 4 Comments THE WATER COOLER IS GONE! Apr 12, 2019 THE WATER COOLER IS GONE! If you are reading this, you have most assuredly been aware that the landscape of corporate life has not only been\u2026 7 Reinventing Healthcare in the Developing World \u2013 Breaking down Barriers in South Sudan. May 2, 2017 Reinventing Healthcare in the Developing World \u2013 Breaking down Barriers in South Sudan. After challenging the status quo with improved healthcare in West Africa, Aspen Medical International (AMI) has entered\u2026 11 1 Comment AMI supports the World Health Organization in Mosul, Iraq. Mar 29, 2017 AMI supports the World Health Organization",
    "chunk_id": "downloaded_1763554644_11"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "South Sudan. After challenging the status quo with improved healthcare in West Africa, Aspen Medical International (AMI) has entered\u2026 11 1 Comment AMI supports the World Health Organization in Mosul, Iraq. Mar 29, 2017 AMI supports the World Health Organization in Mosul, Iraq. US company chosen to help re-build Mosul\u2019s healthcare system as part of the global humanitarian effort in Iraq\u2026 Aspen Medical South Sudan: Continues to increase medical services in Juba Feb 10, 2017 Aspen Medical South Sudan: Continues to increase medical services in Juba Aspen Medical South Sudan is proud to announce the 8 February official launch of its emergency ambulance service in\u2026 18 4 Comments Aspen Medical International \u2013 South Sudan is officially open! Dec 12, 2016 Aspen Medical International \u2013 South Sudan is officially open! After months of planning and preparations Aspen Medical South Sudan (AMSS) has opened its doors for operations. The\u2026 40 8 Comments Show more See all articles Explore content categories Career Productivity Finance Soft Skills & Emotional Intelligence Project Management Education Technology Leadership Ecommerce User Experience Recruitment & HR Customer Experience Real Estate Marketing Sales Retail & Merchandising Science Supply Chain Management Future Of Work Consulting Writing Economics Artificial Intelligence Employee Experience Workplace Trends Fundraising Networking Corporate Social Responsibility Negotiation Communication Engineering Hospitality & Tourism Business Strategy Change Management Organizational Culture Design Innovation Event Planning Training & Development Show more Show less LinkedIn \u00a9 2025 About Accessibility User Agreement Privacy Policy Cookie Policy Copyright Policy Brand Policy Guest Controls Community Guidelines \u0627\u0644\u0639\u0631\u0628\u064a\u0629 (Arabic) \u09ac\u09be\u0982\u09b2\u09be (Bangla) \u010ce\u0161tina (Czech) Dansk",
    "chunk_id": "downloaded_1763554644_12"
  },
  {
    "doc": "downloaded_1763554644.txt",
    "chunk": "Management Organizational Culture Design Innovation Event Planning Training & Development Show more Show less LinkedIn \u00a9 2025 About Accessibility User Agreement Privacy Policy Cookie Policy Copyright Policy Brand Policy Guest Controls Community Guidelines \u0627\u0644\u0639\u0631\u0628\u064a\u0629 (Arabic) \u09ac\u09be\u0982\u09b2\u09be (Bangla) \u010ce\u0161tina (Czech) Dansk (Danish) Deutsch (German) \u0395\u03bb\u03bb\u03b7\u03bd\u03b9\u03ba\u03ac (Greek) English (English) Espa\u00f1ol (Spanish) \u0641\u0627\u0631\u0633\u06cc (Persian) Suomi (Finnish) Fran\u00e7ais (French) \u0939\u093f\u0902\u0926\u0940 (Hindi) Magyar (Hungarian) Bahasa Indonesia (Indonesian) Italiano (Italian) \u05e2\u05d1\u05e8\u05d9\u05ea (Hebrew) \u65e5\u672c\u8a9e (Japanese) \ud55c\uad6d\uc5b4 (Korean) \u092e\u0930\u093e\u0920\u0940 (Marathi) Bahasa Malaysia (Malay) Nederlands (Dutch) Norsk (Norwegian) \u0a2a\u0a70\u0a1c\u0a3e\u0a2c\u0a40 (Punjabi) Polski (Polish) Portugu\u00eas (Portuguese) Rom\u00e2n\u0103 (Romanian) \u0420\u0443\u0441\u0441\u043a\u0438\u0439 (Russian) Svenska (Swedish) \u0c24\u0c46\u0c32\u0c41\u0c17\u0c41 (Telugu) \u0e20\u0e32\u0e29\u0e32\u0e44\u0e17\u0e22 (Thai) Tagalog (Tagalog) T\u00fcrk\u00e7e (Turkish) \u0423\u043a\u0440\u0430\u0457\u043d\u0441\u044c\u043a\u0430 (Ukrainian) Ti\u1ebfng Vi\u1ec7t (Vietnamese) \u7b80\u4f53\u4e2d\u6587 (Chinese (Simplified)) \u6b63\u9ad4\u4e2d\u6587 (Chinese (Traditional)) Language",
    "chunk_id": "downloaded_1763554644_13"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "Source: https://relevanceai.com/learn/what-is-the-ai-workforce What is the AI Workforce? - Relevance AI Recruit your AI BDR AgentLearn more InstructionsTo make this component work follow these steps:Remove the delete-this-class class from the navbar13_component div. This will change the positioning of the navbar to fixed.Add the navbar-on-page class to the page-wrapper class. This will ensure that the navbar is centered on the page.Add the max-width-full class to the main-wrapper class. This will ensure all sections inside of the main wrapper are full-wdith.Product AI AgentsBuild an AI Agent in seconds.AI WorkforceCreate & manage AI teams.AI ToolsGive AI agents superpowers. IntegrationsPower your AI agents. APIEasily trigger your AI agents.FEATURES InventCreate custom AI Agents just by describing them. MetadataCapture high-value data from every agent task, automatically. SchedulingControl when your AI agents run, and how much they do. ApprovalsControl when you need, automation when you don\u2019t. KnowledgeGive every agent the context your best people rely on. Version ControlTrack, test, and restore your AI agents and tools with ease. Collaboration & SharingWork solo or scale as a team, with total clarity. Chat EmbedTurn any AI Agent into a live chat experience.Phone AgentAdd voice-calling superpowers to your product.Relevance ChatUse agents like teammates.Function BY TEAM SalesCreate custom AI Agents just by describing them. MarketingCapture high-value data from every agent task, automatically. Customer SupportControl when your AI agents run, and how much they do. ResearchControl when you need, automation when you don\u2019t. OperationsGive every agent the context your best people rely on.LATEST BLOGS Qualified vs. Drift: Choosing the Right Solution for Real-Time Pipeline GenerationHow to Submit to the",
    "chunk_id": "downloaded_1763554647_0"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "run, and how much they do. ResearchControl when you need, automation when you don\u2019t. OperationsGive every agent the context your best people rely on.LATEST BLOGS Qualified vs. Drift: Choosing the Right Solution for Real-Time Pipeline GenerationHow to Submit to the Relevance AI MarketplaceAgents USE CASES AI BDR AgentBooking meetings 24/7. Lifecycle MarketerMessage every customer like they are your only customer. Account ResearcherHuman-quality account research on autopilot. CRM EnrichmentEnrich your CRM with real-time. Inbound QualificationQualify and Book Meetings. SEOAutomatically generate SEO content & pages. Inbox ManagerManage inbound replies and execute personalized follow-ups. Customer SupportAutomatically handle support requests. Sales NotetakerCapture every detail from your sales calls. MRP AgentGet complex work done with simple tools.LATEST DROP The Definitive Guide: Understanding AI Agents vs. AI WorkflowsResources RESOURCES Documentation Blog Customers Community Changelog Templates Careers What is the AI Workforce Partner DirectoryBecome PartnerAffiliate ProgramCUSTOMERS Inside Send Payments' AI-First StrategyRead moreLEARN What is the AI WorkforceEnterprisePricingSimple Menu Link FiveLink SixLink SevenLoginTalk to SalesSign UpProduct AI AgentsBuild an AI Agent in seconds.AI WorkforceCreate & manage AI teams.AI ToolsGive AI agents superpowers. IntegrationsPower your AI agents. APIEasily trigger your AI agents.FEATURES InventCreate custom AI Agents just by describing them. MetadataCapture high-value data from every agent task, automatically. SchedulingControl when your AI agents run, and how much they do. ApprovalsControl when you need, automation when you don\u2019t. KnowledgeGive every agent the context your best people rely on. Version ControlTrack, test, and restore your AI agents and tools with ease. Collaboration & SharingWork solo or scale as a team, with total clarity. Chat EmbedTurn any AI",
    "chunk_id": "downloaded_1763554647_1"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "you don\u2019t. KnowledgeGive every agent the context your best people rely on. Version ControlTrack, test, and restore your AI agents and tools with ease. Collaboration & SharingWork solo or scale as a team, with total clarity. Chat EmbedTurn any AI Agent into a live chat experience.Phone AgentAdd voice-calling superpowers to your product.Relevance ChatUse agents like teammates.Function BY TEAM SalesCreate custom AI Agents just by describing them. MarketingCapture high-value data from every agent task, automatically. Customer SupportControl when your AI agents run, and how much they do. ResearchControl when you need, automation when you don\u2019t. OperationsGive every agent the context your best people rely on.LATEST BLOGS Qualified vs. Drift: Choosing the Right Solution for Real-Time Pipeline GenerationHow to Submit to the Relevance AI MarketplaceAgents USE CASES AI BDR AgentBooking meetings 24/7. Lifecycle MarketerMessage every customer like they are your only customer. Account ResearcherHuman-quality account research on autopilot. CRM EnrichmentEnrich your CRM with real-time. Inbound QualificationQualify and Book Meetings. SEOAutomatically generate SEO content & pages. Inbox ManagerManage inbound replies and execute personalized follow-ups. Customer SupportAutomatically handle support requests. Sales NotetakerCapture every detail from your sales calls. MRP AgentGet complex work done with simple tools.LATEST DROP The Definitive Guide: Understanding AI Agents vs. AI WorkflowsResources RESOURCES Documentation Blog Customers Community Changelog Templates Careers What is the AI Workforce Partner DirectoryBecome PartnerAffiliate ProgramCUSTOMERS Inside Send Payments' AI-First StrategyRead moreLEARN What is the AI WorkforceEnterprisePricingSimple Menu Link FiveLink SixLink SevenLoginTalk to SalesSign UpLoginTalk to SalesSign UpInstructionsTo make this component work follow these steps:Remove the delete-this-class class from the navbar13_component div. This",
    "chunk_id": "downloaded_1763554647_2"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "DirectoryBecome PartnerAffiliate ProgramCUSTOMERS Inside Send Payments' AI-First StrategyRead moreLEARN What is the AI WorkforceEnterprisePricingSimple Menu Link FiveLink SixLink SevenLoginTalk to SalesSign UpLoginTalk to SalesSign UpInstructionsTo make this component work follow these steps:Remove the delete-this-class class from the navbar13_component div. This will change the positioning of the navbar to fixed.Add the navbar-on-page class to the page-wrapper class. This will ensure that the navbar is centered on the page.Add the max-width-full class to the main-wrapper class. This will ensure all sections inside of the main wrapper are full-wdith.LoginTalk to SalesSign UpProduct AI AgentsBuild an AI Agent in seconds.AI WorkforceCreate & manage AI teams.AI ToolsGive AI agents superpowers. IntegrationsPower your AI agents. APIEasily trigger your AI agents.FEATURES InventCreate custom AI Agents just by describing them. MetadataCapture high-value data from every agent task, automatically. SchedulingControl when your AI agents run, and how much they do. ApprovalsControl when you need, automation when you don\u2019t. KnowledgeGive every agent the context your best people rely on. Version ControlTrack, test, and restore your AI agents and tools with ease. Collaboration & SharingWork solo or scale as a team, with total clarity. Chat EmbedTurn any AI Agent into a live chat experience.Phone AgentAdd voice-calling superpowers to your product.Relevance ChatUse agents like teammates.Function BY TEAM SalesCreate custom AI Agents just by describing them. MarketingCapture high-value data from every agent task, automatically. Customer SupportControl when your AI agents run, and how much they do. ResearchControl when you need, automation when you don\u2019t. OperationsGive every agent the context your best people rely on.LATEST BLOGS Qualified vs. Drift: Choosing",
    "chunk_id": "downloaded_1763554647_3"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "from every agent task, automatically. Customer SupportControl when your AI agents run, and how much they do. ResearchControl when you need, automation when you don\u2019t. OperationsGive every agent the context your best people rely on.LATEST BLOGS Qualified vs. Drift: Choosing the Right Solution for Real-Time Pipeline GenerationHow to Submit to the Relevance AI MarketplaceAgents USE CASES AI BDR AgentBooking meetings 24/7. Lifecycle MarketerMessage every customer like they are your only customer. Account ResearcherHuman-quality account research on autopilot. CRM EnrichmentEnrich your CRM with real-time. Inbound QualificationQualify and Book Meetings. SEOAutomatically generate SEO content & pages. Inbox ManagerManage inbound replies and execute personalized follow-ups. Customer SupportAutomatically handle support requests. Sales NotetakerCapture every detail from your sales calls. MRP AgentGet complex work done with simple tools.LATEST DROP The Definitive Guide: Understanding AI Agents vs. AI WorkflowsResources RESOURCES Documentation Blog Customers Community Changelog Templates Careers What is the AI Workforce Partner DirectoryBecome PartnerAffiliate ProgramCUSTOMERS Inside Send Payments' AI-First StrategyRead moreLEARN What is the AI WorkforceEnterprisePricingSimple Menu Link FiveLink SixLink SevenLoginTalk to SalesSign UpWhat is the AI Workforce?Sign up for freeFree planNo card requiredTable of ContentsThe AI workforce is a team of diverse AI agents equipped with AI tools. These agents work collaboratively in a multi-agent system to solve complex tasks.The pace of innovation in artificial intelligence is accelerating at an astounding rate. Technologies that were once only theoretical are now becoming practical realities. Companies across industries are increasingly adopting AI to automate tasks, enhance productivity and create new possibilities.There is one particular area in AI that has even captured the",
    "chunk_id": "downloaded_1763554647_4"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "astounding rate. Technologies that were once only theoretical are now becoming practical realities. Companies across industries are increasingly adopting AI to automate tasks, enhance productivity and create new possibilities.There is one particular area in AI that has even captured the fascination of legendary technologists like Bill Gates and Vinod Khosla, that is AI agents - A type of AI system that is designed to act autonomously and accomplish even complex tasks on behalf of a user, it is able to plan, reason, react and make actions.In less than ten years each American will have a dozen or more AI agents constantly running around the net with AI that is 10x more powerful.Vinod Khosla, early investor in OpenAI, founder of Suns Microsystems and Khosla Venture.Agents are coming. In the next few years, they will utterly change how we live our lives, online and off.Bill Gates, Founder of Microsoft.With this increasing adoption and development of AI agents, the birth of a new segment to the workforce is becoming increasingly important - the AI workforce. Every company will have not just a human workforce but also an AI workforce working in tandem. Teams will only be limited by their ideas, not their size.How do you build an AI workforce?\u200d\u200dTo build an AI Workforce there are three core building blocks to it:AI agents: they are digital workers that given instructions will complete a task. These AI agents are powered by LLMs such as GPT, Mistral, Claude and more. These need to be meticulously created to be effective. They need to",
    "chunk_id": "downloaded_1763554647_5"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "to it:AI agents: they are digital workers that given instructions will complete a task. These AI agents are powered by LLMs such as GPT, Mistral, Claude and more. These need to be meticulously created to be effective. They need to be exceptionally well-instructed and well-constructed so they can run with any technical errors. This is before we get towards human level reasoning, thoughts, and actionsTools for the Agents: In order for Agents to ascend from just generating text it needs to be given access to AI tools such as \u201cgoogle search\u201d, \u201cuse salesforce\u201d, \u201crun code\u201d to give it real superpowers to automate tasks.Multi-agent system: In order for agents to work collaboratively like a team, you\u2019ll need a multi-agent system, which allows different types of diverse agents to interact and speak with each other. A team of AI agents will always be more effective than 1.An effective AI workforce is one that has a diverse team of AI agents that are domain experts, each equipped with powerful and relevant tools for that domain and working in a multi-agent system.What are AI Agents?AI agents can be broadly classified into two categories based on their level of autonomy and the nature of their interaction with users: Co-pilot and Autopilot.Co-pilot Agents - AI in the LoopCo-pilot agents are a widespread form of AI agents, designed to work alongside humans and augment our productivity. AI in the loop refers to the practice of actively involving AI systems in the decision-making process, while still maintaining human oversight and control. They are integrated",
    "chunk_id": "downloaded_1763554647_6"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "form of AI agents, designed to work alongside humans and augment our productivity. AI in the loop refers to the practice of actively involving AI systems in the decision-making process, while still maintaining human oversight and control. They are integrated into various tools and platforms, assisting with tasks and streamlining workflows. In fact, according to a recent report, the global AI co-pilot market is projected to reach $23.1 billion by 2027, growing at a Compound Annual Growth Rate (CAGR) of 38.4% during the forecast period. Additionally, a survey by Gartner found that 75% of organizations have already deployed or plan to deploy co-pilot agents in the next year. Here are some examples of co-pilot agents in use:Github Co-pilot for coding. Embedded directly into visual studio code and github to help developers write effective code more quickly and focus on the core parts of building durable software such as logic.Microsoft 365 Co-pilot for presentations. Embedded directly into Microsoft suite like Microsoft PowerPoint to help you create PowerPoints more effectively\u200dNotion AI for writing. Embedded directly into notion to help you create notion documents more effectively.\u200dAutopilot Agents - Human in the LoopAutopilot agents different to co-pilots in that they are designed to act autonomously, interacting with tools as a human would, and instead require humans to supervise or manage them. Autopilot agents represent a significant advancement in AI technology, capable of autonomously completing tasks with minimal human intervention. However, even with their advanced capabilities, these agents are not yet perfect and sometimes require human oversight to ensure accuracy and",
    "chunk_id": "downloaded_1763554647_7"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "them. Autopilot agents represent a significant advancement in AI technology, capable of autonomously completing tasks with minimal human intervention. However, even with their advanced capabilities, these agents are not yet perfect and sometimes require human oversight to ensure accuracy and precision. This is where the \"human-in-the-loop\" approach comes in, allowing humans to review and correct the decisions made by autopilot agents. This collaborative approach enables the benefits of automation while still leveraging human judgment and expertise, and is particularly useful in high-stakes applications such as healthcare, finance, and transportation.\u200d\u200dKlarna recently announced that their customer support autopilot chatbot handled 2.3 million customer service chats in 35 languages worldwide during its first four weeks. This volume equates to the workload of 700 full-time human agents. Klarna reported that their autopilot achieved customer satisfaction ratings equal to its human team members. It also showed higher accuracy than humans with a 25 per cent reduction in repeat inquiries. Moreover, it can resolve tickets in less than 2 minutes, compared to the previous benchmark of 11 minutes.\u200dAI in the Loop (AITL) versus Human in the Loop (HITL)As AI technology continues to advance and become increasingly integrated into various aspects of our lives, it's essential to understand the different approaches to human-AI collaboration. Two prominent paradigms have emerged: Human in the Loop (HITL) and AI in the Loop (AITL). While both approaches aim to leverage the strengths of humans and AI, they differ significantly in their underlying philosophy, application, and benefits.Key differences:Level of autonomy: HITL has higher autonomy, as AI makes decisions",
    "chunk_id": "downloaded_1763554647_8"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "(HITL) and AI in the Loop (AITL). While both approaches aim to leverage the strengths of humans and AI, they differ significantly in their underlying philosophy, application, and benefits.Key differences:Level of autonomy: HITL has higher autonomy, as AI makes decisions and humans only review and correct when necessary, whereas AITL has lower autonomy, as AI acts as a co-pilot, providing recommendations for human decision-making.Role of humans: In HITL, humans have a reviewing and correcting role, while in AITL, humans have a decision-making role, with AI providing support.Decision-making process: HITL involves AI making decisions, followed by human review and correction, while AITL involves humans making decisions, with AI providing recommendations.Applications: HITL is suited for applications where AI is highly advanced and accurate, such as data processing and analysis, while AITL is suitable for complex decision-making and creative tasks.Benefits: HITL ensures efficiency and accuracy, while AITL enhances human capabilities and provides additional insights.\u200dHow to make an effective agent?Creating an effective AI agent requires a thoughtful and systematic approach. It involves combining cutting-edge technologies like machine learning and natural language processing with a deep understanding of the agent's intended goals, tasks, and environment. By carefully designing and training an AI agent, developers can unlock its full potential and create a powerful tool that enhances productivity, decision-making, and overall performance.\u200dThere are 5 core components:Large Language Model (LLM)At the heart of any AI agent is a powerful foundational model, usually what's known as a large language model. Unlike simple rules-based chatbots, LLMs like GPT4 and Anthropic's Claude can understand nuanced language,",
    "chunk_id": "downloaded_1763554647_9"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "are 5 core components:Large Language Model (LLM)At the heart of any AI agent is a powerful foundational model, usually what's known as a large language model. Unlike simple rules-based chatbots, LLMs like GPT4 and Anthropic's Claude can understand nuanced language, generate coherent long-form text, and even execute logical reasoning when prompted appropriately.System PromptThe system prompt serves as the personality and reasoning patterns for the AI agent. Carefully engineered prompts prime the LLM to respond appropriately as that agent, whether as a helpful assistant, curious child, or domain expert. There are many kinds of different system prompts that can enable different kinds of reasoning behaviour such as Chain of thought, Tree of thought, ReAct and more.MemoryIn addition to analyzing the current input text, effective AI agents need memory of past interactions and context. This could be a simple short-term memory to recall the last few exchanges or a more comprehensive long-term memory component. With memory, agents can have true conversations that reference shared history and maintain logical consistency.FeedbackIt is crucial that the Agent is receiving feedback from the user on good and bad actions. This feedback can then be incorporated via fine-tuning the model using methods like RLHF.Tools for agentsWhile LLMs can generate remarkable text, agents need additional tools to take meaningful actions. This could include APIs to look up information, integrate with calendars, or complete transactions. With tools, agents can go beyond chat to truly assist users across applications.Together, these four components enable AI agents that understand, learn, reason, and act in an intelligent manner. The",
    "chunk_id": "downloaded_1763554647_10"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "to look up information, integrate with calendars, or complete transactions. With tools, agents can go beyond chat to truly assist users across applications.Together, these four components enable AI agents that understand, learn, reason, and act in an intelligent manner. The rapid evolution of these core capabilities is bringing us closer to artificial general intelligence. The next generation of AI agents will collaborate with humans seamlesslyTools for AI agents - Giving Agents the ability to interact with the worldIn order for agents to ascend from just generating text and interacting with the real world, it needs to be given access to tools.For those with an engineering background you can think of tools like functions. They are \u2018skills\u2019 that an agent can call and execute when it deems the task requires it.There are 3 core types of tools that is useful in making an agent powerful.Source of truth tools. These are knowledge bases, files where the agent can access data about different topics to answer new questions. E.g. \u201cLegislation lookup\u201d, \u201cHR manual\u201d\u200dFunctional tools. These are APIs / integrations to run some sort of action. E.g. \u201cSend an email\u201dSkill based tools. These are use case specific workflows constructed by domain experts that can be made up of multiple LLMs each with expert crafted prompts, and other tools. E.g. \u201cHow to reply to an NDA request professionally.\u201dHere are some examples of tools being utilized in both a co-pilot and autopilot system:This co-pilot example shows a tool that can find the job title, company, and company size of a person given",
    "chunk_id": "downloaded_1763554647_11"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "to reply to an NDA request professionally.\u201dHere are some examples of tools being utilized in both a co-pilot and autopilot system:This co-pilot example shows a tool that can find the job title, company, and company size of a person given an email address. This is a GPT built in ChatGPT using our Custom Actions for GPTs feature.\u200dThis auto-pilot example shows a writing agent that has the tools for Google Search and Website Scraping. So they can do desk research using Google and then scrape the content from the results to summarize and help them write an article. This is built in Relevance AI.\u200d\u200dWhat are Multi-agent Systems?Often the work we do in teams require expertise from different disciplines in order to effectively complete a task. For example when you are launching a very simple feature of a product you need. A product marketer to manage the launch, a content creator to write a landing page and help documentation, a designer to design the landing page, a data analyst to report on it\u2019s usage so you can see if it\u2019s been effective. If you only had the skills of a content writer on this project, you would miss out on the benefits of visual communication and the feedback loop you get from data.\u274c Avoid using any agents in that can only operate in silos you would be missing majority of the compounding effects that the AI workforce can bring.In order for agents to be effectively work on complex tasks, you need a multi-agent system. There are many different",
    "chunk_id": "downloaded_1763554647_12"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "that can only operate in silos you would be missing majority of the compounding effects that the AI workforce can bring.In order for agents to be effectively work on complex tasks, you need a multi-agent system. There are many different types of multi-agent system. Here are some examples:Assembly line - Each agent completes their task sequentially given a SOP. Great for process driven task where the process is well figured out but requires a lot of reasoning to decide which path of a process to go down.Omni-direct - All agents are in 1 meeting room constantly speaking to one another. Great for creative tasks.Leader driven - A leader agent creates and adjusts the plan and coordinates majority of the communication and subtasks to be completed. Its best when both creativity and process is required.\u200dCreating an AI workforceThe importance of an AI workforce and AI agents in today's world is growing rapidly. As artificial intelligence continues to advance, companies are harnessing the power of AI agents to automate tasks, increase productivity, and even create new possibilities. These AI agents, acting as digital workers, are capable of performing complex tasks autonomously, contributing to the emerging concept of an AI workforce. Such a workforce, which works in parallel with human teams, is becoming an essential component in many industries, revolutionizing the way we work and conduct business.Creating an effective AI workforce involves numerous critical elements to ensure the efficiency of each AI agent. This necessitates the human workforce to encapsulate their domain expertise into prompts and tools, while continuously",
    "chunk_id": "downloaded_1763554647_13"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "revolutionizing the way we work and conduct business.Creating an effective AI workforce involves numerous critical elements to ensure the efficiency of each AI agent. This necessitates the human workforce to encapsulate their domain expertise into prompts and tools, while continuously observing and providing feedback. Doing so allows the human workforce to delegate highly repetitive tasks to the AI agents, enabling them to focus on tasks that only humans can perform.However creating an AI workforce can be easier, thats why we have built at Relevance AI. You can sign up here and try it out.\u200dBuilding the business case for the AI Workforce - ROI?Building a strong business case for an AI workforce requires a clear understanding of its potential to solve business problems, generate measurable returns, and overcome implementation challenges. This guide explores how to identify opportunities, quantify ROI through key metrics like efficiency gains and cost savings, and examines real-world success stories from customer service and operations. We'll also address critical challenges such as data quality and change management, emphasizing that a comprehensive approach to AI integration is essential for long-term value and successful business transformation.Identifying Business Problems and OpportunitiesSuccessful AI workforce business cases often emerge from operational inefficiencies that create bottlenecks or consume disproportionate resources. For example, companies like Uber have leveraged AI agents to improve employee productivity and customer service, while Toyota's AI platform enables factory workers to develop machine learning models, reducing man-hours and increasing operational efficiency. These implementations succeeded because they addressed specific, measurable problems with clear success criteria.The key to identifying",
    "chunk_id": "downloaded_1763554647_14"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "improve employee productivity and customer service, while Toyota's AI platform enables factory workers to develop machine learning models, reducing man-hours and increasing operational efficiency. These implementations succeeded because they addressed specific, measurable problems with clear success criteria.The key to identifying viable opportunities lies in conducting thorough process audits that reveal where human workers spend time on routine tasks that could be automated, where errors occur frequently due to manual processes, or where 24/7 availability would create significant value. Organizations should also consider areas where AI can enhance human decision-making through better data analysis and pattern recognition.\u200dCore Metrics for Measuring Return on InvestmentEssential KPI metrics fall into three primary categories: efficiency gains, cost savings, and revenue impact.Efficiency metrics focus on productivity improvements and time savings achieved through AI workforce implementation. Key indicators include labor cost reduction from decreased overtime and optimized staffing, schedule creation efficiency that saves management time, and productivity improvements measured through metrics like sales per labor hour or service delivery times. These metrics provide concrete evidence of operational improvements that translate directly to financial benefits.Cost savings calculations must account for both direct and indirect cost reductions. Direct savings include reduced labor costs, decreased error rates that eliminate rework expenses, and lower administrative overhead. Indirect savings encompass improved compliance adherence that avoids regulatory penalties, reduced employee turnover costs due to improved job satisfaction, and decreased training expenses as AI agents handle routine tasks that previously required extensive human training.Revenue impact measurements capture how AI workforce solutions contribute to top-line growth. This includes increased customer satisfaction",
    "chunk_id": "downloaded_1763554647_15"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "employee turnover costs due to improved job satisfaction, and decreased training expenses as AI agents handle routine tasks that previously required extensive human training.Revenue impact measurements capture how AI workforce solutions contribute to top-line growth. This includes increased customer satisfaction scores that drive retention and referrals, faster response times that improve conversion rates, and enhanced service availability that captures previously lost opportunities. Companies like Klarna have demonstrated significant revenue impact, with their AI assistants handling the equivalent work of 700 full-time agents while reducing repeat inquiries by 25% and improving customer satisfaction through faster resolution times.\u200dReal-World Examples: How Companies Achieve ROI from AI Agents\u200dRelevance AI Case Study: Send PaymentsSee how Send Payments, a global payment infrastructure provider, built a network of AI agents with Relevance AI to automate lead qualification, compliance, and CRM workflows - saving 40+ hours a week and delivering 24/7 customer service.From timezone challenges to manual processes, this case study shows how agentic automation helped the team scale with confidence, to now thinking as an AI-first company.Read full blog post here.Relevance AI Case Study: QualifiedDiscover how Qualified built an AI workforce of 50+ agents with Relevance AI - unlocking $10M in pipeline and transforming how their team works. From automating BDR outreach to streamlining demos and data workflows, this case study breaks down the impact of agentic automation across the business.\u200dRead full blog post here.Relevance AI Case Study: Safety CultureDiscover how SafetyCulture achieved remarkable success with Relevance AI's flagship AI Agent, Bosh, which:3x'd meetings booked at 50% the cost per meeting.2x'd the number",
    "chunk_id": "downloaded_1763554647_16"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "the impact of agentic automation across the business.\u200dRead full blog post here.Relevance AI Case Study: Safety CultureDiscover how SafetyCulture achieved remarkable success with Relevance AI's flagship AI Agent, Bosh, which:3x'd meetings booked at 50% the cost per meeting.2x'd the number of qualified opportunities.Read full blog post here.AI in Customer ServiceThe customer service sector has emerged as one of the most successful areas for AI workforce implementation, with numerous companies achieving substantial ROI through intelligent agent deployment. Motel Rocks, a fashion brand, exemplifies this success through their implementation of Zendesk Advanced AI. Their chatbots deflected 43% of customer tickets and reduced overall ticket volume by 50%, while simultaneously achieving a 9.44% increase in customer satisfaction scores. The AI system also provided mood indicators for customers, enabling human agents to deliver more personalized service when needed.Camping World faced a surge in customer calls and deployed IBM's cognitive AI tool to create an AI assistant named Arvee. Operating 24/7, this assistant increased customer engagement by 40% and reduced wait times by 33 seconds per call. Most significantly, agent efficiency improved by 33%, demonstrating how AI workforce solutions can enhance rather than replace human capabilities. The continuous availability of AI agents provided value that would have been impossible to achieve cost-effectively with human agents alone.Klarna's implementation represents perhaps the most impressive scale of AI workforce deployment in customer service. Their AI assistants handle the equivalent work of 700 full-time agents, reducing repeat inquiries by 25% and solving customer issues in less than 2 minutes on average. The system supports communication",
    "chunk_id": "downloaded_1763554647_17"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "impressive scale of AI workforce deployment in customer service. Their AI assistants handle the equivalent work of 700 full-time agents, reducing repeat inquiries by 25% and solving customer issues in less than 2 minutes on average. The system supports communication in over 35 languages, dramatically expanding the company's ability to serve global customers without proportional increases in staffing costs. This implementation demonstrates how AI workforce solutions can enable business scaling that would be prohibitively expensive with traditional human-only approaches.Telstra's Ask Telstra system, built on Microsoft Azure OpenAI, achieved 20% fewer follow-up calls and improved agent effectiveness by 90%. Bank of America's virtual assistant Erica has surpassed 1.5 billion interactions, significantly improving customer engagement while reducing operational costs. These examples consistently show that successful AI customer service implementations achieve ROI through a combination of cost reduction, efficiency improvement, and enhanced customer satisfaction.Build an AI Agent for Customer Support on Relevance AIIn this Relevance Live session, Alexandra Waite, Support Team Lead at Relevance AI, walks you through building an AI Agent for Case Review - from setup to practical use cases.You\u2019ll also hear insights from the live Q&A, where Alex answered questions about: How support teams can use AI agents day-to-day, Tips for improving agent accuracy and usefulness, Ways to scale AI in customer support without losing the human touch.AI in Operations and Supply ChainSupply chain and operations represent another area where AI workforce implementations have delivered exceptional ROI through improved forecasting, optimization, and automation. IKEA's implementation of machine learning for demand forecasting integrates sales data, promotional information,",
    "chunk_id": "downloaded_1763554647_18"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "human touch.AI in Operations and Supply ChainSupply chain and operations represent another area where AI workforce implementations have delivered exceptional ROI through improved forecasting, optimization, and automation. IKEA's implementation of machine learning for demand forecasting integrates sales data, promotional information, and weather patterns to improve demand accuracy and streamline inventory management. This comprehensive approach to data integration enables more precise planning and reduces both stockouts and excess inventory costs.Coca-Cola's real-time demand forecasting system utilizes AI to align production schedules with actual market demand, reducing stockouts and optimizing production efficiency. This alignment with real-time demand has improved service levels while reducing waste, demonstrating how AI workforce solutions can simultaneously improve customer satisfaction and operational efficiency. The system's ability to process and respond to market signals faster than human analysts provides a significant competitive advantage.DHL's AI optimization of logistics operations has improved on-time deliveries by 15% while reducing operational costs. The predictive analytics capabilities enable proactive management of potential issues and efficient scaling of operations based on demand patterns. Amazon's comprehensive embedding of AI across its supply chain, from warehouse automation to predictive delivery routing, has reduced shipping delays and operational costs while enabling the scale of operations that defines the company's competitive position.These supply chain implementations consistently demonstrate ROI through improved accuracy, reduced waste, enhanced efficiency, and better customer service. The ability of AI agents to process vast amounts of data and identify patterns that human analysts might miss creates value that compounds over time as systems learn and improve.\u200dOvercoming Challenges in Proving ai automation ROIData Quality,",
    "chunk_id": "downloaded_1763554647_19"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "better customer service. The ability of AI agents to process vast amounts of data and identify patterns that human analysts might miss creates value that compounds over time as systems learn and improve.\u200dOvercoming Challenges in Proving ai automation ROIData Quality, Change Management, and Adoption BarriersData quality represents one of the most significant challenges in proving AI automation ROI, as poor data quality can impair model performance and lead to inaccurate ROI calculations. Common data issues include inconsistent formats, missing values, outdated information, and data silos that prevent comprehensive analysis. These problems can undermine AI system effectiveness and make it difficult to demonstrate clear value creation.Organizations must implement robust data governance frameworks that include regular data audits, standardized data collection processes, and automated data cleaning tools. Establishing centralized data repositories with clear data quality standards ensures that AI systems have access to reliable information for decision-making. The investment in data quality infrastructure often represents a significant portion of AI implementation costs, but it's essential for achieving reliable ROI measurements.Change management and adoption barriers often stem from employee fears about job displacement and lack of understanding about AI's role in the organization. Resistance to AI adoption can significantly impact ROI by reducing system utilization and effectiveness. Successful organizations address these challenges through transparent communication that emphasizes AI as a tool to augment rather than replace human capabilities.Training programs that enhance existing skillsets and provide hands-on experience with AI tools are essential for overcoming adoption barriers. Engaging employees in the AI journey through workshops, feedback sessions, and collaborative development",
    "chunk_id": "downloaded_1763554647_20"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "a tool to augment rather than replace human capabilities.Training programs that enhance existing skillsets and provide hands-on experience with AI tools are essential for overcoming adoption barriers. Engaging employees in the AI journey through workshops, feedback sessions, and collaborative development processes fosters a culture of acceptance and innovation. Organizations that invest in comprehensive change management typically see higher AI adoption rates and better ROI outcomes.Measuring Intangible Benefits and Long-Term ValueQuantifying intangible benefits represents a significant challenge in AI ROI measurement, as many of the most valuable outcomes from AI workforce implementation don't appear directly on financial statements. Employee satisfaction, innovation capacity, strategic agility, and enhanced decision-making quality all contribute to long-term value creation but require sophisticated measurement approaches.Employee satisfaction can be measured through regular surveys and feedback mechanisms that track changes in job satisfaction, engagement levels, and retention rates. Innovation capacity can be evaluated by tracking the number of new ideas generated and implemented, the speed of product development cycles, and the organization's ability to respond to market opportunities. Strategic agility can be assessed through decision-making speed, market responsiveness, and the ability to adapt to changing conditions.These intangible benefits often provide the most significant long-term value from AI workforce implementations. Organizations that focus solely on short-term financial metrics may underestimate the true ROI of their AI investments and make suboptimal decisions about scaling and optimization. A comprehensive approach that balances quantitative financial metrics with qualitative assessments of intangible benefits provides a more accurate picture of AI workforce value.TakeawayThe most successful organizations treat AI workforce development as",
    "chunk_id": "downloaded_1763554647_21"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "investments and make suboptimal decisions about scaling and optimization. A comprehensive approach that balances quantitative financial metrics with qualitative assessments of intangible benefits provides a more accurate picture of AI workforce value.TakeawayThe most successful organizations treat AI workforce development as a comprehensive business transformation initiative that encompasses strategic planning, change management, continuous improvement, and systematic scaling. They invest in data quality, employee training, and robust measurement frameworks that capture both tangible and intangible value creation.\u200dFAQsCan\u2019t find the answer here? Contact our support team. What is an AI workforce?An AI workforce refers to the integration of artificial intelligence agents or systems alongside human employees in an organization. This collaborative approach combines human expertise with AI capabilities to enhance productivity, automate routine tasks, and enable employees to focus on higher-value work. An AI workforce typically includes various AI tools, virtual assistants, and autonomous agents that perform specific functions within the organization's operational framework.How can AI agents benefit my business workforce?AI agents can benefit your business workforce in several ways:Automating repetitive and time-consuming tasksProcessing and analyzing large volumes of data quicklyProviding 24/7 availability for customer service and supportReducing human error in routine processesEnhancing decision-making with data-driven insightsFreeing human employees to focus on creative, strategic workScaling operations without proportional increases in staffingImproving consistency in service delivery and internal processesThe most successful implementations align AI capabilities with specific business needs and integrate seamlessly with human workflows.What's the difference between AI workforce solutions and traditional automation?AI workforce solutions differ from traditional automation in several key ways:Traditional automation is rules-based, following predetermined paths",
    "chunk_id": "downloaded_1763554647_22"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "successful implementations align AI capabilities with specific business needs and integrate seamlessly with human workflows.What's the difference between AI workforce solutions and traditional automation?AI workforce solutions differ from traditional automation in several key ways:Traditional automation is rules-based, following predetermined paths and handling structured data with limited adaptability. It excels at executing defined processes but struggles with exceptions or variations.AI workforce solutions can understand unstructured data, learn from experiences, make decisions with incomplete information, and adapt to new situations. They can interpret context, recognize patterns, and improve performance over time without explicit programming for each scenario.While traditional automation replaces specific manual tasks, AI workforce solutions can augment human capabilities, collaborate with employees, and handle complex cognitive tasks that previously required human judgment.How do I integrate AI agents as employees in my existing team?Integrating AI agents into your existing team requires a thoughtful approach:Identify specific roles and tasks where AI can provide the most valueSelect appropriate AI solutions designed for those specific functionsEstablish clear workflows that define how AI and human team members will collaborateProvide training for your human workforce on working effectively with AI colleaguesStart with pilot projects before scaling to broader implementationCreate feedback mechanisms to continuously improve AI performanceDevelop clear policies about AI decision authority and human oversightEstablish metrics to measure the impact of AI integrationSuccessful integration focuses on complementary strengths rather than replacement, with AI handling routine tasks while humans manage exceptions and relationship-based activities.What are the costs associated with implementing an AI workforce?Implementing an AI workforce involves several cost considerations:Technology costs: Subscriptions to AI",
    "chunk_id": "downloaded_1763554647_23"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "integration focuses on complementary strengths rather than replacement, with AI handling routine tasks while humans manage exceptions and relationship-based activities.What are the costs associated with implementing an AI workforce?Implementing an AI workforce involves several cost considerations:Technology costs: Subscriptions to AI platforms, custom development work, and infrastructure upgradesIntegration expenses: Connecting AI systems with existing software and workflowsTraining costs: Educating employees on effectively working with AI systemsMaintenance and updates: Ongoing management and improvement of AI capabilitiesPotential restructuring costs: Adjusting roles and responsibilities as workflows changeThe investment typically ranges from a few thousand dollars for basic implementations using existing platforms to hundreds of thousands for enterprise-wide custom solutions. Many organizations see ROI through labor cost savings, increased productivity, and error reduction within 6-18 months of implementation.What types of AI agents can be included in an AI workforce?An AI workforce can include various types of specialized agents:Administrative agents: Managing calendars, scheduling, and organizing informationCustomer service agents: Handling inquiries, support requests, and customer interactionsData analysis agents: Processing information, generating reports, and identifying patternsContent creation agents: Drafting documents, emails, and marketing materialsResearch agents: Gathering information, summarizing findings, and monitoring trendsProcess automation agents: Executing complex workflows across multiple systemsDecision support agents: Providing recommendations based on data analysisLearning and development agents: Delivering personalized training and educationOrganizations typically begin with one or two agent types focused on high-impact areas before expanding to a more comprehensive AI workforce strategy.How will AI workforce solutions affect my human employees?AI workforce solutions typically affect human employees in several ways:Role evolution: Shifting from routine tasks to higher-value work requiring creativity,",
    "chunk_id": "downloaded_1763554647_24"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "focused on high-impact areas before expanding to a more comprehensive AI workforce strategy.How will AI workforce solutions affect my human employees?AI workforce solutions typically affect human employees in several ways:Role evolution: Shifting from routine tasks to higher-value work requiring creativity, critical thinking, and emotional intelligenceNew skill requirements: Increasing need for digital literacy, AI collaboration skills, and strategic thinkingProductivity enhancement: Enabling employees to accomplish more with AI assistanceJob satisfaction improvements: Reducing tedious work and allowing focus on more meaningful tasksCareer advancement opportunities: Creating new roles in AI management, oversight, and developmentWhile some job functions may be automated, organizations that implement AI thoughtfully typically redeploy employees rather than replace them, focusing on augmentation rather than substitution. The most successful implementations involve employees in the transformation process from the beginning.Are there no-code solutions for creating an AI workforce?Yes, several no-code platforms allow businesses to build AI workforce solutions without extensive technical expertise:Workforce.ai offers drag-and-drop interfaces for building business process AI agentsRelevance AI provides templates for common workforce automation scenariosVarious productivity platforms now include AI agent capabilities with visual configurationEnterprise automation tools increasingly offer AI components that can be implemented without codingThese no-code solutions typically offer:Pre-built templates for common use casesVisual workflow buildersSimple integration with existing business softwareUser-friendly training interfacesPerformance monitoring dashboardsWhile custom-coded solutions offer more flexibility, no-code platforms provide a faster implementation path and lower technical barriers for many organizations.What are best practices for AI workforce management?Effective AI workforce management includes:Clear governance structures: Establishing oversight, responsibility, and decision authorityPerformance monitoring: Tracking AI agent effectiveness and alignment with objectivesContinuous improvement",
    "chunk_id": "downloaded_1763554647_25"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "a faster implementation path and lower technical barriers for many organizations.What are best practices for AI workforce management?Effective AI workforce management includes:Clear governance structures: Establishing oversight, responsibility, and decision authorityPerformance monitoring: Tracking AI agent effectiveness and alignment with objectivesContinuous improvement processes: Regularly reviewing and enhancing AI capabilitiesHuman-AI collaboration protocols: Defining how and when human intervention occursEthics and bias prevention: Implementing safeguards against harmful outcomesChange management: Supporting the organization through the transitionSkills development: Preparing human workers to collaborate effectively with AISecurity protocols: Protecting sensitive data and systemsOrganizations that excel at AI workforce management typically establish dedicated roles or teams responsible for overseeing their digital workforce alongside their human resources.How can I measure the ROI of implementing an AI workforce?Measuring the ROI of an AI workforce implementation should consider:Productivity metrics: Tasks completed per hour/day, processing times, throughput ratesQuality improvements: Error reduction, consistency measures, compliance ratesCost savings: Reduced overtime, contractor expenses, hiring needsRevenue impacts: Sales increases, customer retention, new opportunities capturedEmployee experience: Job satisfaction, retention rates, internal mobilityCustomer satisfaction: Response times, resolution rates, satisfaction scoresStrategic value: Innovation capacity, market responsiveness, competitive advantageEffective measurement requires establishing baseline metrics before implementation and tracking changes over time. Many organizations use balanced scorecards that combine quantitative metrics with qualitative assessments from stakeholders to gain a comprehensive view of AI workforce impact.Free your team. Build your first AI agent today!Recruit AI teammates and complete tasks on autopilot. Grow your business, not your headcount.Try for freeRequest DemoFree plan No card requiredThe home of the AI Workforce\u00a9 2025 OnSearch Pty Ltd T/A Relevance AI. All rights",
    "chunk_id": "downloaded_1763554647_26"
  },
  {
    "doc": "downloaded_1763554647.txt",
    "chunk": "Build your first AI agent today!Recruit AI teammates and complete tasks on autopilot. Grow your business, not your headcount.Try for freeRequest DemoFree plan No card requiredThe home of the AI Workforce\u00a9 2025 OnSearch Pty Ltd T/A Relevance AI. All rights reserved.Website \u2013 Q AGENCYFunctionSalesMarketingOperationsResearchSupportProductAI AgentsAI WorkforceMulti-Agent SystemsAI ToolsAI BDR AgentIntegrationsCustom Actions for GPTsSlidesSupportDocumentation\u200bChangelogAPI & Python SDKBook demoEnterprisePartnersExpert Partner DirectoryLearnRelevance AcademyLearnCustomersBlogTopicsToolsWorkflowsCompanyCareers\u200bTrust CenterMedia EnquiriesLegalPrivacy policy\u200bSecurity policy\u200bTermsAnthropic DPAOpenAI DPA",
    "chunk_id": "downloaded_1763554647_27"
  },
  {
    "doc": "downloaded_1763605374.txt",
    "chunk": "Source: https://www.geeksforgeeks.org/maths/algebra/ Algebra in Math - Definition, Branches, Basics and Examples - GeeksforGeeks Skip to content Interview PrepDSAInterview CornerAptitude & ReasoningPractice Coding ProblemsAll CoursesTutorialsPythonJavaML & Data ScienceProgramming LanguagesWeb DevelopmentCS SubjectsDevOpsSoftware and ToolsSchool LearningTracksLanguagesPythonCC++JavaAdvanced JavaSQLJavaScriptC#Interview PreparationGfG 160GfG 360System DesignCore SubjectsInterview QuestionsInterview PuzzlesAptitude and ReasoningProduct ManagementComputer Organisation and ArchitectureData SciencePythonData AnalyticsComplete Data ScienceGen AIAgentic AIDev SkillsFull-Stack Web DevDevOpsSoftware TestingCyberSecurityNextJSGitToolsComputer FundamentalsAI ToolsMS Excel & Google SheetsMS Word & Google DocsMathsMaths For Computer ScienceEngineering MathematicsSchool Maths Number System and ArithmeticAlgebraSet TheoryProbabilityStatisticsGeometryCalculusLogarithmsMensurationMatricesTrigonometryMathematics Sign In \u25b2 Open In App Algebra in Math - Definition, Branches, Basics and Examples Last Updated : 23 Jul, 2025 Comments Improve Suggest changes 13 Likes Like Report Algebra is the branch of mathematics with the following properties.Deals with symbols (or variables) and rules for manipulating these symbols. Elementary (Taught in Schools) Algebra mainly deals with variables and operations like sum, power, subtraction, etc. For example, x + 10 = 100, x2 - 2x + 1 = 5 and x + y = 20. Abstract Algebra (Taught in Colleges) deals with groups, rings, and fields instead of normal variables (representing numbers).In this article, we are mainly going to focus on Elementary algebra.Example: A father is 30 years older than his son. The combined age of both father and son is 60 years. You are asked to find the individual ages of the father and the son.Real-life Equation:Let x represent the son's age.The father's age will then be x + 30, since the father is 30 years older than the son.The sum of their ages is 60, so the",
    "chunk_id": "downloaded_1763605374_0"
  },
  {
    "doc": "downloaded_1763605374.txt",
    "chunk": "individual ages of the father and the son.Real-life Equation:Let x represent the son's age.The father's age will then be x + 30, since the father is 30 years older than the son.The sum of their ages is 60, so the equation becomes: x + (x + 30) = 60Algebraic Equation: 2x + 30 = 60.Algebra for Beginners & School StudentsThis section covers key algebra concepts, including expressions, equations, operations, and methods for solving linear and quadratic equations, along with polynomials and factorization.Basics of AlgebraBranches of AlgebraAlgebraic ExpressionsAlgebraic EquationsOne-step EquationsExpression and EquationsAlgebraic Operations & PropertiesLinear equation in one VariableLinear Equation in Two VariablesPair of Linear Equation in Two VariablesSolving Pair of Linear Equation in Two VariablesSubstitution MethodElimination MethodCross Multiplication MethodQuadratic EquationsQuadratic FormulaAlgebraic IdentitiesPolynomials Degree of PolynomialFactorization of PolynomialZeroes of a PolynomialFactor Theorem and Remainder Theorem Linear Inequalities Algebra vs CalculusAlgebra for Aptitude PreparationThis section covers key algebra formulas and tricks to boost your aptitude skills and improve exam performance.Algebra FormulasAlgebra Tricks for AptitudeAlgebra Aptitude Questions & AnswersAlgebra Practice QuestionsThis section offers a variety of algebra practice questions at different difficulty levels, including linear and quadratic equations, to help you sharpen your skills and prepare for exams.Algebra Practice Questions (Easy Level)Algebra Practice Questions (Medium Level)Algebra Practice Questions (Hard Level)Practice Problems on Linear Equation in Two VariablesPractice Questions on Quadratic EquationsAlgebra Practice Quiz Algebra for ProgrammersThis section focuses on algebra concepts for programmers, including coding solutions for linear and quadratic equations, finding missing values, and determining the maximum and minimum values of algebraic expressions.Find number of solutions of a",
    "chunk_id": "downloaded_1763605374_1"
  },
  {
    "doc": "downloaded_1763605374.txt",
    "chunk": "Quadratic EquationsAlgebra Practice Quiz Algebra for ProgrammersThis section focuses on algebra concepts for programmers, including coding solutions for linear and quadratic equations, finding missing values, and determining the maximum and minimum values of algebraic expressions.Find number of solutions of a linear equation of n variablesProgram to find number of solutions in Quadratic EquationProgram to find the Roots of Quadratic equationFind the missing value from the given equation a + b = cMaximum and Minimum Values of an Algebraic Expression Create Quiz Algebra Algebra How to solve Quadratic Equations? Homogeneous Linear Equations Solving Cubic Equations Binomial Theorem | Formula, Proof, Binomial Expansion and Examples Principle of Mathematical Induction Comment A abhishek1 Follow 13 Improve A abhishek1 Follow 13 Improve Article Tags : Mathematics School Learning Class 10 Algebra Maths-Class-8 Maths-Class-9 Maths-Class-10 Maths-Class-11 Maths-Class-12 Tutorials Maths-Categories Math Tutorials +8 More Explore Maths 4 min read Basic ArithmeticWhat are Numbers? 15+ min read Arithmetic Operations 9 min read Fractions - Definition, Types and Examples 7 min read What are Decimals? 10 min read Exponents 9 min read Percentage 4 min read AlgebraVariable in Maths 5 min read Polynomials| Degree | Types | Properties and Examples 9 min read Coefficient 8 min read Algebraic Identities 14 min read Properties of Algebraic Operations 3 min read GeometryLines and Angles 9 min read Geometric Shapes in Maths 2 min read Area and Perimeter of Shapes | Formula and Examples 10 min read Surface Areas and Volumes 10 min read Points, Lines and Planes 12 min read Coordinate Axes and Coordinate Planes in",
    "chunk_id": "downloaded_1763605374_2"
  },
  {
    "doc": "downloaded_1763605374.txt",
    "chunk": "read Geometric Shapes in Maths 2 min read Area and Perimeter of Shapes | Formula and Examples 10 min read Surface Areas and Volumes 10 min read Points, Lines and Planes 12 min read Coordinate Axes and Coordinate Planes in 3D space 6 min read Trigonometry & Vector AlgebraTrigonometric Ratios 4 min read Trigonometric Equations | Definition, Examples & How to Solve 9 min read Trigonometric Identities 7 min read Trigonometric Functions 6 min read Inverse Trigonometric Functions 8 min read Inverse Trigonometric Identities 9 min read CalculusIntroduction to Differential Calculus 6 min read Limits in Calculus 11 min read Continuity of Functions 10 min read Differentiation 2 min read Differentiability of Functions 9 min read Integration 3 min read Probability and StatisticsBasic Concepts of Probability 6 min read Bayes' Theorem 13 min read Probability Distribution - Function, Formula, Table 11 min read Descriptive Statistic 5 min read What is Inferential Statistics? 5 min read Measures of Central Tendency in Statistics 9 min read Set Theory 3 min read PracticeNCERT Solutions for Class 8 to 12 7 min read RD Sharma Class 8 Solutions for Maths: Chapter Wise PDF 5 min read RD Sharma Class 9 Solutions 10 min read RD Sharma Class 10 Solutions 9 min read RD Sharma Class 11 Solutions for Maths 13 min read RD Sharma Class 12 Solutions for Maths 13 min read Like Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137,",
    "chunk_id": "downloaded_1763605374_3"
  },
  {
    "doc": "downloaded_1763605374.txt",
    "chunk": "min read RD Sharma Class 12 Solutions for Maths 13 min read Like Corporate & Communications Address: A-143, 7th Floor, Sovereign Corporate Tower, Sector- 136, Noida, Uttar Pradesh (201305) Registered Address: K 061, Tower K, Gulshan Vivante Apartment, Sector 137, Noida, Gautam Buddh Nagar, Uttar Pradesh, 201305 CompanyAbout UsLegalPrivacy PolicyContact UsAdvertise with usGFG Corporate SolutionCampus Training ProgramExplorePOTDJob-A-ThonBlogsNation Skill UpTutorialsProgramming LanguagesDSAWeb TechnologyAI, ML & Data ScienceDevOpsCS Core SubjectsInterview PreparationSoftware and ToolsCoursesIBM CertificationDSA and PlacementsWeb DevelopmentProgramming LanguagesDevOps & CloudGATETrending TechnologiesVideosDSAPythonJavaC++Web DevelopmentData ScienceCS SubjectsPreparation CornerInterview CornerAptitudePuzzlesGfG 160System Design @GeeksforGeeks, Sanchhaya Education Private Limited, All rights reserved Improvement Suggest changes Suggest Changes Help us improve. Share your suggestions to enhance the article. Contribute your expertise and make a difference in the GeeksforGeeks portal. Create Improvement Enhance the article with your expertise. Contribute to the GeeksforGeeks community and help create better learning resources for all. Suggest Changes min 4 words, max Words Limit:1000 Thank You! Your suggestions are valuable to us. What kind of Experience do you want to share? Interview Experiences Admission Experiences Career Journeys Work Experiences Campus Experiences Competitive Exam Experiences",
    "chunk_id": "downloaded_1763605374_4"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "Source: https://arize.com/blog/retrieval-augmented-generation-paper-reading-and-discussion/ Retrieval-Augmented Generation - Paper Reading and Discussion - Arize AI Arize AX Arize AX AX - Generative Enterprise AI Engineering Platform AX - ML & CV Enterprise ML Observability Arize Platform demo See how it works Watch video Phoenix OSS Pricing Docs Learn Learn Prompt Learning Essentials playbook Paper readings AI research insights Courses Essential Arize-led courses Agents hub AI agent evaluation LLM Evals Hub LLM evaluation guide AI Product Manager AI PM learning Insights Blog Get to know Arize Community Engage with AI engineers Events AI networking events Video tutorials Hands-on video tutorials Company Company About We power the future of AI Careers Join a world class team Partners Partner with us Customers Built with Arize AX Press Updates from the newsroom Security We take your trust seriously Customers See who is achieving better outcomes in production Sign in Book a demo Get started Arize AX Phoenix OSS Pricing Docs Learn Company Book a demo Sign in Sign up Sarah Welsh Contributor Share Subscribe to the Arize blog Get the latest On this page Suggested reading Meta AI Researcher Explains ARE and Gaia2: Scaling Up Agent Environments and Evaluations ServiceNow\u2019s Tara Bogavelli on AgentArch: Benchmarking AI Agents for Enterprise Workflows Retrieval-Augmented Generation \u2013 Paper Reading and Discussion Published Jun 9, 2023 Paper Readings Podcasts Research Sarah Welsh Contributor Introduction In this paper reading, we discuss \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\u201d We know GPT-like LLMs are great at soaking up knowledge during pre-training and fine-tuning them can lead to some pretty great, specific",
    "chunk_id": "downloaded_1763607480_0"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "Podcasts Research Sarah Welsh Contributor Introduction In this paper reading, we discuss \u201cRetrieval-Augmented Generation for Knowledge-Intensive NLP Tasks.\u201d We know GPT-like LLMs are great at soaking up knowledge during pre-training and fine-tuning them can lead to some pretty great, specific results. But when it comes to tasks that really demand heavy knowledge lifting, they still fall short. Plus, it\u2019s not exactly easy to figure out where their answers come from or how to update their knowledge. Enter RAG models, a hybrid beast that combines the best of both worlds: the learning power of pre-trained models (the parametric part), and an explicit, non-parametric memory \u2014 imagine a searchable index of all of Wikipedia. Join us every Wednesday as we discuss the latest technical papers, covering a range of topics including large language models (LLM), generative models, ChatGPT, and more. This recurring event offers an opportunity to collectively analyze and exchange insights on cutting-edge research in these areas and their broader implications. Watch Dive in: Read the original paper Register for upcoming paper readings Transcript Aman Khan, Group Product Manager at Arize AI: So we\u2019ve got a few folks in the community joining some familiar names and faces. Cool. Why don\u2019t we kick things off just in the interest of time? I\u2019ll just kind of briefly introduce myself. My name is Aman, I\u2019m a Product Manager here at Arize. So my job is really to hear customer feedback, customer pain about what\u2019s going on when you\u2019re observing or monitoring models and learning about how to make the product",
    "chunk_id": "downloaded_1763607480_1"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "My name is Aman, I\u2019m a Product Manager here at Arize. So my job is really to hear customer feedback, customer pain about what\u2019s going on when you\u2019re observing or monitoring models and learning about how to make the product better, and then feeding that back into the engineering team, and working with engineers to build out our product roadmap. I\u2019m joined here by Michael, our CTO. Michael, if you want to give a brief introduction. Michael Schiff, Chief Technology Officer of Arize AI: I\u2019m Michael, I\u2019m the CTO, I have a background in distributed systems and ML engineering and I\u2019m excited to talk about this paper. Aman Khan: So I think when we were kind of like pre talking about this a little bit. Why did we select this paper, what\u2019s novel about this technique? And let me go ahead and share my screen. So we\u2019re kind of looking at the same visual tier. So we\u2019re going to be chatting about retrieval augmented generation. This has been a pretty hot topic of discussion for a little while now, specifically, when it comes to applying LLMs for actual useful applications on top of your own data. And I think maybe one interesting nuance to call out that we\u2019ll get into a little bit more is specifically we\u2019re talking about knowledge intensive tasks which will define and get into more depth. But we\u2019re gonna go through the sort of canonical paper on retrieval augmented generation for knowledge intensive tasks and the sort of approach of RAG. We\u2019ll",
    "chunk_id": "downloaded_1763607480_2"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "we\u2019re talking about knowledge intensive tasks which will define and get into more depth. But we\u2019re gonna go through the sort of canonical paper on retrieval augmented generation for knowledge intensive tasks and the sort of approach of RAG. We\u2019ll talk about how it works, why it works the way it does, and then kind of build off of that, maybe do something a little bit different than what we\u2019ve been doing, which is, we might be hopping between different models in this paper read to look at what other companies are doing in industry and some of the interesting work on top of the foundation of this concept. Please feel free to leave questions, we\u2019ll answer them in real time. So feel free to leave any comments or questions, so we can help answer. Michael Schiff: Will you swap over the slide show mode up in the upper right? Aman Khan: Yes. Well, we\u2019ll be talking between the papers so we might be jumping between screens here. Can folks still see if I pull up a PDF? Does this still work? Michael Schiff: I\u2019m able to see okay, I think it\u2019s just a maybe a clearer view. Aman Khan: Yeah. So we\u2019ll be hopping between slides and the paper a little bit just up, just as like raw notes. But we want to kind of stick to the paper, and then, as we\u2019ll jump to different slides. Michael, do you want to kick us off with the abstract? What\u2019s novel about this? I think you",
    "chunk_id": "downloaded_1763607480_3"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "as like raw notes. But we want to kind of stick to the paper, and then, as we\u2019ll jump to different slides. Michael, do you want to kick us off with the abstract? What\u2019s novel about this? I think you yesterday you were like, well, okay, so what\u2019s this model actually doing? Michael Schiff: I came to the paper, not realizing this was sort of like the paper around retrieval augmented models, and I was like, this is what people have been doing for weeks! But at the time we live in, a week feels like this glacial time period. But this is a technique that\u2019s really picked up in popularity for augmenting generative models. Specifically, adding what the authors call non parametric memory to parametric models. The insight that they build off of is sequence to sequence models\u2013which we\u2019ve all become very familiar with in the last a couple of months\u2013 encode a lot of real world factual information into their parameters. The parameters aren\u2019t just encoding the structure of language. And what makes up a sequence of speech or text that is plausibly human, but it has information that we believe to be true about the world, encoded into its parameters. But not everything. And you hinted at this in the beginning, but really for knowledge, intensive tasks. And the authors set those aside as tests that even humans wouldn\u2019t be able to do without like an encyclopedia or look up to go answer those questions. We could synthesize a response given that external",
    "chunk_id": "downloaded_1763607480_4"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "for knowledge, intensive tasks. And the authors set those aside as tests that even humans wouldn\u2019t be able to do without like an encyclopedia or look up to go answer those questions. We could synthesize a response given that external reference source. But we need that, too, we don\u2019t have it encoded into our parameters, either. So this is a technique for augmenting a sequence to sequence parameterized model with a non parametric memory. And talk more about what that looks like. Aman Khan: Yeah, awesome. So I feel like one of the takeaways was what is parametric and non parametric memory, and what does that mean? So we\u2019ve kind of all experienced chat GPT, hallucinating, giving an inaccurate response, etc. What\u2019s interesting about what we\u2019re going to hop into is really the architecture of this type of model, and how it handles hallucinations when you\u2019re actually retrieving on top of your own data. So, kind of just jumping right in. I mean, I feel like this diagram really kind of conveys a lot of the architecture. I feel like this take away, which is wild. This development is exciting. I mean, basically. But saying, Okay, pre-trained language models can do a ton of stuff. They can do this without access to external memory. But when it comes to actually answering questions about specific topics, how do pre train models perform as opposed to when you\u2019re accessing memory. And I think that this diagram really kind of gives a lot of insight into this model\u2019s architecture.",
    "chunk_id": "downloaded_1763607480_5"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "it comes to actually answering questions about specific topics, how do pre train models perform as opposed to when you\u2019re accessing memory. And I think that this diagram really kind of gives a lot of insight into this model\u2019s architecture. So, Michael, do you want to do you want to take a step and maybe breaking down like what\u2019s going on here from an architectural perspective. I think specifically, there\u2019s kind of a few components to talk about which would be like the query encoder, the retriever, document index, and the generator. Michael Schiff: Yeah. so I guess before going into the exact architecture, kind of a high level overview on the intuition behind the technique which is effectively given an encyclopedia, an external reference source. We want to select from it relevant things like, if I were to ask you: how do I change the time on my car stere? You don\u2019t know the answer to that, you don\u2019t have it memorized. But I throw you my Honda manual, and you are gonna be able to tell me the answer. So you flip through, and you figure out what are the relevant passages. You find the relevant passages, you summarize and synthesize a response. You hold this button, and then you you know toggle through whatever to to set the time. And so this architecture is a specified version of that. The the non parametric retriever is the look up on this factual index structure. And the the form that that takes here and in",
    "chunk_id": "downloaded_1763607480_6"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "whatever to to set the time. And so this architecture is a specified version of that. The the non parametric retriever is the look up on this factual index structure. And the the form that that takes here and in most of the implementations we\u2019ve seen is in a vector database so specifically a storage system that can store and retrieve vectors which correspond to passages of text from your index, and which can be retrieved with a semantic search. So you\u2019re not like selecting based on labeled tags. But you\u2019re able to find relevant information in a learned capacity. And then you\u2019re augmenting the generation process, which is this, you know, sequence sequence model. So we\u2019re familiar with transformers, which already knows how to spit out a reasonable sounding answer, and might, in fact, have a little bit of the knowledge of this problem encoded in its parameters? It might know what a car is, and It know what a car stereo is, but it doesn\u2019t know the specifics of my model Honda or whatever You augment the question. So, how do I change my car stereo time? With these documents and feed that in. So going left to right, the architecture looks like a query encoder, which takes your query and turns it into the vectors that our model is going to understand a maximum inner product search, which is the semantic lookup on our vector database. So this vector database holds encoded strings of text from\u2013in the paper it\u2019s Wikipedia, but one of",
    "chunk_id": "downloaded_1763607480_7"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "the vectors that our model is going to understand a maximum inner product search, which is the semantic lookup on our vector database. So this vector database holds encoded strings of text from\u2013in the paper it\u2019s Wikipedia, but one of the interesting things we\u2019ve seen about this architecture is that it\u2019s very generalizable, and that index structure can contain facts about anything you want. So I\u2019ve been using this Honda car manual example, but you do a maximum inner product. Search for that. You get your top documents in the paper. And then you generate possible sequences. Given those documents, they have different approaches to token versus sequence generation. From there, it\u2019s working the same way as the parametric generators work always, which is to guess at the next probable token. Given the input effectively, trying to pick the most likely string that you would expect. Given the input, we\u2019ve just augmented the input for this retrieval task. Aman Khan: Yeah, I think that\u2019s gonna be really interesting when we get into the trade-offs between those approaches of token versus sequence-based generation. But I wanted to actually pause a little bit and talk about the query encoder and the retriever. So from the paper, it looks like the query encoder is really just chunking up documents based on like, roughly how many words. It\u2019s like Wikipedia articles\u2013is it a hundred? I think it\u2019s a hundred words, maybe it\u2019s a hundred characters, but it\u2019s some preset sort of document chunk that is flexible. They just basically took",
    "chunk_id": "downloaded_1763607480_8"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "based on like, roughly how many words. It\u2019s like Wikipedia articles\u2013is it a hundred? I think it\u2019s a hundred words, maybe it\u2019s a hundred characters, but it\u2019s some preset sort of document chunk that is flexible. They just basically took like an arbitrary sort of method of chunking up the documents. And then they actually just kind of use an off the shelf, what they\u2019re calling the retriever here is like a dense passage, retriever. And it\u2019s really just a model that is purpose built to retrieve documents from where their index and store from the query encoder. I think that\u2019s pretty interesting, because it means that that\u2019s like some level of flexibility as well off the shelf. I think they just use BART here as well. So they basically just use kind of an off the shelf model and said, Okay, here\u2019s your corpus of information. Now get really good at pulling out information from here. And that\u2019s that\u2019s basically all this like Dpr is, which is sort of the meat of retrieval. Any thoughts on that, Michael? Why, like, it\u2019s kind of interesting, like an LLM, you know, using using a retriever or Dpr, to kind of pull documents on. It\u2019s kind of interesting to reason. It\u2019s almost like a reasoning engine about the the index. Right? Michael Schiff: I mean to be honest, this is an area where I had a little bit of uncertainty about their methods. because if you look lower down, they describe the actual I mean, I hate to",
    "chunk_id": "downloaded_1763607480_9"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "the index. Right? Michael Schiff: I mean to be honest, this is an area where I had a little bit of uncertainty about their methods. because if you look lower down, they describe the actual I mean, I hate to use an overloaded word, but like retrieval from the document index with face and extracted with hierarchical, navigable small world indexes. I need to do a little bit more reading about what the depth passage retriever is. If that\u2019s the name for this approach. The other thing that I thought was really interesting was in their fine tuning process. They choose not to fine tune the document encoder. So they have several encoders which they seem to refer specifically to like the vector, encoding of a passage, and everywhere it\u2019s for it. So it\u2019s like, you know, it\u2019s like there\u2019s but they so they fine tune. But the one that they don\u2019t fine tune is the document encoder, because this would require rebuilding the index. So I think it speaks to some of the intentions, I guess, of the author. If I can be presumptive and assume some of that is they were trying not to build special purpose models for retrieval tasks. Such things existed already. The goal here seems to be to take fairly off the shelf components in a general fine-tuning process, and then not need to do a lot more work on top of that, and they, in fact, give out their index of Wikipedia, and if the problem required fine tuning",
    "chunk_id": "downloaded_1763607480_10"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "off the shelf components in a general fine-tuning process, and then not need to do a lot more work on top of that, and they, in fact, give out their index of Wikipedia, and if the problem required fine tuning of the document. Encoder, you\u2019d have to throw away that index and start over, and to the expense of some of these steps where you\u2019re like, use pre-trained stuff where possible, do a minimal fine tuning step on just the components that are cheap to find, too. Aman Khan: yeah, we\u2019ll get a little bit deeper into like the index to. And what swapping the index looks like, but maybe for the benefit of folks that might be learning about this for the first time. Can you talk a little bit about what parametric memory is, and what non parametric memory is? What\u2019s the trade off? What\u2019s the difference between as soon as we\u2019re using those terms. Michael Schiff: I mean to me, to me they feel a little bit like fancy words for stuff that I would guess that a lot of people who are, if they\u2019re present here, are actually already familiar with the concepts. In the paper \u201cParametric memory\u201d really just refers to the stored factual information about the world which is present in our sequence to sequence model parameters. They encode it with that Theta. So you have some sequence to sequence model that knows how to generate probable output text from input text. And this is actually one of the\u2013I don\u2019t",
    "chunk_id": "downloaded_1763607480_11"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "in our sequence to sequence model parameters. They encode it with that Theta. So you have some sequence to sequence model that knows how to generate probable output text from input text. And this is actually one of the\u2013I don\u2019t want to take it too philosophical too early\u2013but one of the interesting things I think about, you know, sequence sequence models in general and this notion of hallucinations, which is like a probable output text, feels like, it\u2019s not a line at which point you know it passes the Turing test. But for something to be plausible, possibly human. It first needs to be like you read it, and it doesn\u2019t sound like gibberish. And then that was like Markov chain generators, you would read it, and it\u2019d be like token like I am, and you, you know it makes sense on any gram chunk. But you read the whole thing. It doesn\u2019t make any sense, and then Transformers added attention to that. So you would read a paragraph, and, like the third sentence in the paragraph, was contextually relevant with the first. But that\u2019s not the end state. That\u2019s a step along the path. And then now, if you\u2019re talking to a person you have this like BS sensor, right where it\u2019s like you\u2019re a human, but you\u2019re lying to me or like you don\u2019t know what you\u2019re talking about. It\u2019s interesting what we consider a hallucination versus I don\u2019t know the transformer. These generators are doing what they were always meant to do, which",
    "chunk_id": "downloaded_1763607480_12"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "human, but you\u2019re lying to me or like you don\u2019t know what you\u2019re talking about. It\u2019s interesting what we consider a hallucination versus I don\u2019t know the transformer. These generators are doing what they were always meant to do, which is predict probable output text. So, coming back to your question, the parametric memory is not just that it knows how to generate language that is syntactically correct and semantically well formed, but is about the universe that we actually live in. It\u2019s not, you know, an English language sequence about a made up fantasy land. And this is parametric memory. Non-parametric memory is what you\u2019ve added to your model to be able to extend those encoded parameters. You spent a lot of money encoding structures of language facts about the world into your sequence model parameters. And you don\u2019t want to keep doing that over and over and over again. This is quite an expense. So this technique adds an additional source of information in the form of non-parametric memory. And I don\u2019t know that it would always need to take the form of a vector database\u2013in this paper it does. But really, I think it would be anything that your model can leverage which is not encoded into its parameters. So I would even make the argument that if you\u2019ve trained your model to make calls to Google, Google is acting as a form of non-parametric memory for your model. So it\u2019s really your model\u2019s ability to reference some external index structure. That\u2019s not",
    "chunk_id": "downloaded_1763607480_13"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "make the argument that if you\u2019ve trained your model to make calls to Google, Google is acting as a form of non-parametric memory for your model. So it\u2019s really your model\u2019s ability to reference some external index structure. That\u2019s not its train parameters. Aman Khan: Yeah, I also find it interesting that they call out specifically the Dpr follows a by encoder architecture. So that\u2019s the relationship between the query and the document that\u2019s being referenced. They\u2019ve specifically trained this Dpr with a buying encoder architecture to simplify the architecture. I mean, you could use things like crossing coders. You could use much more complex encoders. But the idea is like, let\u2019s just throw something really simple at a large corpus of data, so that we can build up these relationships in the form of this non parametric memory. And I think that that means that there\u2019s some concept of this like scaling. Basically, you can throw more, you know, swap out the index and the encoder architecture remains the same, and so you will get roughly the same performance, which I think is pretty interesting. Michael Schiff: Parametric memory is also what\u2019s allowing some of the fine tuning. So we said earlier that they don\u2019t fine tune the document encoder this D,Z, but they do fine tune the query encoder over time. Go through the fine tuning process, they will produce better encodings of your query, such better defined as when used to retrieve documents. We\u2019ll pull out more relevant documents, having not changed the",
    "chunk_id": "downloaded_1763607480_14"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "fine tune the query encoder over time. Go through the fine tuning process, they will produce better encodings of your query, such better defined as when used to retrieve documents. We\u2019ll pull out more relevant documents, having not changed the document encoding, just better encoding of the query which I found really interesting. Aman Khan: Yeah, exactly. And they talk about that in the training method here: \u201cUpdating the document encoder during training is costly, it requires a document index to be periodically updated,\u201d and they reference the canonical work before that which is a realm which is sort of pre-training with retrieval, augmentation. And they do not find the stuff necessary for strong performance and keep the documents encoder fixed, only find toning the query encoder BERT and the BART generator. So it\u2019s exactly what you\u2019re saying, Michael, which is like you could also throw the encoder and and basically use retrieval augmentation during the pre training step, but that just makes it so much more expensive as an architectural perspective versus just keeping that encoder fixed and swapping out your query on and your sort of knowledge based on top of that. Michael Schiff: I think this also hits on the online implementations that we\u2019ll start to see of this where your document index is not static, but is growing over time. It\u2019s this expensive, incrementally built thing that you\u2019re slowly indexing more and more information, and likely than you need to fine tune your query encoding to better access this growing corpus of",
    "chunk_id": "downloaded_1763607480_15"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "is not static, but is growing over time. It\u2019s this expensive, incrementally built thing that you\u2019re slowly indexing more and more information, and likely than you need to fine tune your query encoding to better access this growing corpus of data. Aman Khan: We\u2019ll take a slight aside into RAG token versus RAG sequence as well, and I think this one was pretty interesting. They experimented with like: Can you kind of predict the next token, or the next sequence based on the previous token of sequence, that you retrieve when you retrieve context? And then they basically threw these approaches at a bunch of experiments to compare. Okay, which one is actually you know, like, there\u2019s straight offs between either of them. But the interesting one rack token we can plug into a standard beam encoder when it comes to rack sequence, you need more efficient decoding. So there\u2019s sort of like trade offs between either token or sequence, and we\u2019ll kind of get into some of the experiments here. So what they did\u2013 the authors of this paper\u2013is through Open Domain question answering, which is, you know, kind of answering an open-ended question. And in this case again, you are referencing Wikipedia. There is Closed-Book QA, or Open-Domain QA. So you know, Closed-Book might be like, what\u2019s the tallest mountain in North America? Something that has like, you know, sort of a specific answer. And then, what\u2019s a good Open Domain QA or question, Michael, that you can come up with? Michael Schiff: Just",
    "chunk_id": "downloaded_1763607480_16"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "be like, what\u2019s the tallest mountain in North America? Something that has like, you know, sort of a specific answer. And then, what\u2019s a good Open Domain QA or question, Michael, that you can come up with? Michael Schiff: Just an aside of what we were just talking about\u2013the thing I thought was interesting about the discussion of Closed Book here is it\u2019s hard to argue that there is any form of RAG that is truly closed book. And also distinguishing between closed book, open book, and closed domain, open domain. So something that has like a super concrete right answer\u2013that\u2019s Closed-Domain. The open book, closed book is like: Do I have my reference manual? Am I relying only on parametric memory? So I think it\u2019s interesting that they talk about close book retrieval, because there\u2019s no it\u2019s a close book, RAG. Aman Khan: It\u2019s like a look up at that point right? You\u2019re just like looking at the reference at that point? Michael Schiff: Correct, which is not cheating or anything. They bring that up at the very beginning, that knowledge intensive tasks are those that cannot be expected to be answered without this external reference. I\u2019m struggling to think of an open domain. Aman Khan: Yeah, I\u2019m trying to remember. It\u2019s like something that you know\u2026 Michael Schiff: Oh, what\u2019s the weather in Volcano, California? Aman Khan: Right, where there is a specific answer. But it\u2019s like dependent on real time data and it depends on how up to date your data is. And",
    "chunk_id": "downloaded_1763607480_17"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "you know\u2026 Michael Schiff: Oh, what\u2019s the weather in Volcano, California? Aman Khan: Right, where there is a specific answer. But it\u2019s like dependent on real time data and it depends on how up to date your data is. And then they have these sort of abstractive question answers, there\u2019s no supply passes only the question and answers. And they use MSMARCO. Which is Bing questions basically. So you know, some of those will require a look up that Wikipedia won\u2019t even have information on. Actually, I thought this was interesting, this data set, by the way, on abstractive question answering, using MSMARCO, it\u2019s things that you would expect to see from Bing, which is like very short questions. Actually, it\u2019s like, you know, what\u2019s you know, like book a flight or whatever. But it\u2019d be a question like it\u2019s not. You\u2019re not going to get like a very long form, like what you might expect to see from a Bar exam, or like a medical exam. So it\u2019s really pretty practical as a data set. And then Jeopardy question generation, which is pretty interesting. This is all just sort of set up on like the evaluation. But then they talk about with Jeopardy questions you have to have the context, and some of the questions are phrased in a certain way, and you have to infer what the question is asking and know what the context is that they\u2019re asking about. So it\u2019s this, this is a pretty complex Michael Schiff: That one was particularly",
    "chunk_id": "downloaded_1763607480_18"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "are phrased in a certain way, and you have to infer what the question is asking and know what the context is that they\u2019re asking about. So it\u2019s this, this is a pretty complex Michael Schiff: That one was particularly interesting and highlighting some of the differences between RAG sequence and RAG token. Aman Khan: Exactly. So now we\u2019re going to jump into that. So I\u2019m actually going to hop ahead a little bit so open domain question answering, open book retrieval based approaches. The main takeaway here is, you know, RAG, basically the main take away, I think, from here is like an open book, closed book is that RAG actually performs better than these large sort of state of the art language models. so if you\u2019re even if you\u2019re even if you\u2019re comparing to like billion per billion. For in our models, these are like what you were kind of mentioning before, you know, this is at a time when, like the larger language model like that meant it was like that much better the sort of state of the art. So billion parameters. This is like pre-GPT days so I mean, you\u2019re really taking like an underpowered model, and you\u2019re hooking it up to this knowledge base, and it performs better than a very powerful parametric memory language model. So I thought that was like the main takeaway. What I wanted to jump into actually, is this example which you\u2019re going to talk about Michael. I\u2019m guessing is the Hemingway example of when",
    "chunk_id": "downloaded_1763607480_19"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "very powerful parametric memory language model. So I thought that was like the main takeaway. What I wanted to jump into actually, is this example which you\u2019re going to talk about Michael. I\u2019m guessing is the Hemingway example of when you\u2019re asking Jeopardy questions. So, what is actually happening underneath the hood? What\u2019s firing in the memory to answer this type of question. Is this something that is kind of interesting to you as well? This example shows how parametric non parametric memories work together. The sort of jeopardy question here? Michael Schiff: Yeah, there\u2019s, I mean, there\u2019s a bunch of interesting stuff in this section. I think we should maybe talk for a minute just about the difference between RAG sequence and RAG token. Without going into, like all of the math. RAG sequence after selecting the top K documents for the question, we will use a single one of those documents to generate the entire response sequence, and RAG token will generate token by token, using a different one of those top K documents per token. And we talked a little bit about the decoding and actually generating from those models. And one of the things I thought was kind of. I guess. Surprising was that the rad sequence, the generation seemed to be more expensive, that they required this approximation. And that surprised me at first. The rag sequence from their results tended to outperform r token except in the jeopardy case. A. And one of the things I thought was interesting there",
    "chunk_id": "downloaded_1763607480_20"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "more expensive, that they required this approximation. And that surprised me at first. The rag sequence from their results tended to outperform r token except in the jeopardy case. A. And one of the things I thought was interesting there is that they describe this to be due to the fact that a good jeopardy answer often needs to rely on information across multiple documents. So I wonder how much of the increased performance of RAG sequence over at token was due to the types of questions you\u2019re asking. And similarly, the selection of you know, to documents. How much of this is due to the corpus they selected like, if you split Wikipedia up into a hundred word chunks, and then the types of questions they ask, How often are you going to need to reference multiple chunks to get a good answer? And how often is it going to come from a single word chunk? But if you change your problem, will that still be true? So this visualization is very cool. It kind of shows a graphical representation of the posterior probabilities of each next token conditioned on the latent documents that were selected. So in this case they pulled out five documents, and each column can be thought of as the posterior probability for generating the next token given each of those documents. So, you can see from the heat map, the way different documents contribute differently to the final. And ultimately it\u2019s just going to choose one. But the sun coming",
    "chunk_id": "downloaded_1763607480_21"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "probability for generating the next token given each of those documents. So, you can see from the heat map, the way different documents contribute differently to the final. And ultimately it\u2019s just going to choose one. But the sun coming from Doc two or coming from Doc one is one of the interesting takeaways. Aman Khan: And so for context, like document one document two, these are chunks from Wikipedia. And what this is saying is, when I provide this this jeopardy question: The Sun Also Rises is a novel by this author of a Farewell to Arms. It\u2019s like you\u2019re framing it in this way where you need to have the contacts, even though what you\u2019re talking about it\u2019s not even to generate the answers, to, to actually know what to even look up, what\u2019s relevant to look up. And I thought this was really fascinating actually, in the explanation. By the way, I highly recommend it, we\u2019ll send out you know, maybe a link to the paper. But there\u2019s a video by the first author of the paper, Patrick Lewis, which also kind of talks about this, and I\u2019m like well, we\u2019re both scratching ahead of this yesterday, like, why is, why is it firing on like A Farewell to Arms? Right? Why is document one which is his works are considered classics like, why is that the relevant piece of information with A Farewell to Arms? And it\u2019s actually because most books don\u2019t start with the letter \u201cA\u201d so it actually makes it",
    "chunk_id": "downloaded_1763607480_22"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "document one which is his works are considered classics like, why is that the relevant piece of information with A Farewell to Arms? And it\u2019s actually because most books don\u2019t start with the letter \u201cA\u201d so it actually makes it really powerful and strong to look up a farewell to arms, being pretty unique in this and the index and relevant to the document being asked in the non parametric sort of memory. Here it was like a farewell to arms, and then the sun. Once you have that information that you know you can say, Okay, well, this, when you\u2019re talking about something. This is the relevant sort of document with that artist with that who, based on that look up. So I thought that was pretty interesting as well. based on this visualization of like top documents that are retrieved. This one fires on a Farewell to Arms, on a letter, on the letter a, so that was pretty interesting based on it the entire sequence. So that\u2019s like a visualization on the token sort of the token based model here. Do you want to talk a little bit about what\u2019s going on with the index hot swapping, or I guess any thoughts on this overall sort of evaluation that they used? Michael Schiff: The index hot swapping is interesting. I mean, I think it speaks to the generality of the approach and a little bit of what we were discussing a minute ago. Which is you? You could build that index in an",
    "chunk_id": "downloaded_1763607480_23"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "The index hot swapping is interesting. I mean, I think it speaks to the generality of the approach and a little bit of what we were discussing a minute ago. Which is you? You could build that index in an online fashion. You can swap it out. They also discuss the degree to which that index is humanly readable and and humanly modifiable. So, I think it makes practical a way to augment models that are otherwise out of the realm of an individual, to modify their parametric memory. So I think this approach is going to be a way that we see. And I mean, it\u2019s pretty easy to say in hindsight, because it\u2019s already happening but a way of democratizing the use of these models on tasks for which they were not specifically trained, and for which maybe you hold the data privately. Aman Khan: Yeah, exactly. And they kind of talk about the results of when you swap out the document index, and you do the same comparison of something like you know, sort of off the shelf parametric model and the non parametric\u2013it\u2019s going to perform better, even if you trained that that larger model on on, on some of the the same data. I realized we actually jumped over one pretty interesting insight from this explanation as well, which was the interaction between the parametric and non-parametric memory. Do you want to chat about how those two kind of work hand in hand about how to generate the response here. Michael",
    "chunk_id": "downloaded_1763607480_24"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "interesting insight from this explanation as well, which was the interaction between the parametric and non-parametric memory. Do you want to chat about how those two kind of work hand in hand about how to generate the response here. Michael Schiff: Yea so I mean ultimately, the output is still the output of the sequence model. So the end thing that you are reading is entirely the product of parametric memory. I think they throw it in there In one sentence. When all is said and done, they grab a document, and they concatenate it onto the question. So like what this model of this architecture is a way of\u2013they call it retrieval augmented generation. It\u2019s really question augmentation, intelligent question augmentation through an index structure of relevant data. But the fact that the output comes through a generator\u2013so is the product of parametric memory is is pretty different from other retrieval systems. Maybe the finding of relevant documents is the same, and then they intelligently crop out portions or mask out parts of the document, pull out and extract and a verbatim quote. These architectures, RAG architectures are able to answer questions correctly in cases where the documents don\u2019t contain verbate of the answer. So you might be able to pull out documents which together and in, and you know you would be able to understand the answer. But there\u2019s no one sentence that is exactly the answer these models can produce, whereas an explicit extractive retrieval model wouldn\u2019t be able to do that. This",
    "chunk_id": "downloaded_1763607480_25"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "and in, and you know you would be able to understand the answer. But there\u2019s no one sentence that is exactly the answer these models can produce, whereas an explicit extractive retrieval model wouldn\u2019t be able to do that. This again, I think, comes back to that philosophical question of the gray area slash continuum from what is plausibly human text to what is factually accurate text to this is a hallucination. And you look at a case where it\u2019s produced a correct answer that was nowhere in the original text, and arguing that that\u2019s different from a prediction which turned out to align with our reality versus a hallucination which doesn\u2019t align with our reality\u2013it\u2019s tough for me to know where those two things are actually different from each other. Aman Khan: If I can reframe Michael, basically what you\u2019re saying is: RAG is great to be able to pull out the context that\u2019s then used to generate some piece of text or generate some context. So you can find the index and use that to generate something. So that\u2019s the non parametric memory that then flows into parametric memory. But in many ways the parametric memory component is a hallucination, it\u2019s a Wikipedia document. But if you swap this out with your own knowledge, base the non parametric memory, the retrieval is specific to your knowledge base. That\u2019s the index. But the parametric memory is just whatever the LLM is producing. It could literally be a hallucination that sounds correct because it sounds like",
    "chunk_id": "downloaded_1763607480_26"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "base the non parametric memory, the retrieval is specific to your knowledge base. That\u2019s the index. But the parametric memory is just whatever the LLM is producing. It could literally be a hallucination that sounds correct because it sounds like the context that was retrieved should be able to produce the next kind of token, or the next sequence based on that parametric memory, but it could literally be like, how do you even gauge the correctness of that right? I mean, it could be you could be pulling the right document, the right piece of information and the parametric memory can produce a hallucination that sounds correct. And I thought that was so interesting from this paper as well that is kind of a little bit covered over, I think, like it\u2019s not really called out super explicitly. But basically they find that because you\u2019ve trained a model on data that you aren\u2019t referencing, and you\u2019re using non-parametric memory to augment that generation, the hallucinations that appear are even harder to spot. Michael Schiff: I don\u2019t know if it\u2019s in the paper, or if it was elsewhere but it was the example of like, how many calories are in an average apple and an average serving an apple has a thousand calories. And if you don\u2019t know anything about nutrition, you\u2019d be like, okay, cool, that sounds good. But you look back at it by a thousand, it sounds so accurate and right that I think that that\u2019s where it comes back to these. You",
    "chunk_id": "downloaded_1763607480_27"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "don\u2019t know anything about nutrition, you\u2019d be like, okay, cool, that sounds good. But you look back at it by a thousand, it sounds so accurate and right that I think that that\u2019s where it comes back to these. You know, the sequence models are generating a probable output sequence. Given the input sequence. And if trained well, the most probable output sequence is going to align with reality. But the degradation of that is going to be something that doesn\u2019t align with reality, but does look possibly human. So I think it\u2019s interesting. The way we as an industry talk about hallucinations. It\u2019s like this black and white thing, when really it\u2019s sort of like the continuum of what these things are expected to do. Aman Khan: Exactly. Yeah. I mean, I feel like, that\u2019s like, kind of just getting to some of the wrap up actually, so it says it makes it hallucinate less with generations that are more factual and offers more control. It generates hallucinations that sound less incorrect is basically what they\u2019re saying here, And I think that\u2019s a really interesting nuance. It\u2019s something to consider, for the folks here are the researchers here as you\u2019re looking at rag models, we\u2019re I mean, we\u2019re looking at the canonical paper here. I think another interesting, just sort of insight is like they\u2019re talking about. GPT. These are older models. Parametric memory has gotten even better. So you could imagine that. Okay, even if your retrieval is good. The parametric memory is solid.",
    "chunk_id": "downloaded_1763607480_28"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "think another interesting, just sort of insight is like they\u2019re talking about. GPT. These are older models. Parametric memory has gotten even better. So you could imagine that. Okay, even if your retrieval is good. The parametric memory is solid. It knows enough about the world to reason about the context that you\u2019re providing it. The hallucination is going to sound even better, even if you know the top document retrieved is relevant. It\u2019s something to keep in mind. I thought it was pretty fascinating that like, basically. What they\u2019re saying is that not in parametric memory just augments how good the hallucination might sound, so I think that one came out of the video discussion with the first author here when someone asked him or around that. So any more sort of thoughts as we kind of round this out and kind of open any questions of folks happening in the community. Michael Schiff: I\u2019m happy to pass it off to the community if people will have questions. Aman Khan: I guess, while we wait, what\u2019s kind of interesting as well is, we talked a little bit about you know this canonical paper. What are some other interesting applications you\u2019re seeing of RAG today? I think we talked a little bit about index. yeah, offline. What are your thoughts on index and more modern approaches to RAG? Michael Schiff: We\u2019re seeing a lot of people take product documentation and use that as the index. I mean, I was even the example I pulled off in",
    "chunk_id": "downloaded_1763607480_29"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "What are your thoughts on index and more modern approaches to RAG? Michael Schiff: We\u2019re seeing a lot of people take product documentation and use that as the index. I mean, I was even the example I pulled off in terms of a car usage manual. But I think you\u2019re seeing a lot of approaches where it comes back to this idea of hallucinations again, and like what these models are really good at and we\u2019ve seen it, their ability to to summarize work really, really well. And so the degree to which you can turn this into a summarization problem where, rather than hallucinating an answer based on documents. It\u2019s summarizing documents retrieved and providing an interface onto a pre existing problem like your experience with the product documentation before might have been like a keyword search, and then being presented with a list of answers that, like you, you are probably pretty good at skimming through the words in that summary. That\u2019s truly just an extractive summary. But you know, a layer on top of that that provides humanized summaries and and guides you through that process which is really a process you\u2019ve already been doing but more easily, and without having that kind of I don\u2019t know if you\u2019ve ever watched somebody else run a search engine query, who\u2019s like not necessarily doing it all the time. And it\u2019s like they\u2019re clicking the wrong links. And I can imagine, you know, assisting that process. And Aman Khan: yeah, it changes. It changes your",
    "chunk_id": "downloaded_1763607480_30"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "run a search engine query, who\u2019s like not necessarily doing it all the time. And it\u2019s like they\u2019re clicking the wrong links. And I can imagine, you know, assisting that process. And Aman Khan: yeah, it changes. It changes your interactions. It changes what the queries even look like, right? Because you\u2019re now no longer optimizing for how Google returns the top index result, you\u2019re actually framing a question and expecting an answer. And so I think that has some implications and like design language designing for these systems where it feels more like you\u2019re interacting with an expert or a human on the topic. And it\u2019s just something to consider if you\u2019re building one of those systems that understanding what\u2019s being retrieved, and how you know, token or sequence that\u2019s being generated is pretty important. So I think it was pretty interesting to die deeper here because you assume like, yeah, I hooked up my, you know my agents to my vector database. And it\u2019s gonna pull a top document and give me relevant results. But even then, there\u2019s so much weight on the parametric memory. That\u2019s been augmented. That understanding how it works is, I think for me it was a pretty big takeaway. Actually, that it hallucinates correctly is basically the takeaway answer questions correctly, even when the correct answer is not in retrieving documents. Michael Schiff: Yeah. Aman Khan: A lot of fun to read this one. I think we\u2019ll probably do some more on retrieval systems. And you know, context augmented",
    "chunk_id": "downloaded_1763607480_31"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "questions correctly, even when the correct answer is not in retrieving documents. Michael Schiff: Yeah. Aman Khan: A lot of fun to read this one. I think we\u2019ll probably do some more on retrieval systems. And you know, context augmented generation in the future. We got to talk about the foundational paper on the subject. Thanks for the time, Michael. And thanks, everyone. Share Suggested reading Meta AI Researcher Explains ARE and Gaia2: Scaling Up Agent Environments and Evaluations ServiceNow\u2019s Tara Bogavelli on AgentArch: Benchmarking AI Agents for Enterprise Workflows Sign up for our monthly newsletter, The Evaluator. Subscribe Platform Arize AX - Generative Arize AX - ML & CV Docs Pricing Phoenix Open Source Learn Blog AI Agents & Assistants Handbook Evaluating AI Agents course AI Research Papers Arize Community Topics Agent Evaluation AI Agent: Useful Case Study AI Product Manager LLM Tracing LLM Hallucination Examples Prompt Optimization Techniques LLM as a Judge Company About Careers Press Security Customers Get started Book a Demo Sign In Contact Privacy Policy Arize - LLMs.txt Phoenix - LLMs.txt Linkedin Twitter Copyright \u00a9 2025 Arize AI, Inc Privacy Policy Subscribe to The Evaluator We\u2019ll send you the latest news, expertise, and product updates from Arize. Your inbox is sacred, so we\u2019ll only curate and send the best stuff. *We\u2019re committed to your privacy. Arize uses the information you provide to contact you about relevant content, products, and services. You may unsubscribe from these communications at any time. For more information, check out our privacy policy.",
    "chunk_id": "downloaded_1763607480_32"
  },
  {
    "doc": "downloaded_1763607480.txt",
    "chunk": "committed to your privacy. Arize uses the information you provide to contact you about relevant content, products, and services. You may unsubscribe from these communications at any time. For more information, check out our privacy policy.",
    "chunk_id": "downloaded_1763607480_33"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "Source: https://blog.roboflow.com/what-is-retrieval-augmented-generation/ What is Retrieval Augmented Generation? Products Platform Universe Open source computer vision datasets and pre-trained models Annotate Label images fast with AI-assisted data annotation Train Hosted model training infrastructure and GPU access Workflows New Low-code interface to build pipelines and applications Deploy Run models on device, at the edge, in your VPC, or via API Solutions By Industry Explore all industry solutions Aerospace & Defense Automotive Consumer Goods Energy & Utilities Healthcare & Medicine Industrial Manufacturing Logistics Manufacturing Media & Entertainment Retail & Service Transportation Warehousing Explore customer stories and ebooks -> See case studies, comprehensive guides, and insights from thousands of real-world AI projects. Resources Customer Stories Weekly Product Webinar User Forum Inference Templates Documentation Model Playground Changelog Convert Annotation Formats Pricing Docs Blog Search Sign In Book a demo Get Started Search Sign in Book a demo Get Started Search Blog What is Retrieval Augmented Generation? James Gallagher Published Nov 16, 2023 \u2022 5 min read Large Language Models (LLMs), especially LLMs with vision capabilities like GPT-4, have an extensive range of applications in industry. For example, LLMs can be used to answer questions about a given subject, write code, explain an infographic, identify defects in products, and more.With that said, LLMs have significant limitations. One notable limitation is that models are expensive to train and fine-tune, which means customizing large models to specific use cases is prohibitive. As a result, the knowledge on which a model was trained may be stuck in the past or not relevant to your domain.This is",
    "chunk_id": "downloaded_1763607482_0"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "expensive to train and fine-tune, which means customizing large models to specific use cases is prohibitive. As a result, the knowledge on which a model was trained may be stuck in the past or not relevant to your domain.This is where Retrieval Augmented Generation, or RAG, comes in. With RAG, you can retrieve documents relevant to a question and use the documents in queries to multimodal models. This information can then be used to answer a question.In this guide, we are going to talk about what RAG is, how it works, and how RAG can be applied in computer vision. Without further ado, let\u2019s get started!What is Retrieval Augmented Generation (RAG)?Retrieval Augmented Generation (RAG) is a technique to retrieve context for use in prompting Large Language Models (LLMs) and Large Multimodal Models (LMMs). RAG starts with searching a series of documents that contain text or image files for content that is relevant to a query. Then, you can use the text and/or image context in a prompt. This enables you to ask questions with additional context that is not available to a model.RAG attempts to solve a fundamental problem with the current generation of LMMs: they are frozen in time. LMMs such as GPT-4 are trained infrequently due to the high capital costs and resources required to train a model. Consequently, it is difficult to train a model for a specific use case, which means many rely on base models such OpenAI\u2019s GPT series.RAG helps overcome these problems. With the RAG approach to programmatically writing information",
    "chunk_id": "downloaded_1763607482_1"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "to train a model. Consequently, it is difficult to train a model for a specific use case, which means many rely on base models such OpenAI\u2019s GPT series.RAG helps overcome these problems. With the RAG approach to programmatically writing information rich prompts, you can provide contextual information in a prompt. For example, consider an application that uses LMMs to answer questions about software documentation. You could use RAG to identify documents relevant to a question (i.e. \u201cwhat is {this product}\u201d)? Then, you can include those documents in a prompt, with direction that the documents are context.With RAG, you can provide documents that:Contain your own data;Are relevant to a query, and;Represent the most up to date information you have.RAG enables you to supercharge the powers of LMMs. The LMM has a vast body of knowledge while RAG enables you to augment those capabilities with images and text relevant to your use case.How RAG WorksA flow chart showing how RAG works. Image sourced from and owned by Scriv.ai.At a high level, RAG involves the following steps:A user has a question.A knowledge base is searched to find context that is relevant to the query.The context is added to a prompt that is sent to an LMM.The LMM returns a response.To use RAG, you need to have a database of content to search. In many approaches, a vector database is used, which stores both text or image data (i.e. a page of documentation or an image of a car part) and vectors which can be used to search the database.Vectors",
    "chunk_id": "downloaded_1763607482_2"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "content to search. In many approaches, a vector database is used, which stores both text or image data (i.e. a page of documentation or an image of a car part) and vectors which can be used to search the database.Vectors are numeric representations of data which are calculated using a machine learning model. These vectors can be compared to find similar documents. Vector databases enable semantic search, which means you can find documents that are most related to a prompt. For example, you could provide a text query \u201cToyota\u201d and retrieve images related to that prompt.To get a feel for how semantic search works in a real application, try querying this dataset in Roboflow Universe to find images.Next, you need a question from a user or an application. Consider an application that values cars. You could use RAG to search a vector database for images of mint condition car parts that are related to the specific model of car that a user has (i.e. \u201cToyota Camry car doors\u201d). These images could then be used in a prompt, such as:\u201cThe images below show Toyota Camry car doors. Identify whether any of the images contain scratches or other damage. If an image contains any damage, describe the damage in detail.\u201dBelow the prompt, you would provide reference images from a vector database (the mint condition car parts) and the image that has been submitted by a user or an application (the part that should be valued). If the user submitted an image that contains a scratch, the model should",
    "chunk_id": "downloaded_1763607482_3"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "a vector database (the mint condition car parts) and the image that has been submitted by a user or an application (the part that should be valued). If the user submitted an image that contains a scratch, the model should identify the scratch and describe the issue. This could then be used as part of a report reviewed by a person to decide how to value the car, or an automated system.Using RAG in Computer VisionOver the years, computer vision has been greatly influenced by developments in the field of natural language processing.The RAG approach was originally developed for use exclusively for use with text and LLMs. But, a new generation of models are available: LMMs with vision capabilities. These models are able to answer natural language questions with images as references.With RAG, you can retrieve relevant images for a prompt, enabling you to provide visual information as a reference when asking questions. Microsoft Research published a paper in October 2023 that notes performance improvements when providing reference images in a prompt as opposed to asking a question with no references.For example, the paper ran a test to read a speed meter. Using GPT-4V with two examples (few-shot learning) resulted in successfully reading the speed meter, a task that GPT-4V could not accomplish with one or no examples.There are many possibilities to use RAG as part of vision applications. For example, you could use RAG to build a defect detection system that can refer to existing images of defects. Or you could use RAG as part",
    "chunk_id": "downloaded_1763607482_4"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "no examples.There are many possibilities to use RAG as part of vision applications. For example, you could use RAG to build a defect detection system that can refer to existing images of defects. Or you could use RAG as part of a logo detection system that can reference existing logos in your database which may be obscure and unknown by an LMM.You can also use RAG as part of a few-shot labeling system. Consider a scenario where you have 1,000 images of car parts that you want to label to train a fine-tuned model that you can run at the edge, on device. You could use RAG with an existing set of labeled images to provide context for use in labeling the rest of a dataset.ConclusionRetrieval Augmented Generation (RAG) helps address the constraint that LMMs are trained in one large training job; they are infrequently retrained, too. With RAG, you can provide relevant contextual information in a prompt that will then be used to answer a question.RAG involves using a vector database to find information related to a query, then using that information in a prompt.Traditionally, RAG was used with text data. With the advent and continued development of multimodal models that can use images as inputs, RAG has a myriad of applications in computer vision. With a RAG-based approach, you can retrieve images relevant to a prompt and use them in a query to a model such as GPT-4. Cite this Post Use the following entry to cite this post in your research: James Gallagher.",
    "chunk_id": "downloaded_1763607482_5"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "With a RAG-based approach, you can retrieve images relevant to a prompt and use them in a query to a model such as GPT-4. Cite this Post Use the following entry to cite this post in your research: James Gallagher. (Nov 16, 2023). What is Retrieval Augmented Generation?. Roboflow Blog: https://blog.roboflow.com/what-is-retrieval-augmented-generation/ Stay Connected Get the Latest in Computer Vision First Unsubscribe at any time. Review our Privacy Policy. Model Playground Compare VLM Models Side-by-Side Written by James Gallagher James is a technical writer at Roboflow, with experience writing documentation on how to train and use state-of-the-art computer vision models. View more posts Topics Multimodal Multimodal Table of Contents More About View All Posts Product Universe Annotate Train Workflows Deploy Pricing Talk to Sales Enterprise Ecosystem Notebooks Autodistill Supervision Inference Roboflow 100 Open Source Hardware Developers Documentation User Forum Changelog What is computer vision? Weekly Product Webinar Convert Annotation Formats Computer Vision Models Model Playground Industries Customer Stories Aerospace & Defense Automotive Consumer Goods Energy and Utilities Healthcare & Medicine Industrial Manufacturing Logistics Manufacturing Media & Entertainment Retail & Service Transportation Warehousing Models RF-DETR YOLO11 YOLOv8 YOLOv5 Florence-2 SAM 2 Multimodal Models Explore All Models Company About Us Blog Careers Press Contact Service Status Terms of Service Enterprise Terms Privacy Policy Sitemap \u00a9 Roboflow, Inc. All rights reserved.",
    "chunk_id": "downloaded_1763607482_6"
  },
  {
    "doc": "downloaded_1763607482.txt",
    "chunk": "reserved.",
    "chunk_id": "downloaded_1763607482_7"
  }
]